"use strict";(self.webpackChunk_openfn_docs=self.webpackChunk_openfn_docs||[]).push([[73516],{28453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>r});var a=t(96540);const i={},o=a.createContext(i);function s(e){const n=a.useContext(o);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),a.createElement(o.Provider,{value:n},e.children)}},73789:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>r,default:()=>h,frontMatter:()=>s,metadata:()=>a,toc:()=>d});const a=JSON.parse('{"id":"hive","title":"Hive Adaptor","description":"About Apache Hive","source":"@site/adaptors/hive.md","sourceDirName":".","slug":"/hive","permalink":"/adaptors/hive","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Hive Adaptor"},"sidebar":"adaptors","previous":{"title":"README.md","permalink":"/adaptors/packages/googlesheets-readme"},"next":{"title":"Functions","permalink":"/adaptors/packages/hive-docs"}}');var i=t(74848),o=t(28453);const s={title:"Hive Adaptor"},r=void 0,c={},d=[{value:"About Apache Hive",id:"about-apache-hive",level:2},{value:"Integration Options",id:"integration-options",level:2},{value:"Authentication",id:"authentication",level:2},{value:"Helpful Links",id:"helpful-links",level:3},{value:"Implementation Examples",id:"implementation-examples",level:3}];function l(e){const n={a:"a",code:"code",em:"em",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",...(0,o.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h2,{id:"about-apache-hive",children:"About Apache Hive"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"https://hive.apache.org/",children:"Apache Hive"})," is a data warehouse software that facilitates reading, writing, and managing large datasets stored in distributed storage systems."]}),"\n",(0,i.jsx)(n.h2,{id:"integration-options",children:"Integration Options"}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.code,{children:"hive"})," adaptor provides direct database connections for accessing data and executing SQL and standard database operations. See ",(0,i.jsx)(n.a,{href:"/adaptors/packages/hive-docs",children:"functions"})," for more on how to use this adaptor."]}),"\n",(0,i.jsx)(n.h2,{id:"authentication",children:"Authentication"}),"\n",(0,i.jsxs)(n.p,{children:["See ",(0,i.jsx)(n.a,{href:"https://hive.apache.org/docs/",children:"Hive docs"})," for the latest on supported authentication methods. When integrating with a Hive database via OpenFn, you authenticate via SSH using authorized database credentials. See this adaptor's ",(0,i.jsx)(n.a,{href:"/adaptors/packages/hive-configuration-schema",children:"Configuration docs"})," for more on the required authentication parameters."]}),"\n",(0,i.jsxs)(n.p,{children:["See platform docs on ",(0,i.jsx)(n.a,{href:"/documentation/manage-projects/manage-credentials",children:"managing credentials"})," for how to configure a credential in OpenFn. If working locally or if using a Raw JSON credential type, then your configuration will look something like this:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'{\n  "host": "some-host-url.compute-1.amazonaws.com",\n  "database": "demo-db",\n  "username": "admin-demo",\n  "password": "@super(!)Secretpass"\n}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"helpful-links",children:"Helpful Links"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://hive.apache.org/",children:"Hive documentation"})}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"implementation-examples",children:"Implementation Examples"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.em,{children:"Coming soon!"})})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(l,{...e})}):l(e)}}}]);