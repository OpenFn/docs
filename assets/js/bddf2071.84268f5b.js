"use strict";(self.webpackChunk_openfn_docs=self.webpackChunk_openfn_docs||[]).push([[82501],{77981:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"/2022/09/19/auth-security","metadata":{"permalink":"/articles/2022/09/19/auth-security","editUrl":"https://github.com/openfn/docs/edit/main/articles/2022-09-19-auth-security.md","source":"@site/articles/2022-09-19-auth-security.md","title":"Secure by design: a roadmap to secure authentication and authorization","description":"In order to ensure that Global Goods and Digital Public Goods can enable impact","date":"2022-09-19T00:00:00.000Z","tags":[{"inline":true,"label":"security","permalink":"/articles/tags/security"},{"inline":true,"label":"authentication","permalink":"/articles/tags/authentication"},{"inline":true,"label":"authorization","permalink":"/articles/tags/authorization"}],"readingTime":3.16,"hasTruncateMarker":true,"authors":[{"name":"Amber Rignell","socials":{"github":"https://github.com/amberrignell"},"imageURL":"https://avatars.githubusercontent.com/amberrignell","key":"amber","page":null}],"frontMatter":{"layout":"post","title":"Secure by design: a roadmap to secure authentication and authorization","authors":"amber","tags":["security","authentication","authorization"],"image":"https://user-images.githubusercontent.com/105651463/172341536-ebde5ca0-12b8-4a8a-bb40-da9442701df3.png","featured":false},"unlisted":false,"nextItem":{"title":"Workflow Automation; Why do it yourself when a program can do it for you?","permalink":"/articles/2022/06/07/workflow-automation"}},"content":"In order to ensure that Global Goods and Digital Public Goods can enable impact\\nwithout doing any harm, it is crucial that their authentication and\\nauthorization systems are secure from the outset.\\n\\nWe\u2019ve put together a resource to help other Digital Public Goods and Global\\nGoods achieve just this. You can view and comment on the resource\\n[here](https://docs.google.com/document/d/1QvOcOdk2iZCWnAVNiBbmhh-6Q2gapUhsMCUzJQNWqEU/edit?usp=sharing),\\nor read on to learn why.\\n\\n\x3c!--truncate--\x3e\\n\\nDigital health technologies have a critical role to play in both improving the\\ndelivery of health services _and_ making health systems more robust and\\nadaptable. Whilst this has been the consensus for a while, various factors such\\nas bureaucracy, lack of capacity, authority/ownership, budget or simply lack of\\nprioritization have hindered the adoption and implementation of such\\ntechnologies.\\n\\nHowever, the COVID-19 pandemic has brought digital health systems back to the\\ntop of the agenda, having forced governments to adapt their health systems and\\nprocesses in a short amount of time and confronted them with the fragility and\\ninflexibility of some of their existing systems. This has led to an increase in\\nfunding for both new and existing health technologies.\\n\\nAt the same time, the recent pandemic also saw an increase in data breaches and\\ndata leaks in the healthcare sector. Whilst these are a serious matter in any\\nsystem, the nature of the healthcare technologies means that the data they are\\nstoring or managing almost always includes Personally Identifiable Information\\n(PII) which, if leaked, can have dramatic consequences for those they identify.\\n\\nThe higher the number of technologies and quantity of data stored in these, the\\nhigher the risk of vulnerabilities and negative impact of a data breach or data\\nleak. If Global Goods are to make the most of this renewed interest and increase\\nin funding for digital health technologies, it is crucial for them to keep\\nsecurity as a top priority to ensure that they \u2018do no harm\u2019, a\\ncore[ Digital Public Good](https://digitalpublicgoods.net/standard/) principle.\\n\\nSeveral organizations have already put some thought into documenting security\\nbest practices and standards. However, none situate these security decisions\\nwithin the wider context of a product development timeline or roadmap. This\\nrequires individuals to regularly scan through long lists of security\\nrecommendations to pick out and prioritize their implementation, increasing the\\nlikelihood of an oversight or early-made product decisions which make it harder\\nto implement such security features down the line.\\n\\nAs product manager at Open Function Group, I myself have recently been reviewing\\nand analyzing numerous resources to identify and prioritize features required to\\nget to fully-secure authentication and authorization for our newest product\\n[Lightning](/documentation#openfn-v2-lightning-/)\u2013and make sure that nothing\\nfalls through the cracks. I\u2019ve also had the opportunity to gather insights from\\nDigital Public Good community forums (OpenMRS, DHIS2, OpenLMIS, etc) and speak\\nto other product managers and engineers from the Digital Public Goods community\\nto ask them about their learnings, and any tips they might have: Austin and\\nMorten from DHIS2, Dev and Biyeun from Dimagi.\\n\\n**To more widely share these learnings, we have drafted this resource\\ndocumenting the specific security measures that should be considered at each\\nstage of product development _specifically with regards to authentication and\\nauthorization. _**Our hope is that this article will help other product managers\\nin the Global Good (GG) and Digital Public Good (DPG) communities consider these\\nfeatures into their backlog/roadmap from the outset and make sure they are\\nfollowing a \u2018secure by design\u2019 approach. To inform our analysis, we analyzed\\nlearnings from the wider DPG community, as well as recommendations from other\\nsecurity experts and international standards, including GovStack, OpenHIE,\\nOWASP, NIST, and more.\\n\\n**The resource can be found\\n[here](https://docs.google.com/document/d/1QvOcOdk2iZCWnAVNiBbmhh-6Q2gapUhsMCUzJQNWqEU/edit?usp=sharing).**"},{"id":"/2022/06/07/workflow-automation","metadata":{"permalink":"/articles/2022/06/07/workflow-automation","editUrl":"https://github.com/openfn/docs/edit/main/articles/2022-06-07-workflow-automation.md","source":"@site/articles/2022-06-07-workflow-automation.md","title":"Workflow Automation; Why do it yourself when a program can do it for you?","description":"Do you think twice when you get an automatic SMS notification because your","date":"2022-06-07T00:00:00.000Z","tags":[{"inline":true,"label":"automation","permalink":"/articles/tags/automation"},{"inline":true,"label":"solution","permalink":"/articles/tags/solution"}],"readingTime":5.9,"hasTruncateMarker":true,"authors":[{"name":"Alexa de Vegvar","key":"alexa","page":null}],"frontMatter":{"layout":"post","title":"Workflow Automation; Why do it yourself when a program can do it for you?","authors":"alexa","tags":["automation","solution"],"image":"https://user-images.githubusercontent.com/105651463/172341536-ebde5ca0-12b8-4a8a-bb40-da9442701df3.png","featured":false},"unlisted":false,"prevItem":{"title":"Secure by design: a roadmap to secure authentication and authorization","permalink":"/articles/2022/09/19/auth-security"},"nextItem":{"title":"How learning JavaScript helps me better understand OpenFn jobs","permalink":"/articles/2021/10/29/how-learning-javascript-helped-me-better-understand-jobs"}},"content":"Do you think twice when you get an automatic SMS notification because your\\nprescription is ready? (Neither do I.) This seamless experience is driven by\\n\u201cworkflow automation\u201d, a key feature that OpenFn provides. The OpenFn\\nIntegration Toolkit is a Digital Public Good (DPG) used by governments and NGOs\\nto boost efficiency through workflow automation. The automation that OpenFn\\nprovides includes automatically sending SMSs, automating stock updates across\\nsupply chain systems, tracking clinical visits, and helping plan vaccine\\nrollouts. We support our partners\u2019 work by lifting the burden of manual data\\ntransfers between platforms.\\n\\n\x3c!--truncate--\x3e\\n\\n:::note\\n\\nThis article\\n[originally appeared](https://www.linkedin.com/pulse/workflow-automation-why-do-yourself-when-program-can-you-openfn/?trackingId=TnWiYNtf5QP4GfAj6R4meQ%3D%3D)\\nas a LinkedIn article from Open Function Group.\\n\\n:::\\n\\n## What is workflow automation?\\n\\nWorkflow automation is an approach to making the flow of tasks across platforms\\nrun independently. A prescription SMS notification feels seamless, but it\\nprobably requires complex automation across multiple systems like clinical\\nregistries, pharmacy stock databases, and SMS gateways. Tools like OpenFn run\\n\u201cbehind the scenes\u201d to perform calculations and transfer relevant data to/from\\ndifferent systems autonomously, minimising the risk of human error and\\nultimately saving time and money that an agency would spend on manual data\\ntransfers. The goal is to preserve data integrity, uphold data security, and\\nenforce compliance with policies and data standards.\\n\\nSince 2014, OpenFn has been at the forefront of workflow automation in the\\nsocial sector, providing a platform to help governments and NGOs focus on the\\nhuman aspect of their work rather than wasting time trying to exchange data\\nbetween systems or perform calculations manually.\\n\\n### MyAgro\\n\\n[MyAgro](https://www.myagro.org/), an NGO helping West African farmers increase\\ntheir yield, uses OpenFn to power its SMS-based savings deposit system for\\nsmall-scale farmers. MyAgro distributes and tracks saving vouchers using the\\n[CommCare](https://www.dimagi.com/commcare/) app. Smallholder farmers purchase\\npre-paid myAgro saving scratch cards and text the one-time code to secure the\\nvoucher credit in their account. Once the amount has been added to their\\nbalance, a confirmation notification is sent to the farmer. MyAgro works with\\nthe farmers to reach their savings goal, which they then use to pay for seeds,\\nfertilisers, and training courses. OpenFn:\\n\\n<p align=\\"center\\">\\n  <img src=\\"https://user-images.githubusercontent.com/105651463/172341045-62a3eebd-98fb-4189-987f-06bbdb03ac30.png\\" />\\n</p>\\n\\n1. Syncs voucher codes from CommCare to Salesforce so the relevant offices can\\n   track who purchased the saving vouchers.\\n2. Matches incoming SMSs against the database of vouchers to deposit correct\\n   funds into the individual account.\\n3. Allocates savings to farmers\u2019 accounts in Salesforce and updates the account\\n   status.\\n4. Sends a confirmation SMS with updated account balances to farmers, so they\\n   are aware of their credit.\\n\\nOpenFn helps myAgro reach more farmers with less administrative overhead by\\nautomating these key steps. MyAgro calculated that even at their 2014 levels of\\nscale, OpenFn saved them 260+ hours per year and increased customer confidence\\nas they worked to serve poor farmers.\\n\\n### Sinapis\\n\\n[Sinapis](https://sinapis.org/), an NGO that empowers entrepreneurs through\\ntraining courses, uses OpenFn to automate its payment collection process. Every\\ntime a client\u2019s new\\n[M-Pesa](https://www.vodafone.com/about-vodafone/what-we-do/consumer-products-and-services/m-pesa/globalmerchants)\\npayment is registered in [Kopo Kopo](https://kopokopo.co.ke/), OpenFn:\\n\\n<p align=\\"center\\">\\n  <img src=\\"https://user-images.githubusercontent.com/105651463/172341175-5505b647-93dc-44af-9143-00ebdd0b5bae.png\\" />\\n</p>\\n\\n1. Automatically matches incoming payments with existing Sinapis accounts.\\n2. Logs new payments and updated payment status in Salesforce to track\\n   entrepreneurs\u2019 charges.\\n3. Updates account balances to help staff monitor outstanding balances and\\n   overdue fees.\\n\\nWith OpenFn handling the routine data processing, Sinapis has more time to\\nsupport its entrepreneurs. Precious staff time can be spent delivering training,\\nthe essential face-to-face coaching that transforms their clients\u2019 fledgling\\nenterprises. Their team does not have to worry about the accuracy of payments\\nand account balances; the OpenFn implementation replaces error-prone manual data\\nentry with a systematised, intelligible, fully automated process.\\n\\n### DIAL\\n\\nThe [Digital Impact Alliance (DIAL)](https://digitalimpactalliance.org/), an\\norganisation that works to overcome digital development barriers, wanted to\\nprototype a \u201cbuilding-blocks based approach\u201d for their upcoming GovStack.global\\nproject. They configured an HR workflow solution that connects mobile data\\ncollection apps, databases, and payment apps using OpenFn. Every time an\\norganisation registers new workers via\\n[ODK Collect](https://docs.opendatakit.org/collect-intro/), OpenFn:\\n\\n<p align=\\"center\\">\\n  <img src=\\"https://user-images.githubusercontent.com/105651463/172341214-06a1e74b-c1e3-45e4-83c8-4a60af5a9d2d.png\\" />\\n</p>\\n\\n1. Automatically registers new employees in an [iHRIS](https://www.ihris.org/)\\n   database to oversee all new hires.\\n2. Makes payments to workers via\\n   [Mifos](https://www.google.com/aclk?sa=l&ai=DChcSEwicha-ltsnnAhUB1N4KHY8hDEoYABAAGgJ3Yg&sig=AOD64_27g900G2RtoQsW0km9iT4Oq262ag&q=&ved=2ahUKEwj8wKeltsnnAhVSxYUKHVcrBbUQ0Qx6BAgMEAE&adurl=),\\n   ensuring all wage transfers are direct.\\n\\nWhile it\u2019s not in use at scale, this prototype is a powerful illustration of how\\nautomation enables scalable, component-based solutions to become more than the\\nsum of their parts. The processes that DIAL implement with OpenFn help unlock\\nthe true potential of these powerful underlying DPGs.\\n\\n## What\u2019s the big picture here?\\n\\nOpenFn\u2019s goal is to increase the efficiency and effectiveness of the social\\nsector. Why should health and humanitarian organisations waste precious\\nresources manually moving data across systems when workflow automation can do it\\nmore safely and quickly? We want to ensure employees focus on using data to do\\ntheir work, not transferring data between systems and running rote calculations.\\n\\nSaving organisations time and money is part of the picture, but we also deliver\\nbetter program outcomes through efficiency and effectiveness. Suppose OpenFn\\nsecurely automates the complex digital processes critical health and\\nhumanitarian interventions require. Reducing error rates and security\\nvulnerabilities and getting higher quality data into the hands of a doctor\\nfaster actually saves lives. Responsible automation leads to better health and\\nhumanitarian outcomes, enabling larger-scale intervention delivery via\\nefficiency gains and improving service quality by getting accurate data into the\\nhands of patients, clinicians, and policymakers when they need it.\\n\\n## Call to Action\\n\\nThink about your own experiences; have you found yourself in a situation where\\nmanual data processing\u2014some rote, mindless task\u2014has gotten in the way of doing\\nthe more exciting parts of your job? Whether you are in the health and\\nhumanitarian space or just want to make your life easier, OpenFn is here for\\nyou. Our open-source toolkit is available for everyone to automate tasks such as\\nsending SMS and email notifications or automating data cleaning and formatting\\nfor faster reporting.\\n\\nHead to [docs.openfn.org](http://docs.openfn.org/) to learn more about\\nenterprise-grade automations with our DPG and check out\\n[community.openfn.org](http://community.openfn.org/) to connect and collaborate\\nwith like-minded social-sector integrators and OpenFn staff. We hope to see you\\nsoon!\\n\\n## About Open Function Group\\n\\nOpen Function Group (OFG) is a global team of integration specialists and\\ndevelopers of the OpenFn Integration Toolkit. As a\\n[DPG](https://digitalpublicgoods.net/), OpenFn\u2019s core technology is free and\\nopen-source. If you want more information about the Toolkit or to sign up for a\\nfree plan on our associated SaaS application, visit https://www.openfn.org/."},{"id":"/2021/10/29/how-learning-javascript-helped-me-better-understand-jobs","metadata":{"permalink":"/articles/2021/10/29/how-learning-javascript-helped-me-better-understand-jobs","editUrl":"https://github.com/openfn/docs/edit/main/articles/2021-10-29-how-learning-javascript-helped-me-better-understand-jobs.md","source":"@site/articles/2021-10-29-how-learning-javascript-helped-me-better-understand-jobs.md","title":"How learning JavaScript helps me better understand OpenFn jobs","description":"OpenFn automation happens via jobs which","date":"2021-10-29T00:00:00.000Z","tags":[{"inline":true,"label":"javascript","permalink":"/articles/tags/javascript"},{"inline":true,"label":"tips","permalink":"/articles/tags/tips"},{"inline":true,"label":"jobs","permalink":"/articles/tags/jobs"},{"inline":true,"label":"learning","permalink":"/articles/tags/learning"}],"readingTime":7.16,"hasTruncateMarker":true,"authors":[{"name":"Aicha Diallo","socials":{"github":"https://github.com/daissatou2"},"imageURL":"https://avatars.githubusercontent.com/daissatou2","key":"aicha","page":null}],"frontMatter":{"layout":"post","title":"How learning JavaScript helps me better understand OpenFn jobs","authors":"aicha","tags":["javascript","tips","jobs","learning"],"featured":true},"unlisted":false,"prevItem":{"title":"Workflow Automation; Why do it yourself when a program can do it for you?","permalink":"/articles/2022/06/07/workflow-automation"},"nextItem":{"title":"Testing a React app, the blurred line between Unit, integration and E2E","permalink":"/articles/2021/10/22/testing-react-app-with-jest-hound"}},"content":"OpenFn automation happens via [jobs](/documentation/build/workflows) which\\ndefine specific steps (\\"operations\\") that OpenFn should perform. They\'re written\\nin a basic scripting language that runs on top of (and has full access to)\\n**Javascript**. A basic understanding of Javascript will take your job writing\\non OpenFn to the next level. To improve my limited knowledge of JavaScript, I\\nhave been taking Codecademy\'s\\n[Introduction to JavaScript Course](https://www.codecademy.com/learn/introduction-to-javascript).\\n\\n\x3c!--truncate--\x3e\\n\\nIn this post we\'ll discuss:\\n\\n1. Arrow functions\\n2. Falsy values\\n3. Other short-hand notation\\n\\nKeep reading for all the important learnings I have taken from just the first\\nfour modules!\\n\\n## What is that little `=>` arrow?\\n\\nJavascript allows us to create _functions_ which take _arguments_ and _do stuff_\\nwith them. Most times, function declaration in Javascript looks like this:\\n\\n```js\\nfunction getAge(dateString) {\\n  if (!dateString) return;\\n\\n  const today = new Date();\\n  const birthDate = new Date(dateString);\\n  var age = today.getFullYear() - birthDate.getFullYear();\\n  var m = today.getMonth() - birthDate.getMonth();\\n  if (m < 0 || (m === 0 && today.getDate() < birthDate.getDate())) {\\n    age--;\\n  }\\n  return age;\\n}\\n```\\n\\nThis was simple enough for me to follow. We are declaring a function,\\n`getAge()`, which has the steps to calculate a person\'s age and can be easily\\nreused throughout the job.\\n\\nBut other times, function writing looks like this:\\n\\n```js\\nconst getAge(dateString) => {\\n  if (!dateString) return;\\n  // and so on...\\n}\\n```\\n\\nIn OpenFn, you\'re often writing unnamed functions that take `state` as their\\nonly argument and you use them right away. See how concise writing and using a\\nfunction can be with the arrow:\\n\\n```js\\nupsert(\'tbl_study\', \'study_id\', {\\n  study_id: state => state.studyIDMap[state.formType],\\n});\\n```\\n\\nThese **`arrow functions`** confused me when reading through jobs. I\'ve learned\\nthat, for the most part, they can be thought of as short-hand notation which\\nremoves the need to type out `function` for every function declaration.\\n\\n:::tip\\n\\nMDN has a great explanation\\n[here](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Functions/Arrow_functions).\\nTl;dr: \\"An arrow function expression is a compact alternative to a traditional\\nfunction expression, but is limited and can\'t be used in all situations.\\"\\n\\n:::\\n\\nFurther, we can make the code even more concise by also removing the\\nparenthesis, curly braces, and the return keyword when certain criteria are met.\\nIn the code above, the parenthesis are omitted because there are no parameters,\\nand the curly braces and return keyword are omitted because the function body is\\ncomposed of a single-line block. As you can see, there are a variety of ways to\\nwrite functions and this course is helping me better recognize them. Some key\\nterminology here is: `function expression`, `arrow function`,\\n`concise function`, `anonymous function`, and `implicit returns`.\\n\\n## Falsy values\\n\\nDuring the [mapping](/adaptors/salesforce/#mapping-and-design-considerations)\\nphase of integration design, we often discuss how each answer choice for\\n**picklist** values should map from the source system to the destination system.\\nSometimes the mapping is simple but other times, there is an extensive list of\\npossible choices that can be found in the\\n[message](/documentation/get-started/terminology/#message) and not all are\\nrelevant to the destination system. Then the question is, **how should the job\\nhandle values which are not explicitly mapped?**\\n\\nSometimes we hear clients say to \\"ignore\\" those values. **But what does it\\nreally mean to \\"ignore\\" a value?** Should we set it to `0`? An empty string? How\\nabout `null`, `undefined` or `NaN`? In Javascript these are all `falsy` values.\\n\\n:::tip\\n\\nMDN is great for falsy values too! Check their explanation out\\n[here](https://developer.mozilla.org/en-US/docs/Glossary/Falsy).\\n\\n:::\\n\\nDetermining what is really meant here is important and the value selected has\\ndifferent implications depending on the system.\\n\\nTake this sample mapping for different districts in Conakry. The value left of\\nthe colon is from the source system and the value to the right is for the\\ndestination system.\\n\\n```javascript\\nconst districtMapping = {\\n  Ratoma: \'RT\',\\n  Kaloum: \'KL\',\\n  Dixinn: \'DX\',\\n  Matam: \'MA\',\\n  Matoto: \'MT\',\\n  Other: undefined,\\n};\\n```\\n\\nIf the destination system is Salesforce, this mapping would not upload \\"Other\\"\\nto Salesforce. However if \\"Other\\" mapped to an empty string instead, this would\\nupload the empty string to Salesforce. **This distinction is especially\\nimportant in cases where we are overwriting existing data.** For instance, if a\\nstudent previously lived in Ratoma and then moved to an unknown district marked\\nas \\"Other\\", `undefined` _would not_ update the student\'s district in Salesforce\\nbut the empty string would. Both of these are falsy values but have different\\nmeanings in Salesforce.\\n\\nHow about if the message includes a value for a district that _is not_ in the\\nmapping? Such as \\"New York\\". Should the job default to `undefined`? Or `null`?\\n\\nThese questions are just a few examples of how understanding `falsy` values in\\nJavascript can make it easier to implement the best mapping for the real-world\\nuse case.\\n\\n## Short-circuit evaluation, template literals, and all the short hand that used to confuse me\\n\\n**Short-circuit evaluation**\\n\\nWhen we are syncing forms to a database, we sometimes expect different versions\\nof the same form with fields present one version but not the other. One way to\\nmitigate this discrepancy is by submitting a dummy value for the field whenever\\nit is missing in the message. I just learned the fastest way to add this code to\\nmy jobs! For example, the code below will ensure that `household_id` always has\\na value in the destination system: if `survey_info/household_id` is present in\\nthe message this will be the assigned value, otherwise it will assign the dummy\\nvalue `state.data.body._id`.\\n\\n```js\\nhousehold_id: state.data.body[\'survey_info/household_id\'] || state.data.body._id,\\n```\\n\\n**Template literals**\\n\\nLike the arrow discussed above, the \\"dollar sign\\" was another symbol that often\\nconfused me. But template literals are actually very straightforward. They\\nincrease the readability of the code and make it easier to see what the\\nresulting string will be. Wrap your template in the backtick (\\\\`) symbols and\\nthen each variable in `${}`.\\n\\n```js\\nconst sign = \'$\';\\nconsole.log(`The ${sign} isn\'t so confusing!`);\\n```\\n\\n## Higher-order functions & iterators\\n\\nThe most challenging module in the course covered **higher-order functions**.\\nThese are defined as **functions that accept other functions as arguments and/or\\nreturn functions as output.** But why are these important and how are they used\\nin OpenFn jobs? It turns out we use them quite alot! The code below is an\\nexample from an existing integration with the field names replaced.\\n\\n```js\\nconst participantsToUpdate = state.data.json.filter(data =>\\n  state.idList.includes(data.id)\\n);\\nconst participantsToCreate = state.data.json.filter(\\n  data => !state.idList.includes(data.id)\\n);\\n```\\n\\nThis code is using a built-in JavaScript method that **helps us iterate on\\narrays to manipulate elements and return values.** The `.filter()` method is\\nbeing used to return a new array after filtering out certain elements from the\\noriginal array. We have declared two variables to store the new arrays:\\n`participantsToUpdate` and `participantsToCreate`. Participants whose ids are\\nexisting in the destination system (or who are in the `idList` array) are added\\nto `participantsToUpdate`, and any remaining participants are added to\\n`participantsToCreate`. This filtering helped us perform the correct operations\\non each participant type. For instance, later in the job, we use the filtered\\narrays to only overwrite a participant\'s `reportNumber` field if it is a new\\nparticipant. `.filter()` is just one of many higher-order functions that power\\nOpenFn jobs.\\n\\n## Objects & job mappings\\n\\nThe final lesson was on objects and key-value pairs--something used in almost\\nevery OpenFn job! The result of the design and mapping phase of requirements\\ngathering is almost always a mapping document which includes key-value pairs in\\nplain English. These specifications are then translated to JavaScript via\\n**_objects_**. The code below is a snippet of an object which captures the\\nkey-value pairs for states in the US.\\n\\n```js\\nconst stateMapping = {\\n   AK: \'ALASKA\',\\n   AZ: \'ARIZONA\',\\n   AR: \'ARKANSAS\',\\n   CA: \'CALIFORNIA\',\\n   ....\\n```\\n\\nThe value left of the colon is how the state is represented in the source\\nsystem, and the value right of the colon represents how OpenFn will send the\\ndata to the destination system. This mapping process is key to integration\\ndesign. Learn more about mappings\\n[here](/adaptors/salesforce/#mapping-and-design-considerations).\\n\\n:::tip\\n\\nMDN has more details on objects\\n[here](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object).\\nTl;dr: \\"The Object class represents one of JavaScript\'s data types. It is used\\nto store various keyed collections and more complex entities.\\"\\n\\n:::\\n\\n## Next steps\\n\\nI\'m well on my way to becoming a better job reader and writer. Here are some\\nnext steps:\\n\\n1.  Understand `fn(state)` and how `state` can be manipulated in OpenFn jobs.\\n\\n2.  Explore what\'s available on the JavaScript docs\\n    [site](https://developer.mozilla.org/en-US/docs/Web/JavaScript).\\n\\n3.  Sign up for the next level JavaScript course."},{"id":"/2021/10/22/testing-react-app-with-jest-hound","metadata":{"permalink":"/articles/2021/10/22/testing-react-app-with-jest-hound","editUrl":"https://github.com/openfn/docs/edit/main/articles/2021-10-22-testing-react-app-with-jest-hound.md","source":"@site/articles/2021-10-22-testing-react-app-with-jest-hound.md","title":"Testing a React app, the blurred line between Unit, integration and E2E","description":"Have you ever struggled to layout the strategy for testing your React App? Well,","date":"2021-10-22T00:00:00.000Z","tags":[{"inline":true,"label":"how-to","permalink":"/articles/tags/how-to"},{"inline":true,"label":"tips","permalink":"/articles/tags/tips"},{"inline":true,"label":"testing","permalink":"/articles/tags/testing"},{"inline":true,"label":"browser-testing","permalink":"/articles/tags/browser-testing"},{"inline":true,"label":"react","permalink":"/articles/tags/react"},{"inline":true,"label":"elixir","permalink":"/articles/tags/elixir"}],"readingTime":7.95,"hasTruncateMarker":true,"authors":[{"name":"Chaiwa Berian","socials":{"github":"https://github.com/chaiwa-berian"},"imageURL":"https://avatars.githubusercontent.com/u/7937584?v=4","key":"chaiwa","page":null}],"frontMatter":{"layout":"post","title":"Testing a React app, the blurred line between Unit, integration and E2E","authors":"chaiwa","tags":["how-to","tips","testing","browser-testing","react","elixir"],"featured":true},"unlisted":false,"prevItem":{"title":"How learning JavaScript helps me better understand OpenFn jobs","permalink":"/articles/2021/10/29/how-learning-javascript-helped-me-better-understand-jobs"},"nextItem":{"title":"Moving from Webpack to esbuild on Phoenix","permalink":"/articles/2021/10/15/webpack-to-esbuild-part1"}},"content":"Have you ever struggled to layout the strategy for testing your React App? Well,\\nyou are not alone! Here a few hints from the lessons I learned during my\\nexperience testing a\\n[React](https://reactjs.org/)/[Redux](https://redux.js.org/) app with a\\n[Phoenix](https://www.phoenixframework.org/)/[Elixir](https://elixir-lang.org/)\\nbackend.\\n\\n\x3c!--truncate--\x3e\\n\\n## The Blurred Line\\n\\nBecause a React app is built on\\n[components](https://reactjs.org/docs/react-component.html), the basic UI units,\\nit is natural to think and organise your tests around components! And so unit\\ntesting, in this case, would refer to \\"component testing\\", which may be\\nconfusing at times, especially when the concept of unit testing is again applied\\nto testing functions such as Redux `reducers` and `action creators` or any other\\nJavaScript function in your application.\\n\\nThe other challenge that I often faced was whether to write tests for each\\ncomponent in isolation or write a test for a feature that encapsulates a set of\\nrelated components. The later would be equivalent to writing what I would call\\n\\"integration tests\\".\\n\\nFinally, one would say \\"well then you could have just written the tests in a way\\nthat resemble the way the application is used\\"! This approach is commonly\\nrecommended in the React community, but it quickly becomes really complex to\\nmaintain the layers of separation between **_unit tests_**, **_integration\\ntests_** and **_end-to-end tests_**.\\n\\n## What did I learn?\\n\\nGiven a React/Redux application, here is how I would organise my testing\\nstrategy:\\n\\n### Unit Tests\\n\\n- In a React app, **unit tests** will largely apply to testing \\"helper\\n  functions\\" and not to testing components, as justified in the next section.\\n  Helper functions, in this case, would refer to functions that live outside the\\n  components and are neither Redux action creators nor reducers. These functions\\n  can be used inside components, action creators, reducers or other parts of\\n  your application.\\n\\n- Writing unit tests for \\"helper functions\\" would ensure their signatures and\\n  expected outputs are protected against regressions. This would also ensure\\n  their use across components or other functions is consistent and as expected.\\n\\n- Where possible, each \\"helper function\\" must have its own `unit test`.\\n\\n- An example of a unit test would like:\\n\\n  ```javascript\\n  const sum = require(\'../../js/sum\');\\n\\n  test(\'adds 1 + 2 to equal 3\', () => {\\n    expect(sum(1, 2)).toBe(3);\\n  });\\n  ```\\n\\n- Write a _thousand_ of these.\\n\\n### Integration Tests\\n\\n- In the context of a React/Redux app, component tests can be thought of as\\n  **integration tests**. This is because React components are built around\\n  features such as `<Signup />`, `<Search />`, etc. So one React component can\\n  be a mix of other components to achieve a UI feature set.\\n\\n- To test a component, write an **integration test** that covers the use of a\\n  given component for a given UI feature.\\n\\n- If a component being tested dispatches a Redux `action`, this is the right\\n  place to test those actions and their effect on the UI.\\n\\n- Pay attention to the concept of _feature isolation_ vs _component isolation_\\n  as it will help you write better integration tests and also easily mock\\n  component contexts.\\n\\n- A classic example of **feature isolation** is when you have a `<UserList />`\\n  component which displays a list of users and has a `<button />` to add a new\\n  user. Writing a test for `<UserList />` would be equivalent to testing a\\n  feature.\\n\\n- In this example, one would be tempted to test the action of clicking on the\\n  `<AddUserButton />` and further test the `<NewUser />` form... nope! This is\\n  where we draw the line! Only test that the `<UserList />` renders the mock\\n  `users` in the list and that the `<AddUserButton />` is present/enabled. The\\n  `<UserList />` feature ends there, otherwise you will be sliding into\\n  **End-to-End** testing :)! The `<User />` component, although it is invoked by\\n  `<UserList />` component, it is isolated enough to be tested in its own\\n  integration test.\\n\\n- Testing components this way would make \\"context mocking\\" easier for\\n  components.\\n\\n- Another important benefit for isolating testing context, as in the example\\n  above, is that it will be easier to mock the `redux actions` and/or api calls\\n  using tools such as [Jest](https://jestjs.io/) and\\n  [Mock Service Worker](https://mswjs.io/) (or \\"msw\\") as explained in the\\n  [Choosing Tools](#choosing-testing-tools) section.\\n\\n- The value of writing integration tests for components, in this way, ensures\\n  that a given component renders the UI consistently, given all possible\\n  combinations of contexts and interactions. This will also allow you to ensure\\n  redux actions invoked by the component are called as expected and with the\\n  correct arguments.\\n\\n- An example component integration test would look like:\\n\\n  ```javascript\\n  // ....other imports\\n  import { setupServer } from \'msw/node\';\\n  // Tell jest to mock the module\\n  jest.mock(\'../js/actions/UserActions\', () => ({\\n    ...jest.requireActual(\'../js/actions/UserActions\'),\\n    saveUser: jest.fn(),\\n  }));\\n\\n  import { saveUser as mockSaveUser } from \'../js/actions/UserActions\';\\n  const server = setupServer(...handlers);\\n    // Enable API mocking before tests\\n    beforeAll(() => server.listen());\\n    // Reset any runtime handlers we may add during the tests\\n    afterEach(() => server.resetHandlers());\\n    // Disable API mocking after the tests are done.\\n    afterAll(() => server.close());\\n    beforeEach(() => {\\n      jest.clearAllMocks();\\n    });\\n  describe(\'<AddUser/>\', () => {\\n\\n  test(\'create new user\', async () => {\\n      const {getByPlaceholderText,getByText} = render(<User {...defaultProps} />);\\n      userEvent.type(getByPlaceholderText(\'First Name\'), \'John\');\\n      userEvent.type(getByPlaceholderText(\'Last Name\'), \'Doe\');\\n      userEvent.click(getByText(\'Save\'));\\n      expect(mockSaveUser).toHaveBeenCalledTimes(1);\\n      expect(mockSaveUser).toHaveBeenCalledWith({\\n        firstName: \'John\',\\n        lastName: \'Doe\',\\n      });\\n  }\\n\\n  ```\\n\\n- Write a _good couple_ of these.\\n\\n### End-to-End (e2e) Tests\\n\\n- In a React/Redux App, this would mean testing a _full flow_ of a given\\n  feature. **end-to-end tests** would require launching the entire application,\\n  including the backend, to run a given test.\\n\\n- Note that **end-to-end tests** are different from **integration tests** as\\n  they require the entire App to run and render the full flow to your component\\n  under test.\\n\\n- With this understanding, consider writing **e2e** tests _per workflow_.\\n\\n- An example **e2e workflow** is the \\"Viewing and adding users\\" workflow.\\n\\n- The e2e test for this workflow would require a test runner to launch the app,\\n  log-in, navigate to the users list page, verify existing users are in the\\n  list, click on the Add New User button and confirm that the new user has been\\n  added to the list.\\n\\n- As you can see, e2e tests have more dependencies and require that you setup\\n  your testing environment in way that closely simulates your real application\\n  usage.\\n\\n- An example e2e test for a React/Redux App with a Phoenix/Elixir backend, using\\n  `Hound` as a test runner looks like this:\\n\\n```elixir\\ndefmodule OpenFn.UsersTest do\\n  setup do\\n    user = insert(:user, confirmed_at: DateTime.utc_now())\\n    {:ok, user: user }\\n  end\\n\\n  @tag :integration\\n  test \\"Sign-up.\\", %{user: user} do\\n    navigate_to(\\"/sign-up\\")\\n    form = find_element(:id, \\"sign_up_form\\")\\n\\n    form\\n    |> find_within_element(:id, \\"first-name\\")\\n    |> fill_field(\\"John\\")\\n\\n    form\\n    |> find_within_element(:id, \\"last-name\\")\\n    |> fill_field(\\"Doe\\")\\n\\n    form\\n    |> find_within_element(:id, \\"email\\")\\n    |> fill_field(\\"doe@gmail.com\\")\\n\\n    form\\n    |> find_within_element(:id, \\"save-button\\")\\n    |> click\\n\\n    assert page_title() === ~s/Welcome to my page/\\n    end\\nend\\n```\\n\\n- Write _only a few_ of these.\\n\\n## Choosing Testing Tools\\n\\nThere are many testing tools out there, but for a typical _React/Redux_ app the\\nfollowing tools should help you accomplish the above tasks:\\n\\n1. [Jest](https://jestjs.io/docs/getting-started) as test runner for **unit**\\n   and **integration** tests.\\n2. [React Testing Library](https://testing-library.com/docs/) used along with\\n   Jest as an \\"assertion library\\" for integration tests.\\n3. [MSW](https://mswjs.io/docs/getting-started/install) used along with Jest as\\n   a REST API mocking library.\\n4. [Hound](https://hexdocs.pm/hound/readme.html) as a test runner for **e2e**\\n   tests in Elixir/Phoenix apps.\\n   [Puppeteer](https://developers.google.com/web/tools/puppeteer) can also be\\n   used along with Jest.\\n   - If Puppeteer is used, it will work seamlessly with Jest but only in\\n     headless browser mode. It also reduces on tech stack since you will only\\n     need Jest.\\n   - Hound gives you the ability to run your **e2e** tests both in `headless`\\n     and `browser` mode.\\n\\n## Final thoughts and next steps\\n\\nTesting a React App can be really hard, but worth it! By building\\n`Aria-accessible` components ahead of time, you save yourself \ud83d\udcb0 and good\\nhealth! A few more hints would be:\\n\\n- Build clean, isolated and plugable components for your better testing\\n  experience. \\"God components\\" can be a _pain_ to test!\\n- Using test runners such as Jest, that use _emulated_ web browsers (e.g.,\\n  `jsdom`) rather than a real browser come with their own challenges in\\n  rendering and traversing complex DOM trees, especially if you are using UI\\n  libraries such as [MUI](https://mui.com/).\\n- If using Jest for **integration tests**, I would recommend the components\\n  under test have as few dependencies as possible to avoid the complexity\\n  involved in mocking http requests and waiting for asynchronous DOM rendering.\\n\\nWhat would I do differently? Here are my few thoughts:\\n\\n- Organise and document detailed test cases for manual \\"click testing\\".\\n- Identify and clearly isolate components for **integration tests**.\\n- Do not _delete_ slow tests, instead re-write your component to be faster.\\n  Respect the linter\'s advice, always!\\n- Use a commonly supported frontend testing stack such as Jest, Msw, or\\n  Puppeteer for easier setup and community support.\\n- Setup your test runner to use a test database. It helps, especially during\\n  **e2e** testing.\\n- Always write **_all the three types_** of tests, whenever applicable.\\n\\nAll this stuff for what?\\n\\n- Well because regressions can be much more expensive to your organisation!\\n  Writing high quality and thoroughly tested software will save you \ud83d\udcb0 and help\\n  guarantee a maintainable codebase and a progressive software application.\\n\\n:::tip Still looking for the legend\'s advice?\\n\\nGotcha, here you go...\\n\\n1. Swallow your pride and be humble: _always_ do **manual testing!**\\n2. Click test your way through the **manual test cases** for every new\\n   deployment, catching regressions.\\n3. _Lock in_ your fixes and new features as **unit tests**, **integration\\n   tests**, and **end-to-end tests**.\\n\\n:::\\n\\nHappy testing,\\n\\nChaiwa"},{"id":"/2021/10/15/webpack-to-esbuild-part1","metadata":{"permalink":"/articles/2021/10/15/webpack-to-esbuild-part1","editUrl":"https://github.com/openfn/docs/edit/main/articles/2021-10-15-webpack-to-esbuild-part1.md","source":"@site/articles/2021-10-15-webpack-to-esbuild-part1.md","title":"Moving from Webpack to esbuild on Phoenix","description":"We\'re very happy users of Elixir and Phoenix at OpenFn, given that we\'ve been","date":"2021-10-15T00:00:00.000Z","tags":[{"inline":true,"label":"how-to","permalink":"/articles/tags/how-to"},{"inline":true,"label":"js","permalink":"/articles/tags/js"},{"inline":true,"label":"webpack","permalink":"/articles/tags/webpack"},{"inline":true,"label":"build","permalink":"/articles/tags/build"},{"inline":true,"label":"phoenix","permalink":"/articles/tags/phoenix"},{"inline":true,"label":"ci/cd","permalink":"/articles/tags/ci-cd"}],"readingTime":6.63,"hasTruncateMarker":true,"authors":[{"name":"Stuart Corbishley","socials":{"github":"https://github.com/stuartc"},"imageURL":"https://avatars.githubusercontent.com/stuartc","key":"stu","page":null}],"frontMatter":{"layout":"post","title":"Moving from Webpack to esbuild on Phoenix","authors":"stu","tags":["how-to","js","webpack","build","phoenix","ci/cd"],"featured":true},"unlisted":false,"prevItem":{"title":"Testing a React app, the blurred line between Unit, integration and E2E","permalink":"/articles/2021/10/22/testing-react-app-with-jest-hound"},"nextItem":{"title":"Improving Multistage Docker Builds using Buildx","permalink":"/articles/2021/10/08/improving-multistage-docker-builds-using-buildx"}},"content":"We\'re very happy users of Elixir and Phoenix at OpenFn, given that we\'ve been\\nusing it continuously for about 6 years - upgrades and all. Our front-end\\ntoolchain, albeit far from out of date (Webpack `5.52.1` today) has left some\\nroom for improvement.\\n\\n\x3c!--truncate--\x3e\\n\\n> This is a post written on what we call \'Slow Fridays\', where we explore and\\n> think about stuff we\'re curious about. The deal is some artifact at the end of\\n> the day. So while this post is not complete - I believe part two is warranted.\\n\\nPhoenix 1.6 started to include esbuild by [default](#ref1). The main reasons\\ncited were the amount of support the team had to continuously give for a\\ntoolchain that although necessary is not under the control of the framework\\nteams control.\\n\\nBack in the day, Phoenix used brunch to do front end builds - despite not being\\nthe most common bundler at the time. The objective I assume was to provide\\nsomething that is easy to get going with and lowers the barrier to entry for\\nPhoenix. We actually switched brunch out for webpack before webpack got into\\nPhoenix in order to more easily use new libraries and newer ES syntax.\\n\\nIt wasn\'t without its challenges, and still is. Webpack is wonderfully\\npowerful - but it does do _a lot_, and it\'s really easy to stumble onto plugins\\nthat are either order dependent or mutually exclusive.\\n\\n## So what\'s this about esbuild\\n\\nIt\'s a bundler/compiler for JS/TS projects that is written in Go, along with\\nbeing faster by the simple fact it\'s natively compiled it also leverages\\nconcurrency. To compare _why_ esbuild is faster than NodeJS on face value is\\nunfair in my opinion. Although having similar objectives, they are wildly\\ndifferent in implementation and in features.\\n\\nSo **speed** is the big selling point. But thinking back to other bundlers, what\\nmade us switch (thinking of gulp, grunt, mixing in babel, browserify etc). Those\\nchanges were never about speed, at least a drop in build time was nice - a bit of\\ncaching goes a long way. The changes were about being able to use the syntax and\\nlibraries we wanted with as little fuss as possible.\\n\\nWebpack _can_ do almost anything. I\'m not convinced esbuild can match that, and\\nas an open-source maintainer I\'d argue it shouldn\'t break its original goals to\\nmatch Webpack.\\n\\n## Exploring the caveats\\n\\nI started breaking down what our current bundle setup actually does, after all\\nif we were just bundling plain JS I\'d probably be using rollup and terser. Going\\nthrough our `webpack.config.js` file I can see that it:\\n\\n- Conditionally provide sourcemaps depending on the environment.\\n- Uses babel to parse js/jsx files  \\n  At the same time cherry picks lodash imports\\n  <a href=\\"#lodash\\"><sup>*</sup></a>.\\n- Parse `import`s for `.css` files through `style-loader` and `css-loader`  \\n  Injecting the styles onto the dom.\\n- Detect `require` statements to images, copy them to an assets folder  \\n  and replace the statement with a url to image.\\n- Can watch files (excluding `node_modules`) in development.\\n- Splits files that come from `node_modules` into a `vendor.js` bundle.\\n\\nThat\'s a lot more than just building something, there\'s some implicit behaviour\\nhere.\\n\\n- The interaction between `style-loader` and `css-loader` results in extra\\n  functions and behaviour being introduced, it\'s not producing a `.css` file.\\n  > I\'m personally not a big fan of apps injecting styles, but I think I get why\\n  > people do it. Maybe I\'m old-school and like to have my stylesheets delivered\\n  > in a few files (or even one).\\n- The splitting doesn\'t know about `app.js`, it puts everything that resolves to\\n  `node_modules` in `vendor.js`. Subtle but worth pointing out.\\n\\n<a name=\\"lodash\\"><sup>*</sup></a>\\nCould probably ignore this and refactor some\\nfiles and check that tree-shaking is working properly.\\n\\n\\n## What we need esbuild to provide\\n\\nLike I mentioned before, webpack is super versatile and it would be\\nshort-sighted to get esbuild to do everything it does.\\n\\nSo I\'m approaching this with the idea that I code will need some changes, the\\nless the better - I\'ve always firmly believed the kinds of restrictions smaller\\ntools provide can make things neater and more portable.\\n\\n- \u2705 **Provide source maps**  \\n  Supported out of the box. [docs](https://esbuild.github.io/api/#sourcemap)\\n- \u2705 **Watching files**  \\n  Yup. [docs](https://esbuild.github.io/api/#watch)\\n- \ud83c\udd97 **Build our css** (and vendored css)  \\n  Compiling CSS is supported, however it doesn\'t (as far as I can tell) doesn\'t\\n  replace `style-loader` and how it injects CSS into the DOM.\\n- \u2705 **Copy image assets referenced in JS**  \\n  Indeed it can, using the `file` loader.\\n  [docs](https://esbuild.github.io/content-types/#external-file)\\n- \u2705 **Can split our files**  \\n  I picked a confusing green checkbox to illustrate that while esbuild does\\n  support file splitting - it appears to have some caveats, primarily that it\\n  only works with `esm` output files. We don\'t ship ES Modules to the browser,\\n  but seems like a good moment to try given the primary targets for our web\\n  front end getting module support in 2019 <sup><a href=\\"#esm\\">2</a></sup>.\\n\\n## Giving it a go\\n\\nI\'ve tried to go over the process as methodically as possible, after all this\\nisn\'t a new codebase nor am I alone on this. It\'s always important to understand\\nwho\'s going to be working with this, and respect the varying skill sets and\\nfocuses of our peers.\\n\\nSo we know what we want, but can any of this work? Let\'s give it a go with the\\nsimplest of steps:\\n\\n```\\n./node_modules/.bin/esbuild js/app.js --bundle --outfile=out.js                                    \\n > js/app.js:58:2: error: Unexpected \\"<\\"\\n    58 \u2502   <React.StrictMode>\\n       \u2575   ^\\n\\n1 error\\n```\\n\\nBang! Right, that one makes sense to me, it doesn\'t know what JSX is yet. I\'m\\ngonna take a wild guess and say it won\'t know about the CSS or our referenced\\nimages.\\n\\n```\\n./node_modules/.bin/esbuild js/app.js \\\\\\n        --loader:.js=jsx \\\\\\n        --loader:.png=file \\\\\\n        --loader:.jpg=file \\\\\\n        --loader:.jpeg=file \\\\\\n        --bundle \\\\\\n        --outdir=out\\n > js/marketing/ProductsList.js:53:40: error: Unexpected \\":\\"\\n    53 \u2502     const displayList = products.filter(::this.includesText);\\n       \u2575                                         ^\\n\\n > js/marketing/Banner.js:13:4: warning: Duplicate key \\"background\\" in object literal\\n    13 \u2502     background: `-webkit-linear-gradient(to left, ${theme.palette.banner.right}, ${theme.palette.banner.left})`,\\n       \u2575     ~~~~~~~~~~\\n...\\n```\\n\\nNice! Two things worth mentioning here:\\n\\n1. We\'re using some non-standard ES syntax here: `::`, let\'s replace that with\\n   the equivalent `includesText.bind(this)`.\\n2. Some duplicate keys in our theme objects, looks like a warning but worth\\n   cleaning up.\\n\\n```\\n./node_modules/.bin/esbuild js/app.js \\\\\\n        --loader:.js=jsx \\\\\\n        --loader:.png=file \\\\\\n        --loader:.jpg=file \\\\\\n        --loader:.jpeg=file \\\\\\n        --bundle \\\\\\n        --outdir=out\\n\\n  out/app.js                               8.0mb \u26a0\ufe0f\\n  out/commcare-dhis2-JKJLM3MQ.png        471.0kb\\n  ...\\n  out/app.css                             85.1kb\\n  ...and 145 more output files...\\n\\n\u26a1 Done in 651ms\\n```\\n\\nJeepers! 651ms! That\'s nuts.\\n\\nWe can see it\'s copied our images and css into the build folder. Note that we\'re\\nnot doing any bundle splitting right now and from the looks of it\\n\\n```\\n... \\\\ \\n>   --minify\\n\\n  out/app.js                               3.4mb \u26a0\ufe0f\\n  ...\\n\u26a1 Done in 611ms\\n```\\n\\nThat\'s better, wow. It\'s kinda difficult to not be amazed. For context, a\\nminified and split production build takes about 34s with webpack and that\'s on my\\ni7 desktop machine, and 197s (3+ mins) on CI/CD.\\n\\n## What\'s next?\\n\\nSo our \'can we actually do this\' seems to have gone pretty well so far. I\'m\\nreally excited about what this will give us in the end.\\n\\nBut a shell command doth not a replacement for webpack make. We still need to:\\n\\n1. Get Phoenix to use esbuild and watch our files as we work.\\n2. Ensure that our html templates serve the correct files in dev & production.  \\n   Including our CSS that is no longer injected into the DOM.\\n3. Split at least our vendored modules into their own bundle.\\n4. Make sure sourcemaps generate correctly for when we upload them to Sentry.\\n5. Have some kind of cache-busting naming scheme for production builds.\\n\\n## Resources\\n\\n- [FYI: Phoenix drops webpack and npm for esbuild](https://fly.io/blog/phoenix-moves-to-esbuild-for-assets/) <a name=\\"ref1\\"><sup>1</sup></a>\\n- [JavaScript modules via script tag](https://caniuse.com/es6-module) <a name=\\"esm\\"><sup>2</sup></a>"},{"id":"/2021/10/08/improving-multistage-docker-builds-using-buildx","metadata":{"permalink":"/articles/2021/10/08/improving-multistage-docker-builds-using-buildx","editUrl":"https://github.com/openfn/docs/edit/main/articles/2021-10-08-improving-multistage-docker-builds-using-buildx.md","source":"@site/articles/2021-10-08-improving-multistage-docker-builds-using-buildx.md","title":"Improving Multistage Docker Builds using Buildx","description":"So you\'re using docker\'s multi-stage builds and noticed that your build times","date":"2021-10-08T00:00:00.000Z","tags":[{"inline":true,"label":"how-to","permalink":"/articles/tags/how-to"},{"inline":true,"label":"docker","permalink":"/articles/tags/docker"},{"inline":true,"label":"ci/cd","permalink":"/articles/tags/ci-cd"}],"readingTime":6.5,"hasTruncateMarker":true,"authors":[{"name":"Stuart Corbishley","socials":{"github":"https://github.com/stuartc"},"imageURL":"https://avatars.githubusercontent.com/stuartc","key":"stu","page":null}],"frontMatter":{"layout":"post","title":"Improving Multistage Docker Builds using Buildx","authors":"stu","tags":["how-to","docker","ci/cd"],"featured":true},"unlisted":false,"prevItem":{"title":"Moving from Webpack to esbuild on Phoenix","permalink":"/articles/2021/10/15/webpack-to-esbuild-part1"},"nextItem":{"title":"Wrapping my head around jobs","permalink":"/articles/2021/07/05/wrapping-my-head-around-jobs"}},"content":"So you\'re using docker\'s multi-stage builds and noticed that your build times\\naren\'t nearly as quick as you expected?\\n\\n\x3c!--truncate--\x3e\\n\\nAs many teams who spend more and more time using docker, it\'s quite common to\\nget into multi-stage builds; usually resulting in significantly smaller images.\\n\\nHowever this comes with a pretty significant dilemma with caching. Even when\\nusing the `--cache-from` flag when building, docker only caches the last image.\\n\\nOne proposed solution<sup>[1](#ref1)</sup>, is to pull, build and push each\\nindividual stage. Coming with tight coupling between the shape of your\\nDockerfile and your build process/scripts.\\n\\nThe other solution uses Docker Buildx which the document describes as:\\n\\n> Docker Buildx is a CLI plugin that extends the docker command with the full\\n> support of the features provided by Moby BuildKit builder toolkit. It provides\\n> the same user experience as docker build with many new features like creating\\n> scoped builder instances and building against multiple nodes concurrently.\\n\\nWhile that sounds pretty cool, it doesn\'t really touch on caching. This actually\\ntook me a while to find out that it would in fact do caching very differently.\\nIn fact it\'s a very different experience using it, and has lots of really cool\\nfeatures that further detach you from the local docker state allowing you to\\nbuild in environments that are stateless - such as Google CloudBuild without\\nhaving to wire up some kind of persistence or file caching scheme.\\n\\n## Buildx\\n\\nWe\'re only going to scratch the surface of Buildx, and with that let\'s get the\\nabsolute minimum working; build our image locally.\\n\\n### Local Cache\\n\\nFirst things first we need to create a builder, and select it for use. This is\\nimportant as without creating a buildx builder (and setting it as the default),\\nbuildx will use the `docker` driver instead of the `docker-container` driver\\nwhich we want in order to take advantage of cache exporting.\\n\\n```\\ndocker buildx create --name mybuilder --use\\n```\\n\\n> You only need to run this once, except in the case of CloudBuild where each\\n> invocation is a new node.\\n\\n```\\ndocker buildx build \\\\\\n  --cache-from=type=local,src=/tmp/buildx-cache \\\\\\n  --cache-to=type=local,dest=/tmp/buildx-cache \\\\\\n  --load \\\\\\n  .\\n```\\n\\nWhile the `--cache-*` options aren\'t specifically required when running `build`,\\nas `buildx` does manage its own local cache (distinct from the regular docker\\ncache), it\'s there to emphasise the options that cache can be provided via the\\nCLI options.\\n\\nThis is about as close as you get to a regular docker build, with the\\nsignificant difference being that you have to specify where to cache from and\\nto.\\n\\nThe `--load` flag is to tell buildx to set the output to the local docker\\ndaemon. Without that you won\'t actually get a resulting image to run. However,\\ndepending on your use case, this could be seen as a convenience - if you\'re\\nwanting to run your tests inside your build; a resulting image isn\'t\\nparticularly useful.\\n\\n### Remote Cache\\n\\nNow comes to the part I\'m most interested in, caching in a stateless/remote\\nenvironment. Multipart builds for us at OpenFn are essential, since we use\\nElixir and like other compiled languages there is a lot to be gained by only\\nshipping the stuff you\'re going to run; and no language is safe from requiring\\nseveral times more \'stuff\' in order to build our apps.\\n\\nBuildx supports a\\n[handful of different types](https://github.com/docker/buildx/blob/master/docs/reference/buildx_build.md#-export-build-cache-to-an-external-cache-destination---cache-to)\\nof caching sources and destinations. We\'re going to be using the `registry`\\ntype, where you point the cache at a repository reference (repo/image:tag\\nstyle).\\n\\n> One thing to note is that Google Container Registry does not support the\\n> metadata/manifest format that buildx uses, so if you\'re using Google Cloud you\\n> will need to start using Artifact Registry.\\n\\n**Inline**\\n\\nPush the image and the cache together:\\n\\n```\\n...\\n--cache-from=type=registry,ref=$IMAGE_NAME \\\\\\n--cache-to=type=inline \\\\\\n...\\n```\\n\\nThis comes with the constraint that cache mode is always `min`, which only\\nexports/caches the resulting layers; which is still better than the plain docker\\nbuild caching but I think having the intermediary layers is generally a win. We\\nwant to avoid a single line change invalidating an entire build step.\\n\\n**Registry**\\n\\nResulting image and cache are separated:\\n\\n```\\n...\\n--cache-from=type=registry,ref=$IMAGE_NAME-build-cache \\\\\\n--cache-to=type=registry,ref=$IMAGE_NAME-build-cache,mode=max \\\\\\n...\\n```\\n\\nAgain coming back to the cache mode, here being `max`; all intermediary laters\\nare exported to the cache image as well.\\n\\nI have opted to create _two_ images, one for caching and another for the\\nresulting image used to deploy. This gains us a much more granular cache and the\\nability to more easily manage the cache image - like deleting the whole thing\\nwhen wanting to invalidate the cache. Not to mention I\'m fairly sure the size of\\nour images that get pulled on kubernetes would get significantly larger with\\nmany more layers.\\n\\nIt feels like a safer bet to have lean images for kubernetes to pull, and chunky\\ncache images specifically for speeding up build.\\n\\nDepending on your setup, pulling large images can get _seriously_ expensive in a\\nreasonably active deployment environment - like on AWS ECS without using\\nPrivateLink.\\n\\n> It appears the `moby/buildkit` documentation also demonstrates\\n> [this](https://github.com/moby/buildkit#registry-push-image-and-cache-separately)\\n> approach.\\n\\n```\\nIMAGE_NAME=us-east4-docker.pkg.dev/<project-name>/platform/app \\\\\\ndocker buildx build \\\\\\n  -t $IMAGE_NAME:latest \\\\\\n  --cache-from=type=registry,ref=$IMAGE_NAME-build-cache \\\\\\n  --cache-to=type=registry,ref=$IMAGE_NAME-build-cache,mode=max \\\\\\n  --push \\\\\\n  --progress=plain \\\\\\n  .\\n```\\n\\nThis implies that the cache image is named with the suffix `-build-cache`:  \\n`us-east4-docker.pkg.dev/<project-name>/platform/app[-build-cache]`.\\n\\nThe `--push` argument tells buildx to push the resulting image to the registry.\\n\\n## Tips\\n\\n**Clearing the local cache**\\n\\nAs mentioned before, buildx has its own cache and in order to clear the cache\\nwhile debugging and readying a Dockerfile for remote building you\'ll probably\\nneed to reach for `docker buildx prune`.\\n\\n## Closing thoughts\\n\\nUsing buildx has been a really pleasant experience, having personally attempted\\nusing it a few times over the last 3 years; the most recent one being the first\\ntime I felt confident getting it into production. As with any sufficiently\\nflexible build tooling, the errors and issues you can run into range from\\ncomplete gibberish, genuinely concerning inconsistencies to architectural\\nchoices that you haven\'t fully caught up on; requiring an ever growing list of\\nchanges you need to make to your own build process.\\n\\nOur initial observations have been great, reasonable changes on our build have\\ngone from 28 minutes to around 9 minutes.\\n\\nWhile I have encountered a few confusing cache invalidations, especially when\\nbuilding locally, exporting the cache to a repository and then having CloudBuild\\nuse the image cache. And occasionally locally having what feels like _really_\\naggressive caching on intermediate steps, leading me to pruning the local cache.\\n\\nBut overall, these issues aren\'t necessarily buildx issues and more likely a\\ncombination of building docker images in general except with many more steps\\naccounted for by the cache.\\n\\nIt\'s kinda hard to see now what the exact issues I had with it in the past, but\\nhey!\\n\\nBuildx has given me what I \'expected\' with docker multi-stage builds, and having\\nthe cache in a repository completely side-steps having to attach a shared volume\\nor copying from a storage bucket.\\n\\n## Resources\\n\\n- [Multi-stage builds #3: Speeding up your builds](https://pythonspeed.com/articles/faster-multi-stage-builds/)\\n  <a name=\\"ref1\\"><sup>1</sup></a>\\n- [Docker Buildx](https://docs.docker.com/buildx/working-with-buildx/)\\n- [buildx build reference](https://github.com/docker/buildx/blob/master/docs/reference/buildx_build.md#buildx-build)\\n- [mody/buildkey Registry cache exporter](https://github.com/moby/buildkit#registry-push-image-and-cache-separately)"},{"id":"/2021/07/05/wrapping-my-head-around-jobs","metadata":{"permalink":"/articles/2021/07/05/wrapping-my-head-around-jobs","editUrl":"https://github.com/openfn/docs/edit/main/articles/2021-07-05-wrapping-my-head-around-jobs.md","source":"@site/articles/2021-07-05-wrapping-my-head-around-jobs.md","title":"Wrapping my head around jobs","description":"Jobs are business processes turned into functional-style scripts. What does that","date":"2021-07-05T00:00:00.000Z","tags":[{"inline":true,"label":"how-to","permalink":"/articles/tags/how-to"},{"inline":true,"label":"tips","permalink":"/articles/tags/tips"},{"inline":true,"label":"jobs","permalink":"/articles/tags/jobs"}],"readingTime":7.97,"hasTruncateMarker":true,"authors":[{"name":"Taylor Downs","title":"Founder & CEO","page":{"permalink":"/articles/authors/taylor"},"email":"taylor@openfn.org","socials":{"x":"https://x.com/taylordowns2000","github":"https://github.com/taylordowns2000"},"imageURL":"https://avatars.githubusercontent.com/taylordowns2000","key":"taylor"}],"frontMatter":{"layout":"post","title":"Wrapping my head around jobs","authors":"taylor","tags":["how-to","tips","jobs"],"featured":true},"unlisted":false,"prevItem":{"title":"Improving Multistage Docker Builds using Buildx","permalink":"/articles/2021/10/08/improving-multistage-docker-builds-using-buildx"},"nextItem":{"title":"Forms and Cases: CommCare and event-based integration","permalink":"/articles/2021/05/24/commcare-events"}},"content":"Jobs are business processes turned into functional-style scripts. What does that\\nmean, how should you approach writing jobs?\\n\\n\x3c!--truncate--\x3e\\n\\nFirst, this is how _I_ think about jobs and what we do at Open Function Group to\\ntry to make our job code as readable, future-proof, and concise as possible.\\nThere are a million different ways to approach writing jobs. This is one.\\n\\n## It all starts with `state`\\n\\nIf a job is a set of instructions for a chef (a recipe?) then the initial\\n`state` is all of the ingredients they need tied up in a perfect little bundle.\\nIt usually looks something like this:\\n\\n```json\\n{\\n  \\"configuration\\": {\\n    \\"hostUrl\\": \\"https://moh.kenya.gov.ke/dhis2\\",\\n    \\"username\\": \\"taylor\\",\\n    \\"password\\": \\"very-secret\\"\\n  },\\n  \\"data\\": {\\n    \\"type\\": \\"registration\\",\\n    \\"patient\\": {\\n      \\"age\\": 24,\\n      \\"gender\\": \\"M\\",\\n      \\"nationalId\\": \\"321cs7\\"\\n    }\\n  }\\n}\\n```\\n\\nThis might be the initial `state` for a real-time, message-triggered job. Some\\nsource system generated a new patient payload and sent that payload to OpenFn.\\nThe data from our source system will wind up in `state.data`. Now if my job is\\nmeant to take this new patient registration information and use it to create a\\nnew record in the national health record system, I\'ll also need to provide my\\nrobot-chef here with a credential so they can access that system. The credential\\nI\'ve specified will get put into `state.configuration` and now our \\"raw\\ningredients\\" are all ready for our robot chef.\\n\\nNote that even if this job was initiated by a cron trigger (e.g., \\"Hey chef,\\nprepare this recipe every Tuesday at 7pm\\") or by a flow/catch trigger (e.g.,\\n\\"Hey chef, prepare this recipe only when you _fail_ to make banana pancakes\\") it\\nwill have an initial state.\\n\\n**Every job, and every operation inside that job (think \\"step\\" in a recipe) is\\ncalled with `state` and returns `state` when it\'s done.**\\n\\nInitial state for a cron triggered job might look like this:\\n\\n```json\\n{\\n  \\"configuration\\": {\\n    \\"hostUrl\\": \\"https://moh.kenya.gov.ke\\",\\n    \\"apiKey\\": \\"abc123\\"\\n  },\\n  \\"data\\": {},\\n  \\"lastProcessedId\\": 321\\n}\\n```\\n\\nAnd for a fail triggered job like this:\\n\\n```json\\n{\\n  \\"configuration\\": {\\n    \\"hostUrl\\": \\"https://moh.kenya.gov.ke\\",\\n    \\"apiKey\\": \\"abc123\\"\\n  },\\n  \\"data\\": {},\\n  \\"lastProcessedId\\": 321,\\n  \\"error\\": [\\"Required field missing\\", \\"Patient Surname\\", \\"Line 43\\"]\\n}\\n```\\n\\nNo matter what, jobs start with state. See\\n[\\"Initial and final state for runs\\"](/documentation/jobs/state) for a detailed\\nbreakdown.\\n\\n## It ends with `state` too\\n\\nNow that we\'ve got it in our heads that `state` is the raw ingredients you hand\\nto your chef when you ask them to prepare a recipe, let\'s look at the recipe.\\nBoiled down (excuse the pun) a job for loading those patients into the national\\nhealth record system might look like this:\\n\\n```js\\nget(\'/api/insuranceRegistrations\');\\npost(\'/api/patients\', { ...someData });\\npost(\'/api/visits\', { ...someData });\\n```\\n\\nWe\'re telling our chef to take those raw ingredients (login info for our\\nnational health system and a chunk of information about a newly registered\\npatient) and do the following:\\n\\n1. Find out whether this person already has a national health insurance number\\n2. Add this person to the patient registry (making use of some insurance data\\n   from step 1)\\n3. Add a visit record with information about this initial visit (making use of\\n   patient registry data from step 2)\\n\\nWhen all of this is done, we\'ll not only have a new patient and visit logged in\\nthe national health registry, but we\'ll also return a final `state` object with\\ninformation about what we\'ve done that can be used in subsequent jobs. Imagine\\nthat we want to make a cash transfer to this patient so that they can take a cab\\nto the next visit\u2014we might create a job with the Mpesa adaptor that takes the\\nfinal state of this first job as its _initial state_. In this way, jobs are\\ncomposable.\\n\\nBut what about the complexity inside our job\u2014in order to complete step 2, we\\nneed some data from the insurance registry and we only get that data in step 1.\\nCrucially, each operation (again, think \\"step\\" in a recipe) takes state and\\nreturns state. In effect, the OpenFn execution pipeline simply calls all of your\\naction methods _with state_, passing it along from one operation to the next,\\nwaiting for each to finish and using the output from the first as the input for\\nthe second.\\n\\nWhile you may write your `get`, `post`, `post` job as it\'s show above, the way\\nit\'s handled by OpenFn is actually more like:\\n\\n```js\\nreturn get(\'/api/insurance\', { ...useDataFromState })(state)\\n  .then(state2 => post(\'/api/patients\', { ...useDataFromState2 })(state2))\\n  .then(state3 => post(\'/api/visits\', { ...useDataFromState3 })(state3));\\n```\\n\\nEach of these operations returns a function which _takes state_ and returns\\nstate. This means that _within_ a job, you are essentially modifying `state`,\\ncreating/manipulating records in external systems, and returning `state`.\\n\\nIt opens up a really interesting world of possibility for data manipulation,\\ncleaning, or transformation. Consider what we might do _after_ we get data from\\nthe insurance registry but _before_ we create that patient in the national\\npatient registry:\\n\\n```js\\nget(\'/api/insuranceRegistrations\');\\nfn(state => {\\n  console.log(state.data); // let\'s look at the response from the insurance API.\\n  state.data.people.filter(p => p.HasActiveInsurance); // and modify the payload to only retain those with active insurance\\n  return state; // before returning state for our create patients operation.\\n});\\npost(\'/api/patients\', { ...someData });\\npost(\'/api/visits\', { ...someData });\\n```\\n\\nWe might even need to do some manipulation _before_ we send a `get` request to\\nthe insurance registry. That\'s no problem:\\n\\n```js\\nfn(state => {\\n  state.data.registrationType = state.data.age > 18 ? \'Adult\' : \'Minor\';\\n  return state; // before returning state for our create patients operation.\\n});\\nget(\'/api/insuranceRegistrations\', {\\n  query: { type: dataValue(\'registrationType\') },\\n});\\nfn(state => {\\n  state.data.people.filter(p => p.HasActiveInsurance);\\n  return state;\\n});\\npost(\'/api/patients\', { ...someData });\\npost(\'/api/visits\', { ...someData });\\n```\\n\\nHere, we\'ve added a step to modify the initial `state` before we send that first\\n`get` request to the insurance API. We determine if the new patient is a minor,\\nand then use that newly calculated data to apply a query to the insurance API\\nrequest.\\n\\nUsing `fn(state => state)` or `alterState(state => state})` is incredibly\\nuseful, because it allows us to separate our data manipulation, calculation, and\\nraw Javascript (which will be harder for low-tech users to understand) from our\\nexternal actions. Let\'s explore that some more.\\n\\n## Keeping external actions clean\\n\\nInside each operation we could do some data manipulation... all of these\\noperations, across the many different language packages, allow for inline data\\nmanipulation like this:\\n\\n```js\\nget(\'/api/insuranceRegistrations\', {\\n  query: state => {\\n    console.log(\\"I\'m doing some fancy stuff here.\\");\\n    return { type: state.data.age > 18 ? \'Adult\' : \'Minor\' };\\n  },\\n});\\npost(\'/api/patients\', {\\n  body: {\\n    name: state => {\\n      return `${state.data.firstName}${state.data.lastName}`;\\n    },\\n  },\\n});\\n```\\n\\nBut if you\'re interacting with both technical and non-technical users, it makes\\nfor harder to read jobs. Consider the following instead:\\n\\n```js\\n// Perform calculations...\\nfn(state => {\\n  // Create several new calculated attributes...\\n  state.data = {\\n    ...state.data,\\n    type: state.data.age > 18 ? \'Adult\' : \'Minor\',\\n    fullName: `${state.data.firstName}${state.data.lastName}`,\\n  };\\n\\n  return state;\\n});\\n\\n// Get insurance data...\\nget(\'/api/insuranceRegistrations\', { query: { type: dataValue(\'type\') } });\\n\\n// Create new patient...\\npost(\'/api/patients\', { body: { name: dataValue(\'fullName\') } });\\n```\\n\\nSince we often have non-developers creating the external operations like `get`\\nand `post` above, this pattern makes our handoff easier. The business analyst\\ncan say \\"I need to have a registration `type` field available for use when\\nquerying the insurance registry.\\" A developer might respond, \\"Great! How do you\\nwant to calculate it... I\'ve got all of Javascript at my fingertips.\\" That dev\\ncan then make as many API calls as they\'d like, perform as many\\n`map.reduce(...)` calls as their heart desires to complete that calculation...\\nso long as they make sure the hand off `state` to the business analyst\'s\\noperation with a valid `state.data.type` attribute.\\n\\nA final benefit of this approach is that it becomes much easier to generate job\\nscripts from Google Sheets. Our implementation team frequently works with\\nnon-technical clients to generate field maps that look like this:\\n\\n| Path to Source Data | Destination Field |          Auto-generated syntax (using concat) |\\n| ------------------- | ----------------- | --------------------------------------------: |\\n| patient.fullName    | name              | field(\'name\', dataValue(\'patient.fullName\')), |\\n| patient.age         | age               |       field(\'age\', dataValue(\'patient.age\')), |\\n| ???                 | type              | plz help us calculate \'type\' based on x, y, z |\\n| patient.sex         | gender            |    field(\'gender\', dataValue(\'patient.sex\')), |\\n\\nWe can then copy and paste the syntax generated in that final column directly\\ninto OpenFn and update the bits that need some sort of custom code, writing an\\n`fn(state)` block or an `alterState(state)` block before the external action.\\n\\n## Wrapping up\\n\\nSome key takeaways here:\\n\\n1. Jobs start and end with `state` \u2014 some raw ingredients that will be used in a\\n   recipe.\\n\\n2. Jobs are lists of `operations` \u2014 steps in a recipe that _each_ take `state`,\\n   _do some stuff_, and then return `state`.\\n\\n3. As you move through the steps in a job, you are modifying `state`. Each\\n   subsequent step begins with the final state from the previous step.\\n\\n4. It may be useful to keep all your custom Javascript data cleaning,\\n   manipulation, etc., in a separate operation (e.g., `fn(state)` or\\n   `alterState(state)`) so that your external actions are clean and easy to\\n   follow.\\n\\nFinally, taking a close look at how developers write those `fn(state)` steps\\ntells us a lot about what the job execution pipeline is really doing:\\n\\n```js\\n// here, \\"fn\\" is a function that takes state and returns state\\nfn(state => {\\n  console.log(\\"I\'m doing some cool stuff.\\");\\n  //  I might create some new attribute...\\n  state.myNewThing = true;\\n\\n  // And ALWAYS return state for the next operation to use...\\n  return state;\\n});\\n```\\n\\nI hope this gives you sense of how I think about structuring jobs and building\\ndata pipelines or automation flows on OpenFn. We recognize that this stuff is\\ncomplex, and are pushing our new documentation regularly, so please do get in\\ntouch if you think there are ways we could improve this type of\\nwalk-through/helper article.\\n\\nHappy integrating,\\n\\nTaylor"},{"id":"/2021/05/24/commcare-events","metadata":{"permalink":"/articles/2021/05/24/commcare-events","editUrl":"https://github.com/openfn/docs/edit/main/articles/2021-05-24-commcare-events.md","source":"@site/articles/2021-05-24-commcare-events.md","title":"Forms and Cases: CommCare and event-based integration","description":"This is a quick one, but I just got off an exciting call with an organization","date":"2021-05-24T00:00:00.000Z","tags":[{"inline":true,"label":"how-to","permalink":"/articles/tags/how-to"},{"inline":true,"label":"tips","permalink":"/articles/tags/tips"}],"readingTime":9.52,"hasTruncateMarker":true,"authors":[{"name":"Taylor Downs","title":"Founder & CEO","page":{"permalink":"/articles/authors/taylor"},"email":"taylor@openfn.org","socials":{"x":"https://x.com/taylordowns2000","github":"https://github.com/taylordowns2000"},"imageURL":"https://avatars.githubusercontent.com/taylordowns2000","key":"taylor"}],"frontMatter":{"layout":"post","title":"Forms and Cases: CommCare and event-based integration","authors":"taylor","tags":["how-to","tips"],"featured":true},"unlisted":false,"prevItem":{"title":"Wrapping my head around jobs","permalink":"/articles/2021/07/05/wrapping-my-head-around-jobs"},"nextItem":{"title":"Sync Like You Mean It: Thinking Through System \u201cSyncing\u201d Protocols","permalink":"/articles/2021/02/17/syncing-options"}},"content":"This is a quick one, but I just got off an exciting call with an organization\\nthat\'s going to set up some jobs to move data into Salesforce from CommCare and\\nrealized that despite this being one of our more common integration\\nrequirements, we haven\'t done a \'tips\' article for this type of project. Until\\nnow.\\n\\n\x3c!--truncate--\x3e\\n\\nSo here goes. While this is by no means an exhaustive project planning template,\\nhere are a few things to keep in mind if you\'re planning to implement a CommCare\\nto Salesforce integration on your own.\\n\\n## Most people use \\"Data Forwarding\\" in CommCare\\n\\nFirst, most people make use of CommCare\'s \\"Data Forwarding\\" feature to send form\\nsubmissions and changes in cases (creation, update, closure, etc.) to OpenFn in\\nreal-time. You can read about that\\n[here](/adaptors/commcare#webhook-forward-cases-andor-forms-from-commcare-to-openfn-using-rest-service)\\nbut the key consideration at this planning stage is _when_ you\'ll be performing\\noperations\u2014`create(...)`, `update(...)`, `upsert(...)`, `query(...)`,\\n`(bulk(...)`, etc.\u2014in Salesforce and what data you\'ll have access to.\\n\\nEach time a form submission comes into CommCare, we\'ll get a copy of that\\nsubmission at OpenFn and can use that data to create or modify some records in\\nSalesforce.\\n\\nLikewise, each time a case gets updated (or created or closed) we\'ll get a copy\\nof the case with all the case \\"properties\\" and we can use that data to _do some\\nstuff_ in Salesforce.\\n\\nIf you are using \\"Form Forwarding\\", the `trigger` you\'d create in OpenFn might\\nlook like this `{\\"form\\":{\\"@name\\":\\"ART Adherence Self-Reporting Tool\\"}}` and it\\nwould trigger your `job` any time an \\"ART Adherence Self-Reporting Tool\\"\\nsubmission arrived from CommCare, giving that job access to all of the data\\ninside that submission.\\n\\n## Working with the data that comes from CommCare\\n\\nAssuming you\'re using making use of case management, the data that arrives from\\nCommCare will look something like this:\\n\\n```json\\n{\\n  \\"__query_params\\": {\\n    \\"app_id\\": \\"some-long-id\\"\\n  },\\n  \\"app_id\\": \\"some-long-id\\",\\n  \\"archived\\": false,\\n  \\"attachments\\": {\\n    \\"1621866020043.jpg\\": {\\n      \\"content_type\\": \\"image/jpeg\\",\\n      \\"length\\": 16423,\\n      \\"url\\": \\"https://www.commcarehq.org/a/your-project/api/form/attachment/some-uuid/1621866020043.jpg\\"\\n    },\\n    \\"form.xml\\": {\\n      \\"content_type\\": \\"text/xml\\",\\n      \\"length\\": 2727,\\n      \\"url\\": \\"https://www.commcarehq.org/a/your-project/api/form/attachment/some-uuid/form.xml\\"\\n    }\\n  },\\n  \\"build_id\\": \\"0ec83881cd0e420dad5c24ed3a5452fe\\",\\n  \\"domain\\": \\"your-project\\",\\n  \\"edited_by_user_id\\": null,\\n  \\"edited_on\\": null,\\n  \\"form\\": {\\n    \\"#type\\": \\"data\\",\\n    \\"@name\\": \\"ART Adherence Self-Reporting Tool\\",\\n    \\"@uiVersion\\": \\"1\\",\\n    \\"@version\\": \\"2783\\",\\n    \\"@xmlns\\": \\"http://openrosa.org/formdesigner/59E1207B-969F-402D-9EEE-675504036F78\\",\\n    \\"administrative\\": {\\n      \\"coach_verification\\": \\"check_here\\",\\n      \\"visit_notes\\": \\"\\",\\n      \\"vist_notes_to_save\\": \\"\\"\\n    },\\n    \\"case\\": {\\n      \\"@case_id\\": \\"1ec51ee9-5aef-4bd2-b7eb-7599856251bc\\",\\n      \\"@date_modified\\": \\"2021-05-24T14:20:28.693000Z\\",\\n      \\"@user_id\\": \\"332e893dcd1b413686621bd80aae0cd3\\",\\n      \\"@xmlns\\": \\"http://commcarehq.org/case/transaction/v2\\",\\n      \\"update\\": {\\n        \\"consent_received\\": \\"yes\\",\\n        \\"home_visit_notes\\": \\"\\"\\n      }\\n    },\\n    \\"meta\\": {\\n      \\"@xmlns\\": \\"http://openrosa.org/jr/xforms\\",\\n      \\"appVersion\\": \\"CommCare Android, version \\\\\\"2.51.2\\\\\\"(463994). App v2798. CommCare Version 2.51.2. Build 463994, built on: 2021-03-17\\",\\n      \\"app_build_version\\": 2798,\\n      \\"commcare_version\\": \\"2.51.2\\",\\n      \\"deviceID\\": \\"commcare_a39f55a5-c744-4e33-8e01-d17e7698894f\\",\\n      \\"drift\\": \\"0\\",\\n      \\"geo_point\\": null,\\n      \\"instanceID\\": \\"130c68c5-7d17-4086-8a85-27d7d7da2216\\",\\n      \\"timeEnd\\": \\"2021-05-24T14:20:28.693000Z\\",\\n      \\"timeStart\\": \\"2021-05-24T14:18:46.856000Z\\",\\n      \\"userID\\": \\"332e893dcd1b413686621bd80aae0cd3\\",\\n      \\"username\\": \\"some-chw\\"\\n    },\\n    \\"participant_information\\": {\\n      \\"participant_id\\": \\"007\\",\\n      \\"name\\": \\"taylor downs\\",\\n      \\"gender\\": \\"male\\",\\n      \\"guardian_information\\": {\\n        \\"guardians_name\\": \\"Fake Data\\",\\n        \\"guardians_phone_number\\": \\"8675309\\",\\n        \\"guardians_signature\\": \\"1621866020043.jpg\\",\\n        \\"relationship_to_participant\\": \\"father\\"\\n      },\\n      \\"current_medications\\": [\\n        { \\"name\\": \\"generic-1\\", \\"active\\": true },\\n        { \\"name\\": \\"fakelyn-notrealiol\\", \\"active\\": false },\\n        { \\"name\\": \\"sasstra-zenica\\", \\"active\\": false },\\n        { \\"name\\": \\"ibuprofen\\", \\"active\\": true }\\n      ]\\n    },\\n    \\"tested_for_hiv_status_tested_for_hiv\\": \\"OK\\",\\n    \\"visit_information\\": {\\n      \\"consent_given\\": \\"yes\\",\\n      \\"date_consent_given\\": \\"2021-05-23\\",\\n      \\"visit_date\\": \\"2021-05-23\\"\\n    }\\n  },\\n  \\"id\\": \\"130c68c5-7d17-4086-8a85-27d7d7da2216\\",\\n  \\"indexed_on\\": \\"2021-05-24T14:20:39.045971\\",\\n  \\"initial_processing_complete\\": true,\\n  \\"is_phone_submission\\": true,\\n  \\"metadata\\": {\\n    \\"appVersion\\": \\"CommCare Android, version \\\\\\"2.51.2\\\\\\"(463994). App v2798. CommCare Version 2.51.2. Build 463994, built on: 2021-03-17\\",\\n    \\"app_build_version\\": 2798,\\n    \\"commcare_version\\": \\"2.51.2\\",\\n    \\"deviceID\\": \\"commcare_a39f55a5-c744-4e33-8e01-d17e7698894f\\",\\n    \\"drift\\": \\"0\\",\\n    \\"geo_point\\": null,\\n    \\"instanceID\\": \\"130c68c5-7d17-4086-8a85-27d7d7da2216\\",\\n    \\"location\\": null,\\n    \\"timeEnd\\": \\"2021-05-24T14:20:28.693000Z\\",\\n    \\"timeStart\\": \\"2021-05-24T14:18:46.856000Z\\",\\n    \\"userID\\": \\"332e893dcd1b413686621bd80aae0cd3\\",\\n    \\"username\\": \\"some-chw\\"\\n  },\\n  \\"problem\\": null,\\n  \\"received_on\\": \\"2021-05-24T14:20:37.976363Z\\",\\n  \\"resource_uri\\": \\"\\",\\n  \\"server_modified_on\\": \\"2021-05-24T14:20:38.111789Z\\",\\n  \\"type\\": \\"data\\",\\n  \\"uiversion\\": \\"1\\",\\n  \\"version\\": \\"2783\\"\\n}\\n```\\n\\nThis is a big blob of `JSON`\u2014the body of the message that\'s received at OpenFn\\nwhen this particular form (\\"ART Adherence Self-Reporting Tool\\") is submitted in\\nCommCare\u2014will be handed off to the job to start processing. The question is,\\nwhat should we do?\\n\\nWhen setting up for a self-service implementation on OpenFn, the most important\\nthing you can do at this moment is carefully enumerate the data entry process\\nthat you\'d like a real human to follow. You can translate it to a job script\\nlater.\\n\\nYou\'ll need to write this up for your own case, but in this fictional example,\\nhere\'s the data entry process.\\n\\n## The instructions for our worker\\n\\n:::tip\\n\\nRight from the start, notice that we\'re being incredibly explicit with these\\ninstructions! We\'re using the \\"API Name\\" (instead of just the \\"label\\", which\\nmight be ambiguous) of every field we want filled out in Salesforce and we\'re\\nusing the specific \\"path\\" to the data we want this person to enter from\\nCommCare.\\n\\n**Why are we being so specific?** Because eventually, a computer will need to\\ninterpret this\u2014and they\'re _terrible_ with ambiguity!\\n\\n:::\\n\\n1. Every time a messaged is received with\\n   `{\\"form\\":{\\"@name\\":\\"ART Adherence Self-Reporting Tool\\"}}` in the body (this is\\n   our trigger)\\n2. Log into Salesforce and create a new participant with the `participant_id`\\n   you find in the `form.participant_information` section as their\\n   `Participant_Code__c`. (If one already exists in Salesforce with that code,\\n   then update the existing record instead.)\\n3. Fill out the following fields in Salesforce based on the CommCare data in\\n   this message:\\n   - `Name__c` with the data from `form.participant_information.name`\\n   - `Sex__c` with the data from `form.participant_information.gender`\\n   - `CommCare_Case_ID__c` with the data from `form.case.@case_id`\\n4. After you\'ve created (or updated) this participant in Salesforce, create a\\n   record of the visit with the `instanceID` from the `metadata` section as the\\n   unique identifier `Visit_Code__c`. (Again, if there\'s already a visit with\\n   that ID please update the existing record.)\\n5. Fill out the following fields for the visit with data from CommCare\\"\\n   - `Date__c` with `form.visit_information.visit_date`.\\n   - `Consented__c` with `form.visit_information.consent_given`.\\n   - Always set `Test_Status__c` to `true`, regardless of what\'s in the message\\n     from CommCare.\\n   - And relate this record with the `Community_Health_Worker` by their username\\n     in `form.metadata.username`.\\n6. Finally, add a record for each medication listed in the\\n   `form.participant_information.current_medications` array\u2014matching on a unique\\n   ID formed by a combination of the medication `name` and the `participant_id`\\n   so that we can update existing medication records if they\'re present.\\n7. Fill out the following fields for the medication:\\n   - `Generic_Name__c` with `name`\\n   - `Status__c` with `active`\\n   - And relate this record with the participant you created or updated in step\\n     2 via the `participant_id` field.\\n\\nPhew... that\'s the task. It\'s just a fictional example and things could be much\\nmore straightforward, or much more complicated than this, but it\'s important to\\nremember that if you can get to this level of **precision and granularity** in\\nyour data entry process, a tool like OpenFn can automate this for you in a\\nflash.\\n\\n## Translating this into an OpenFn project\\n\\nIf you\'re streaming data in from CommCare and you\'ve got your Salesforce system\\nall set up so that this data entry person can complete the above steps (are all\\nthe objects and fields created? are the right fields marked as \\"unique\\" and set\\nto be used as an \\"external id\\" in the Salesforce administration section? have\\nyou turned on data forwarding in CommCare?) then it\'s time to turn them into an\\nOpenFn project!\\n\\n:::tip\\n\\nA quick plug: **Did you know that there\'s an\\n[OpenFn community forum](https://community.openfn.org)** where you can post\\nstuff like the \\"steps\\" above and get help from other OpenFn users and staff\\nconverting these steps into a real, working, OpenFn job?\\n\\nWell, you do know! Check it out at\\n[community.openfn.org](https://community.openfn.org)\\n\\n:::\\n\\n### Create a Salesforce credential\\n\\nWe don\'t need a CommCare credential, since they\'ll send data to us. Create a\\nSalesforce credential that will allow the OpenFn worker to log into your\\nSalesforce system.\\n\\nRead more about credentials [here](/documentation/build/credentials).\\n\\n### Create a message-filter trigger\\n\\n- Select `Message Filter` for the `type`\\n- Enter `{\\"form\\":{\\"@name\\":\\"ART Adherence Self-Reporting Tool\\"}}` for the\\n  `inclusion criteria`\\n\\nRead more about triggers [here](/documentation/build/triggers).\\n\\n### Create the job\\n\\n- Give it a name\\n- Select the trigger you just created\\n- Select the `salesforce` adaptor\\n- Select the credential you just created\\n\\nAnd convert the instructions above to \\"operations\\" by using the inline help\\nprovided by the Salesforce adaptor:\\n\\n```js\\n// Use upsert to create or update a participant based on their participant code.\\nupsert(\\n  \'Participant__c\',\\n  \'Participant_Code__c\',\\n  fields(\\n    field(\\n      \'Participant_Code__c\',\\n      dataValue(\'form.participant_information.participant_id\')\\n    ),\\n    field(\'Name__c\', dataValue(\'form.participant_information.name\')),\\n    field(\'Sex__c\', dataValue(\'form.participant_information.gender\')),\\n    field(\'CommCare_Case_ID__c\', dataValue(\'form.case[@case_id]\'))\\n  )\\n);\\n\\n// Then upsert a visit using the visit code.\\nupsert(\\n  \'Visit__c\',\\n  \'Visit_Code__c\',\\n  fields(\\n    field(\'Visit_Code__c\', dataValue(\'metadata.instanceID\')),\\n    field(\'Date__c\', dataValue(\'form.visit_information.visit_date\')),\\n    field(\'Consented__c\', dataValue(\'form.visit_information.consent_given\')),\\n    // Always set status to true\\n    field(\'Test_Status__c\', true),\\n    // And related this visit to the participant we just created by their \\"code\\"\\n    relationship(\\n      \'Participant__r\',\\n      \'Participant_Code__c\',\\n      dataValue(\'form.participant_information.participant_id\')\\n    )\\n  )\\n);\\n\\n// And finally for EACH mediation listed, create a medication record with a status\\neach(\\n  merge(\\n    dataPath(\'form.participant_information.current_medications[*]\'),\\n    fields(\\n      field(\'pID\', dataValue(\'form.participant_information.participant_id\'))\\n    )\\n  ),\\n  upsert(\\n    \'Medication_Tx__c\',\\n    \'Medication_Tx_ID__c\',\\n    fields(\\n      field(Medication_Tx_ID__c, state => {\\n        // Here, inside the medications array we\'ve \\"scoped\\" state so that\\n        // state.data, for each item in the array, looks like this:\\n        // { pID: 007, name: \\"sasstra-zenica\\", active: false }\\n\\n        // We will concatenate the participant ID with the medication name.\\n        return state.data.pID + state.data.name;\\n      }),\\n      field(\'Generic_Name__c\', dataValue(\'name\')),\\n      field(\'Status__c\', dataValue(\'status\')),\\n      relationship(\'Participant__r\', \'Participant_Code__c\', dataValue(\'pID\'))\\n    )\\n  )\\n);\\n```\\n\\nNow, every time this job runs (which is every time a CommCare form is submitted)\\nyour OpenFn worker will upsert a `Participant`, upsert a `Visit`, and upsert a\\nwhole list of `Medications` in Salesforce.\\n\\n## What\'s next\\n\\nWell, in our little example you\'d turn the job \\"on\\" (setting it to on the\\ninbound messages from CommCare) and let it run. Whenever there was a failure\\n(maybe your Salesforce admin added a new required field on the\\ncustom`Medication` object) you\'d get an email and you\'d have to come back to\\nOpenFn to update your job, including that new field.\\n\\nIf you\'re in the process of designing your CommCare and Salesforce systems at\\nthe moment, this back-and-forth will be pretty common. Keep in mind that you\\nwant as much simplicity as possible in those end-user systems because... well\\nbecause _humans_ have the interact with them every day!\\n\\nSo long as your processes are well defined, OpenFn can handle a bit of\\ncomplexity (data cleaning, transformation, complex logical flows, etc.) but you\\nshould never make sacrifices to the user experience in CommCare and\\nSalesforce\u2014that\'s a quick way to lose adoption.\\n\\nSo, ideally, you\'ve designed your workflows in CommCare and Salesforce to make\\nyour users happy and get them the information they need to do their jobs well\\nand _then_ you come back to OpenFn and spell out our data entry instructions\\nlike we\'ve done above.\\n\\n## A final thought\\n\\nThe two most important resources you\'ve got at your disposal if you\'re setting\\nthis all up on your own are:\\n\\n1. this site (docs.openfn.org), and\\n2. the [forum](https://community.openfn.org) (community.openfn.org)\\n\\nRead through the\\n[\\"What is an integration\\"](/documentation/tutorials/tutorial),\\n[\\"OpenFn Concepts\\"](/documentation/get-started/terminology), and\\n[\\"Build\\"](/documentation/build/workflows) sections if you\'re a thorough,\\nbackground-first kind of learner. If you crave snippets and sample job code,\\nhead directly to the [Job Library](/adaptors/library) to see how other OpenFn\\nusers are creating their jobs.\\n\\nEither way, keep the community posted on your progress in the forum\u2014you\'ll find\\nlots of helpful folks willing to lend you a hand in your integration journey."},{"id":"/2021/02/17/syncing-options","metadata":{"permalink":"/articles/2021/02/17/syncing-options","editUrl":"https://github.com/openfn/docs/edit/main/articles/2021-02-17-syncing-options.md","source":"@site/articles/2021-02-17-syncing-options.md","title":"Sync Like You Mean It: Thinking Through System \u201cSyncing\u201d Protocols","description":"\u201cSyncing\u201d is getting two systems to a state of harmony. This might mean keeping","date":"2021-02-17T00:00:00.000Z","tags":[{"inline":true,"label":"how-to","permalink":"/articles/tags/how-to"},{"inline":true,"label":"tips","permalink":"/articles/tags/tips"}],"readingTime":3.76,"hasTruncateMarker":true,"authors":[{"name":"Jed Goldstein","socials":{"github":"https://github.com/jedbgold"},"imageURL":"https://avatars.githubusercontent.com/jedbgold","key":"jed","page":null}],"frontMatter":{"layout":"post","title":"Sync Like You Mean It: Thinking Through System \u201cSyncing\u201d Protocols","authors":"jed","tags":["how-to","tips"],"featured":true},"unlisted":false,"prevItem":{"title":"Forms and Cases: CommCare and event-based integration","permalink":"/articles/2021/05/24/commcare-events"},"nextItem":{"title":"Our Servers or Yours: Thinking through deployment options","permalink":"/articles/2021/02/03/hosted-or-local-deployment"}},"content":"\u201cSyncing\u201d is getting two systems to a state of harmony. This might mean keeping\\na list of patients up to date, though modifications can be made in either\\nsystem. It might mean copying transactions from one system to another on a\\nnightly basis. It might mean a lot of things, but the key concept is that when\\nyou sync systems, you\u2019re asking them to work together while simultaneously\\nrespecting both software systems\u2019 independence.\\n\\nIn this post we\u2019ll discuss two different syncing protocols to consider when\\ndesigning your data integration. These include:\\n\\n1. **Real-time, or event-based, syncs**\\n2. **Scheduled syncs**\\n\x3c!--truncate--\x3e\\n\\nFor a\\n[recent project in Cambodia](https://www.openfn.org/spotlight/2021-02-09-interoperability-for-case-referrals),\\nOpenFn is being used by social workers to automate case referrals between the\\nsoftware systems Primero and OSCaR. In the design phase, we evaluated these two\\nsyncing options. Below, we\'ll explain what each one is, the differences between\\nthem and which option we chose in the end.\\n\\n### Real Time/Event Based Syncs\\n\\nThe first option considered for this integration was the real-time/event based\\nsync. This type of sync is triggered whenever a specified event takes place in a\\nsystem. With this approach, whenever a case is referred in Primero (via the user\\ninterface, i.e., when a real case-worker clicks the \u201crefer\u201d button) OpenFn\\nreceives a small payload with case data and transmits it to OSCaR and vice\\nversa.\\n\\n![Real_Time_Sync](/img/syncs1.png)\\n\\n\x3c!-- all diagrams for this article can be found here: https://lucid.app/lucidchart/invitations/accept/d36fb964-7c74-4e48-b248-7e25497883e3 --\x3e\\n\\nBecause of their instantaneous nature, real time/event based syncs are great for\\nintegrations that involve mobile payments or sms messages to recipients. Really,\\nanything that needs to be done \u201cnow\u201d! Additionally, depending on your data\\nvolumes real time syncs might save you money because you\u2019re only using resources\\nwhen specific events take place. For instance, in the above example, a run is\\ntriggered by a referral, so if there are only 10 case referrals/month, you\'d\\nonly process 10 runs each month.\\n\\nThis type of sync is great because it\u2019s instantaneous, typically quite\\nstraightforward to set up, doesn\u2019t require any \u201cstate mangagement\u201d on OpenFn,\\nand allows for the reprocessing of individual events. There are, however,\\ndrawbacks.\\n\\nFor instance, what happens if the app that\u2019s sending notifications to OpenFn\\nfails to send? What if AWS or GCP goes down, taking half of the internet with\\nit? If Primero \u201cthinks\u201d it sent the referral, OpenFn never receives it, that\\ncase might not get referred to Oscar!\\n\\n### Scheduled Syncs\\n\\n![Schedule_Dependent_Sync](/img/syncs2.png)\\n\\nThe second option considered, a bi-directional schedule dependent sync, solves\\nfor the issue discussed above. On a scheduled basis (every 5 minutes, for\\nexample) OpenFn checks with Primero and Oscar to see if case referrals need to\\nbe transmitted between the two systems and then refers the case if required. In\\nthe unlikely event that any of the software systems involved crash, the\\nstability provided by the bi-directional sync means that all data is preserved\\nand eventually makes it to its destination safely.\\n\\nThe major drawback here is complexity. We had to use 4 jobs instead of 2, and\\nthe job that is responsible for \u201cpulling\u201d data that\u2019s been updated since the\\ntime of the last successful sync has to keep \u201cstate\u201d\u2014or some sort of working\\nmemory of what it\u2019s done in the past. When pulling modified cases from Primero,\\nOpenFn now only pulls cases modified on or after `YYYY-MM-DD HH:MM:SS` where\\n`YYYY-MM-DD HH:MM:SS` is the time of the last successful, round-trip\\nsynchronization. OpenFn has built-in functionality to handle exactly this\\nrequirement, but not all ETL systems do and it\u2019s a design implication that must\\nbe considered.\\n\\nUltimately, for the project in Cambodia, we decided that this sync option is the\\nright choice because data integrity is more important than the speed of this\\ndata flow. That\u2019s a crucial point to understand\u2014the organizations operating in\\nCambodia decided that for this particular use case, being able to guarantee\\neventual syncing was more important than having real-time syncing.\\n\\n### Both Sync Options Have Their Pros and Cons\\n\\nBoth options definitely have their use-cases and OpenFn\'s platform versatility\\nenables your team to decide which type of sync is right for your project.\\n\\nAs always, we are here to help with any questions as you think through which\\nsync option makes the most sense for your project."},{"id":"/2021/02/03/hosted-or-local-deployment","metadata":{"permalink":"/articles/2021/02/03/hosted-or-local-deployment","editUrl":"https://github.com/openfn/docs/edit/main/articles/2021-02-03-hosted-or-local-deployment.md","source":"@site/articles/2021-02-03-hosted-or-local-deployment.md","title":"Our Servers or Yours: Thinking through deployment options","description":"Zandile is a program manager at an iNGO and she needs to use CommCare, DHIS2,","date":"2021-02-03T00:00:00.000Z","tags":[{"inline":true,"label":"how-to","permalink":"/articles/tags/how-to"},{"inline":true,"label":"tips","permalink":"/articles/tags/tips"}],"readingTime":4.37,"hasTruncateMarker":true,"authors":[{"name":"Jed Goldstein","socials":{"github":"https://github.com/jedbgold"},"imageURL":"https://avatars.githubusercontent.com/jedbgold","key":"jed","page":null}],"frontMatter":{"layout":"post","title":"Our Servers or Yours: Thinking through deployment options","authors":"jed","tags":["how-to","tips"],"featured":true},"unlisted":false,"prevItem":{"title":"Sync Like You Mean It: Thinking Through System \u201cSyncing\u201d Protocols","permalink":"/articles/2021/02/17/syncing-options"},"nextItem":{"title":"Tracked entity instances in DHIS2","permalink":"/articles/2020/12/09/upsert-in-dhis2"}},"content":"Zandile is a program manager at an iNGO and she needs to use CommCare, DHIS2,\\nand OpenFn for an upcoming public health project. She understands that all three\\npieces of software can be deployed locally, or accessed as SaaS (Software as a\\nService).\\n\\nEssentially, Zandile needs to decide if she would like to run the software on\\nsomeone else\u2019s servers (SaaS), or on her organization\u2019s own servers (deployed\\nlocally). Before making a decision she outlines the basic, non-technical\\nconsiderations for both options.\\n\\n\x3c!--truncate--\x3e\\n\\n## What is SaaS?\\n\\nSaaS is software that is installed and _runs_ on computers maintained by\\nsoftware professionals, rather than on your own computer. While those computers\\nmight be anywhere in the world, typically you\'ll access and _use_ this software via\\nthe Internet.\\n\\n### Some benefits of SaaS\\n\\nWith SaaS, the software vendor is responsible for the expenses of managing and\\nmonitoring all of the technical components and issues associated with the\\nsoftware. This means that Zandile\u2019s iNGO will not be responsible for updating\\nthe software to ensure compliance with new security regulations, maintaining the\\nservers, backing up the data, purchasing and managing uninterrupted power\\nsupplies, and providing a team of physical security guards to protect the\\ncomputers and data therein against physical theft.\\n\\nGoing the SaaS route is often faster and more secure, because you do not need to\\ndevelop expertise in \\"DevOps\\" or hire IT and physical security specialists. This\\noption also provides the greatest amount of flexibility & scalability\u2013 because\\nthe SaaS provider is able to deliver more or less computing power, storage, and\\nbandwidth\u2014right when it\u2019s needed.\\n\\nHaving smaller setup costs (you don\'t have to grow a software delivery company\\nof your own) often makes this a more economical choice for many, though SaaS\\nwill always come with some sort of ongoing fee\u2014a price per month or year that\\ngoes to the vendor to compensate for the time and money they\'ll spend to ensure\\nyour software works properly.\\n\\n## What is Local Deployment?\\n\\nUnlike the SaaS option, local deployment means installing and running software\\non your own computers\u2014typically on your organization\u2019s servers.\\n\\n### Some benefits of Local Deployment\\n\\nIf a SaaS provider doesn\'t offer hosting in your country and your government\\ndoesn\'t allow your data to reside on foreign servers (i.e., you\'re not allowed\\nto use things like Gmail, WhatsApp or Facebook for communicating sensitive\\ninformation) then local deployment allows you to use tools like CommCare, DHIS2,\\nand OpenFn while adhering to government data sovereignty regulations.\\n\\nLocal deployment also provides your organization with complete ownership of the\\nend-to-end system. Your IT team will be personally responsible for ensuring that\\nthe software works, is maintained, is secure, etc. If your organization does not\\nalready have an IT team in place, then this can become a costly headache, but\\nfor a large organization with embedded IT experience, local deployment often\\nmakes sense.\\n\\nUltimately, being able to directly hire and fire the people who are responsible\\nfor your software\'s proper functioning can be very useful. It means you have\\ncomplete responsibility for whether or not the solution succeeds.\\n\\nIf you\'ve already got the teams in place (security, DevOps, etc.) then this\\noption can be more economical in the long run. With a very good DevOps team,\\nmaintaining an extra piece of software might only occupy 20% of a\\nfull-time-employee\'s salary. For your security guards, if the software is\\ninstalled in the same physical location it\'s possible that your costs won\'t\\nincrease at all. While there will be very high setup costs, over time you may\\nrealize cost savings by running an efficient software delivery unit within your\\norganization that spreads its focus around a number of projects.\\n\\n## Zandile\'s Decision\\n\\nIn this fictional case, data residency is a concern\u2014her data is sensitive or\\ncontains PII\u2014and CommCare, DHIS2 and OpenFn do not provide hosting in the\\ncountry she\'s located. Zandile\'s organization has a large, experienced IT team\\nthat has managed high-availability software projects for many years... they\'re\\npros. While they anticipate that the setup costs will be quite high (around\\n$60000 and several months for this set of deployments) they plan on using this\\nsoftware for the next 5 years and have determined that they\'ll recoup a\\nsignificant portion of that setup cost by not having to pay license fees for\\nSaaS. They go with local deployment.\\n\\n## Which Deployment Option is Best for your organization?\\n\\nThe answer is: \\"it depends\\", but if your organization has never managed local\\nsoftware deployments, then we recommend going the SaaS approach. SaaS systems,\\nlike the one OpenFn and CommCare offer, are simply going to be more secure, more\\nstable, and more scalable for the money.\\n\\nCrucially, you can always start with SaaS (most tools even offer a free tier)\\nand then decide later to invest in the big startup costs of a local deployment\\nif the license fees for the SaaS feel high enough to make local deployment more\\neconomical over the long term. After a few months or years on the SaaS, you\'ll\\nlikely be in a better position to know if you want to continue using the\\nsoftware for 5-10 years.\\n\\nShould you need any help with your decision though please do not hesitate to\\ncontact OpenFn."},{"id":"/2020/12/09/upsert-in-dhis2","metadata":{"permalink":"/articles/2020/12/09/upsert-in-dhis2","editUrl":"https://github.com/openfn/docs/edit/main/articles/2020-12-09-upsert-in-dhis2.md","source":"@site/articles/2020-12-09-upsert-in-dhis2.md","title":"Tracked entity instances in DHIS2","description":"tl;dr: Lots of our users want to upsert tracked entity instances in dhis2, but","date":"2020-12-09T00:00:00.000Z","tags":[{"inline":true,"label":"how-to","permalink":"/articles/tags/how-to"},{"inline":true,"label":"tips","permalink":"/articles/tags/tips"}],"readingTime":1.81,"hasTruncateMarker":true,"authors":[{"name":"Taylor Downs","title":"Founder & CEO","page":{"permalink":"/articles/authors/taylor"},"email":"taylor@openfn.org","socials":{"x":"https://x.com/taylordowns2000","github":"https://github.com/taylordowns2000"},"imageURL":"https://avatars.githubusercontent.com/taylordowns2000","key":"taylor"}],"frontMatter":{"layout":"post","title":"Tracked entity instances in DHIS2","authors":"taylor","tags":["how-to","tips"],"featured":true},"unlisted":false,"prevItem":{"title":"Our Servers or Yours: Thinking through deployment options","permalink":"/articles/2021/02/03/hosted-or-local-deployment"},"nextItem":{"title":"Product News: Enhanced Scheduled/Periodic Job Control","permalink":"/articles/2020/07/14/cron-is-better-than-a-timer"}},"content":"tl;dr: Lots of our users want to upsert tracked entity instances in dhis2, but\\nupserts aren\u2019t supported by a standard DHIS2 API endpoint. We built one in our\\ndhis2 adaptor: it\u2019s composed of existing APIs and a bit of logic \ud83e\udd14. Now you can\\n`upsert` tracked entity instances to DHIS2 \ud83d\udc4d \u2705.\\n\\n\x3c!--truncate--\x3e\\n\\n## A bit more...\\n\\nAn \u201cUPSERT\u201d is a portmanteau of the database functions UPDATE and INSERT. It\u2019s\\ncritical to handle upserts properly when integrating systems. As of version 35\\nof the API, DHIS2 does not allow for an administrator to upsert tracked entity\\ninstances (\u201cTEIs\u201d). OpenFn\u2019s own\\n[Chaiwa Berian](https://github.com/chaiwa-berian) has come up with a solution\\nthat highlights the utility of helper functions in our dhis2 adaptor. By\\ncombining various DHIS2 APIs through an upsertTEI function in OpenFn, DHIS2\\nusers can now perform upserts to TEIs.\\n\\nIf you\u2019re curious, check out his implementation\\n[here](https://github.com/OpenFn/language-dhis2/blob/master/src/Adaptor.js#L347).\\n\\n## Even more!\\n\\nA tracked entity instance in DHIS2 is a type of entity that can be tracked\\nthrough the system. It can be anything from a person to a commodity like a\\nmedicine. If I am a database administrator presiding over two different systems\\nthat are connected to one another, let\u2019s call them \u201cSystem A\u201d and \u201cSystem B,\u201d I\\nwould like for any updates made to the TEI of a user named \u201cJim Smith\u201d in System\\nA to also appear in Jim\u2019s record in System B. Before upserts came about, doing\\nso was difficult because of the possibility of duplicate record creation.\\nBecause an upsert simultaneously UPDATES and INSERTS, it prevents duplicates.\\n\\nUpserts are important and good because they cut down on the risk of duplicate\\ndata entry and they also allow for transactions to be retried over and over to\\nensure data integrity. That last bit is called \u201cidempotency\u201d and you can read\\nabout it [over here](2020-07-02-allow-yourself-to-fail.md).\\n\\nPlease don\u2019t hesitate to reach out to one of OpenFn\u2019s implementation specialists\\nif you\u2019d like to learn more.\\n\\n\u2014 Taylor\\n\\n[Sign up](https://openfn.org/register) to set up a project today, absolutely\\nfree.\\n\\n[Reach out](mailto:admin@openfn.org) for more information."},{"id":"/2020/07/14/cron-is-better-than-a-timer","metadata":{"permalink":"/articles/2020/07/14/cron-is-better-than-a-timer","editUrl":"https://github.com/openfn/docs/edit/main/articles/2020-07-14-cron-is-better-than-a-timer.md","source":"@site/articles/2020-07-14-cron-is-better-than-a-timer.md","title":"Product News: Enhanced Scheduled/Periodic Job Control","description":"Hi all, this is a quick one from the product team at","date":"2020-07-14T00:00:00.000Z","tags":[{"inline":true,"label":"annoucement","permalink":"/articles/tags/annoucement"},{"inline":true,"label":"tips","permalink":"/articles/tags/tips"}],"readingTime":1.81,"hasTruncateMarker":true,"authors":[{"name":"Taylor Downs","title":"Founder & CEO","page":{"permalink":"/articles/authors/taylor"},"email":"taylor@openfn.org","socials":{"x":"https://x.com/taylordowns2000","github":"https://github.com/taylordowns2000"},"imageURL":"https://avatars.githubusercontent.com/taylordowns2000","key":"taylor"}],"frontMatter":{"layout":"post","title":"Product News: Enhanced Scheduled/Periodic Job Control","authors":"taylor","tags":["annoucement","tips"],"featured":false},"unlisted":false,"prevItem":{"title":"Tracked entity instances in DHIS2","permalink":"/articles/2020/12/09/upsert-in-dhis2"},"nextItem":{"title":"Allow Yourself to Fail","permalink":"/articles/2020/07/02/allow-yourself-to-fail"}},"content":"Hi all, this is a quick one from the product team at\\n[OpenFn](https://openfn.org/) \u2014 we\'ve made a major upgrade to how timed/period\\njobs work.\\n\\n\x3c!--truncate--\x3e\\n\\nIn the past, if you weren\'t using OpenFn to drive some real-time (or\\n\\"event-based\\") automation, you\'d need to set up an \\"interval trigger.\\" Like the\\nphoto above, this was essentially a sand timer. Set your trigger to `10` seconds\\nand your job fetches data from DHIS2, some regional public health data set, or\\nwhatever, then cleans, transforms, and loads it into some other system.\\n\\nFor the most part, this has got the job done for the last 5 years, but as our\\nNGO and government clients came up with increasingly specific requirements on\\nnot only how often but _when_ a crucial job gets executed, we began finding\\nourselves creating little customizations for them on a once-off basis. We\'re\\nhappy to annouce that as of `v1.75` (released today), you can now schedule jobs\\nto run based on `cron` expressions, giving you incredible control over when your\\ntasks get executed.\\n\\n### Scheduling is better than timing.\\n\\nUsing `cron`, you can choose to run a job every minute by typing `* * * * *`.\\n\\nOr maybe you\'ve got a batch sync that you want to take place while your users\\nare asleep\u2014why not run it every night at 11pm with `23 * * * *`.\\n\\nWhat if you\'ve got to submit reuqests for medical inventory only during the\\nonset of flu season? Simply type `0 0 1 2-4 *` and your job will run at midnight\\nthe 1st of the month, from February through April.\\n\\nYou can still run jobs at the click of a button and create timers with\\nexpressions like `*/10 * * * *` for \\"every 10 minutes\\", but scheduling with cron\\ngives OpenFn.org users so much more control over how they run their\\norganizations. (And that\'s a good thing.)\\n\\nIf you\'re keen on learning by doing but don\'t have an OpenFn account yet,\\n[sign up for free](https://www.openfn.org/signup) or mess around with cron\\nexpressions at <a href=\\"https://crontab.guru\\" target=\\"_blank\\">crontab.guru</a>,\\na brilliant site to quickly build complex cron expressions.\\n\\nThat\'s all from product for today. Speak soon.\\n\\nTaylor"},{"id":"/2020/07/02/allow-yourself-to-fail","metadata":{"permalink":"/articles/2020/07/02/allow-yourself-to-fail","editUrl":"https://github.com/openfn/docs/edit/main/articles/2020-07-02-allow-yourself-to-fail.md","source":"@site/articles/2020-07-02-allow-yourself-to-fail.md","title":"Allow Yourself to Fail","description":"Hi all, this is a very short post with a simple message: design for failure.","date":"2020-07-02T00:00:00.000Z","tags":[{"inline":true,"label":"how-to","permalink":"/articles/tags/how-to"},{"inline":true,"label":"tips","permalink":"/articles/tags/tips"}],"readingTime":1.97,"hasTruncateMarker":true,"authors":[{"name":"Taylor Downs","title":"Founder & CEO","page":{"permalink":"/articles/authors/taylor"},"email":"taylor@openfn.org","socials":{"x":"https://x.com/taylordowns2000","github":"https://github.com/taylordowns2000"},"imageURL":"https://avatars.githubusercontent.com/taylordowns2000","key":"taylor"}],"frontMatter":{"layout":"post","title":"Allow Yourself to Fail","authors":"taylor","tags":["how-to","tips"],"featured":false},"unlisted":false,"prevItem":{"title":"Product News: Enhanced Scheduled/Periodic Job Control","permalink":"/articles/2020/07/14/cron-is-better-than-a-timer"},"nextItem":{"title":"To Automate or Not to Automate? Ask Yourself These 3 Questions.","permalink":"/articles/2020/06/24/three-questions-to-ask"}},"content":"Hi all, this is a very short post with a simple message: design for failure.\\nEven if you\'ve never heard of\\n[MSSQL](https://www.microsoft.com/en-us/sql-server) (or\\n[Azure](https://azure.microsoft.com/en-us/), or Microsoft?), I want to talk for\\none moment about the importance of upserts and a funny developer term called\\n\\"idempotence.\\"\\n\\n\x3c!--truncate--\x3e\\n\\nWe just extended our\\n[language-mssql adaptor](https://github.com/OpenFn/language-mssql) with a custom\\nfunction that allows upserts (an `upsert` is when you either insert a new record\\nor update an existing record based on some identifier). Before, you\'d need to\\nwrite something tedious like:\\n\\n```js\\nsql({\\n  query: `MERGE my_table AS [Target]\\n          USING (SELECT \'8675309\' AS some_unique_id, \'writing_blog_posts\' AS skill) AS [Source]\\n          ON [Target].some_unique_id = [Source].some_unique_id\\n          WHEN MATCHED THEN\\n            UPDATE SET [Target].some_unique_id=8675309, [Target].skill=\'writing_blog_posts\'\\n          WHEN NOT MATCHED THEN\\n            INSERT (some_unique_id, skill) VALUES ([Source].some_unique_id, [Source].skill);`,\\n});\\n```\\n\\nwhereas now you can simply write:\\n\\n```js\\nupsert(\'my_table\', \'some_unique_id\', {\\n  some_unique_id: 8675309,\\n  skill: \'writing blog posts\',\\n});\\n```\\n\\nFor an operation to be idempotent means that it can be repeated time and time\\nagain without producing an unintended result. This is SUPER important for\\ncreating S3 (**S**ecure, **S**table and **S**calable\u2014more on that\\n[here](https://openfn.org/trust)) integrations because it provides you with two\\n\\"get-out-of-jail-free\\" cards.\\n\\n1. If a destination application fails, if a connection times out, or if (for\\n   whatever reason) you\'re not sure if the `job` was completed (say... making a\\n   payment to CHW) then an idempotent operation can be RETRIED without fear of\\n   making a double-payment.\\n\\n2. If you make some change to how your `job` works, make some modification to\\n   one of your destination systems, or just because you want to be _extra extra\\n   sure_ that all the data in a 9 month survey made it to the national public\\n   health reporting system, you can _REPROCESS_ every single message that\'s come\\n   through OpenFn at the click of a button, without having to worry about\\n   duplicates.\\n\\nSo... when clients let me mess around with their jobs, I _always_ recommend we\\ndesign for idempotence. It\'s common sense when you\'re passing messages between\\ntwo different systems that are bound to evolve, go offline, have a bad day, etc.\\n\\n\u2014 Taylor\\n\\n[Sign up](https://openfn.org/register) to set up a project today, absolutely\\nfree.\\n\\n[Reach out](mailto:admin@openfn.org) for more information."},{"id":"/2020/06/24/three-questions-to-ask","metadata":{"permalink":"/articles/2020/06/24/three-questions-to-ask","editUrl":"https://github.com/openfn/docs/edit/main/articles/2020-06-24-three-questions-to-ask.md","source":"@site/articles/2020-06-24-three-questions-to-ask.md","title":"To Automate or Not to Automate? Ask Yourself These 3 Questions.","description":"Automation can save time, unlock critical resources, and enable scale\u2013but it","date":"2020-06-24T00:00:00.000Z","tags":[{"inline":true,"label":"tips","permalink":"/articles/tags/tips"}],"readingTime":2.84,"hasTruncateMarker":true,"authors":[{"name":"Aleksa Krolls","title":"Co-Founder, Chief Customer Officer","page":{"permalink":"/articles/authors/aleksa"},"email":"aleksa@openfn.org","socials":{"github":"https://github.com/aleksa-krolls"},"imageURL":"https://avatars.githubusercontent.com/aleksa-krolls","key":"aleksa"}],"frontMatter":{"layout":"post","title":"To Automate or Not to Automate? Ask Yourself These 3 Questions.","authors":"aleksa","tags":["tips"],"featured":true},"unlisted":false,"prevItem":{"title":"Allow Yourself to Fail","permalink":"/articles/2020/07/02/allow-yourself-to-fail"},"nextItem":{"title":"How Information Is Organized... In Organizations","permalink":"/articles/2020/06/16/how-information-is-organized"}},"content":"Automation can save time, unlock critical resources, and enable scale\u2013but it\\ntypically requires investment to set up. Wondering whether you should automate\\nyour processes? Ask yourself these 3 questions.\\n\\n\x3c!--truncate--\x3e\\n\\n### Our partners use [OpenFn](https://openfn.org) automation solutions to drive efficiency and scale their processes, delivering integrated digital systems that work better, faster, and together.\\n\\nTo date, we have worked with 43 social sector organizations that operate across\\nsectors\u2013from health, education, and agriculture, to livelihoods and emergency\\nresponse. Over the last 6 years, OpenFn has been implemented worldwide for a\\nwide range of use cases, including building real-time data monitoring systems,\\nstreamlining data cleaning pipelines, securely exchanging sensitive information,\\nand automating routine processes like uploading indicator results, sending\\nSMS/email alerts, making mobile payments,\\n[and more](https://openfn.org/solutions).\\n\\nBy connecting any app, OpenFn can integrate and automate all apps within a\\ndigital ecosystem. However, a question that we frequently ask our partners is:\\n\\n#### Just because you _can_ automate\u2014_should_ you?\\n\\nWhile integration and automation have the potential to enable scale and save\\ntime and money (we\u2019ve learned this from our\\n[partners](https:openfn.org/clients)), solutions require investment to set up\\nand maintain. These costs sometimes outweigh expected efficiency gains and\\nservice outcomes. Therefore, when evaluating the cost-benefit of investing in\\nautomation and integration solutions, we at Open Function Group typically ask 3\\nkey questions.\\n\\n#### 1. Security \u2014 Will automation limit the exposure of sensitive data?\\n\\nCan the exposure of sensitive data be limited by integrating with secure API\\nendpoints (rather than relying on human beings to interact with those data, for\\nexample)? Or by automating a data cleaning process?\\n\\n#### 2. Accuracy \u2014 Will automation increase data accuracy and reduce data entry errors?\\n\\nCan the process take place more reliably by limiting the opportunity for human\\nerror (in automating data manipulation or simple algorithmic work, for example)?\\n\\n#### 3. Speed \u2014 Will automation increase the speed of impact?\\n\\nCan the process be done more quickly via automation and is there value in having\\nit done faster? (The answer to the first part is almost always yes, but\\nsometimes there\'s not actually lots of value generated by doing something\\nfaster.)\\n\\n#### If you find yourself answering \u201cyes\u201d to these questions, it may be time to consider automating critical processes at your organization.\\n\\nTasks that meet these 3 criteria, take a lot of time to complete or are very\\nrepetitive, and/or involve moving data between apps are typically great\\ncandidates for automation.\\n\\nIf you find yourself answering \u201cno\u201d, then it may not be worth the investment in\\nautomation... at least not yet. This is especially true if these processes are\\nstill in flux or require a lot of human involvement to complete. That said, now\\nmay be a good time to refine your existing workflows, think about how your\\nprocesses might change at scale, and consider what _new_ processes, services, or\\noutcomes could be unlocked by automation.\\n\\n### Delegate your busywork to OpenFn, and try it today!\\n\\nIf you want to try out automation for your organization,\\n[sign up](https://www.openfn.org/signup) for OpenFn, free of charge. Check out\\n[our documentation](https://docs.openfn.org/) and\\n[website](http://www.openfn.org) to learn how to get started.\\n\\nHaving trouble setting up your first automation \\"job\\"? Email us at\\n[admin@openfn.org](mailto:admin@openfn.org) for support. Our team is always\\nhappy to assist and help you evaluate the total cost of ownership of automation\\nsolutions."},{"id":"/2020/06/16/how-information-is-organized","metadata":{"permalink":"/articles/2020/06/16/how-information-is-organized","editUrl":"https://github.com/openfn/docs/edit/main/articles/2020-06-16-how-information-is-organized.md","source":"@site/articles/2020-06-16-how-information-is-organized.md","title":"How Information Is Organized... In Organizations","description":"Does your organization\'s information have an underlying structure? Try this exercise using boxes and crow\'s feet.","date":"2020-06-16T00:00:00.000Z","tags":[{"inline":true,"label":"how-to","permalink":"/articles/tags/how-to"},{"inline":true,"label":"tips","permalink":"/articles/tags/tips"}],"readingTime":5.84,"hasTruncateMarker":true,"authors":[{"name":"Taylor Downs","title":"Founder & CEO","page":{"permalink":"/articles/authors/taylor"},"email":"taylor@openfn.org","socials":{"x":"https://x.com/taylordowns2000","github":"https://github.com/taylordowns2000"},"imageURL":"https://avatars.githubusercontent.com/taylordowns2000","key":"taylor"}],"frontMatter":{"layout":"post","title":"How Information Is Organized... In Organizations","authors":"taylor","tags":["how-to","tips"],"image":"/img/informationorganized.jpg","featured":false},"unlisted":false,"prevItem":{"title":"To Automate or Not to Automate? Ask Yourself These 3 Questions.","permalink":"/articles/2020/06/24/three-questions-to-ask"}},"content":"#### Does your organization\'s information have an underlying structure? Try this exercise using boxes and crow\'s feet.\\n\\nThis article was originally posted by Taylor Downs, Head of Product, on\\n[The OpenFn Founder\'s blog](https://medium.com/@taylordowns2000) as \\"The power\\nof crow\'s feet.\\"\\n\\nIt\u2019s Saturday Morning in Cape Town and I\u2019ve just spent an hour talking about how\\na non-profit is organized. I thought I was getting into a technical\\ndiscussion\u2014I\u2019ve been doing system architecture discussions for years\u2014but what we\\nended up talking about was how this NGO thinks.\\n\\n\x3c!--truncate--\x3e\\n\\nThis engagement is largely about mapping an already existing \u201cpeople & paper\u201d\\nbased system to technology. Vera Solutions will build a system for this client\\nusing Open Data Kit for field data collection and Salesforce.com for the\\nmanagement \u201cback-end\u201d. Because we\u2019re not explicitly being asked to help redesign\\nprocesses at this organization, the client is \u201ctelling us how things are\u201d, then\\nexpecting us to create a relational database model that facilitates\\nbusiness-as-usual, only in a more efficient, digital way. Seems reasonable.\\n\\nThis organization runs multiple programs focusing on a handful of strategic\\nobjectives. They coordinate various activities in their target communities and\\nreport on those activities against numerous (sometimes overlapping) indicators.\\nSound familiar? As we get to the 3rd explanation of these programs, and the 11th\\niteration of the system schema, it hits me\u2026\\n\\n### Drawing a \\"relational object model\\" sounds technical, but it\'s actually an exercise in clear communication... and everyone can benefit from it.\\n\\nWhen we\u2014human beings\u2014wrestle with complex problems (like managing lots of\\nprograms, other humans, community stakeholders, etc.) we have the capacity to\\ntrick ourselves into thinking that we have wrapped our heads around a system\\n(for clinic registration, for after-school education, etc.) when, in fact, we\u2019re\\nengaging in mental hand-waving and are simply \u2018papering-over\u2019 sections which are\\nsecretly not just complicated, but totally incongruous with other parts of the\\nsystem. We can make ourselves believe that our logic is sound because we want it\\nto be sound, when in reality the organization might be held together by good\\npeople, not good, clear, defined processes. By learning a couple of key\\nconcepts, it\u2019s possible for non-technical people to articulate their thoughts\\nclearly using \u201cboxes\u201d and \u201ccrow\u2019s feet\u201d and see whether or not there is an\\nunderlying structure to their organization\u2019s information.\\n\\n### By forcing yourself to reduce complex systems to sketches containing only two elements, you\u2019ll be able to detect important conflicts and confusions in how you think about your organization that you might otherwise miss.\\n\\nIf you can\u2019t diagram the information structure in your organization using boxes\\nand crow\u2019s feet, it\u2019s a smell that something isn\u2019t quite right (or at least that\\nsomething isn\u2019t easily scalable\u2026 more on this later!). Let me show you the tools\\nin the toolbox and then wrap up by waxing poetic on people, processes, and\\ntechnology.\\n\\n### Boxes and crow\'s feet\\n\\n![](/img/box5.png)\\n\\nThe box is my favorite. It represents an entity in your data system. Entities\\n(like `teachers`) have attributes (like `name`, `phone number`, `date of birth`,\\n`gender`, etc.) Some people like thinking of entities as simple forms. The\\n\u201cTeacher Registration Form\u201d will ask for the teacher\u2019s name, phone number,\\ngender, etc. These are the fields on your teacher entity. By submitting one of\\nthese forms, you\u2019ll add a new teacher to your database. If you\u2019re an Excel\\nperson, the attributes are columns in your `teachers` table.\\n\\n![](/img/crowsfeet2.png)\\n\\nThe crow\u2019s foot is my second favorite. It\u2019s used to show relationships between\\nentities. We know that teachers are related to the sessions that they conduct.\\n(And `session` might be another entity, with fields like `date`,\\n`subject taught`, and `venue`, to name just a few.) The crow\u2019s foot allows us to\\nspecify exactly how they are related. On that session entity, we\u2019ll need to\\nspecify the name (or ID) of the teacher who led it. On the teacher entity,\\nhowever, there won\u2019t be a field to specify the name or ID of the session\u2026\\nbecause a single teacher can lead MANY sessions. This is a one-to-many\\nrelationship. The crow\u2019s foot (that little three-pronged fella) denotes the\\nmany. One teacher can have many sessions. One session, however, can only have\\none teacher. See the diagram below.\\n\\n![](/img/objectmodel3.png)\\n\\nIf we focus just on `teacher` and `session` and think back to MS Excel, we can\\nenvision a `teachers` table and a `sessions` table. Let\u2019s put them on different\\nsheets in the same workbook. On the `teachers` table, there is no column for\\n`session`, but on the `sessions` table, there _is_ a column for `teacher ID`.\\nWe\u2019ve just established a one-to-many relationship.\\n\\nNext time, we\u2019ll talk about what\u2019s going with the `attendance` entity above.\\nIt\u2019s sometimes called a \u201cjunction object\u201d or a \u201cjoin table\u201d, and it\u2019s what\\nallows MANY students to be related to MANY sessions. I\u2019ll write more on this\\nnext time, but there is no magic going on, no technicalities here. The way that\\nmany students are related to many sessions is through this Real World Concept\\nthat we call `attendance`. Attendance is what happens when a student shows up at\\na session. It\u2019s so important to get the language right in these discussions, and\\nmake sure that you\u2019re talking about real-world concepts.\\n\\n### Relational object models with lots of confusing terms are not \\"technical\\". They are \\"bad.\\"\\n\\nRemember that as you start to put pen to paper. And allow yourselves time (and\\nmultiple drafts) to get the boxes and terminology right. Understanding\\nrelational object modelling is an incredibly powerful way to organize a company.\\nAs I said before, if you can\u2019t model it with boxes and arrows, it\u2019s a smell that\\nsomething might not be conceptually sound.\\n\\n### A disclaimer and some thoughts on scaling:\\n\\nSome organizations do amazing work without good conceptual systems. They rely on\\nhumans, instinct, improvisation, nouse, and other not-so-clearly-defined things.\\nThey might do really great work. They might get the job done. But they need to\\nbe well aware of their condition and face it head on. If you can\u2019t systematize\\nyour program implementation processes, then you need to focus tremendous effort\\non finding and retaining the right people.\\n\\nA friend once told me that \u201cpeople are not scalable.\u201d I couldn\u2019t agree more, and\\ndefend my earlier stance that if your organization\u2019s information structure can\u2019t\\nbe defined with boxes and crow\u2019s feet, it may be very hard for you to scale\\nresponsibly. However, if you can create a ruthlessly efficient, world-class\\n\u201cpeople operations\u201d system (recruitment, training, management, compensation, HR,\\netc.) that ensures you\u2019ve always got the right people to figure things out you\\nmight be better off than those operating a well defined assembly-line with\\ninterchangeable parts. Alas, the middle way is probably the best.\\n\\nThat\u2019s all for now. More soon.\\n\\n_Need help organizing or scaling your organization\'s information or process\\nflows? Contact our team of ICT4D specialists at\\n[support@openfn.org](mailto:support@openfn.org)._"}]}}')}}]);