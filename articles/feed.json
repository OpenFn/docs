{
    "version": "https://jsonfeed.org/version/1",
    "title": "OpenFn Help Articles",
    "home_page_url": "https://docs.openfn.org/articles",
    "description": "OpenFn/docs Blog",
    "items": [
        {
            "id": "/2021/10/22/testing-react-app-with-jest-hound",
            "content_html": "<p>Have you ever struggled to layout the strategy for testing your React App? Well,\nyou are not alone! Here a few hints from the lessons I learned during my\nexperience testing a\n<a href=\"https://reactjs.org/\">React</a>/<a href=\"https://redux.js.org/\">Redux</a> app with a\n<a href=\"https://www.phoenixframework.org/\">Phoenix</a>/<a href=\"https://elixir-lang.org/\">Elixir</a>\nbackend.</p><h2>The Blurred Line</h2><p>Because a React app is built on\n<a href=\"https://reactjs.org/docs/react-component.html\">components</a>, the basic UI units,\nit is natural to think and organise your tests around components! And so unit\ntesting, in this case, would refer to &quot;component testing&quot;, which may be\nconfusing at times, especially when the concept of unit testing is again applied\nto testing functions such as Redux <code>reducers</code> and <code>action creators</code> or any other\nJavaScript function in your application.</p><p>The other challenge that I often faced was whether to write tests for each\ncomponent in isolation or write a test for a feature that encapsulates a set of\nrelated components. The later would be equivalent to writing what I would call\n&quot;integration tests&quot;.</p><p>Finally, one would say &quot;well then you could have just written the tests in a way\nthat resemble the way the application is used&quot;! This approach is commonly\nrecommended in the React community, but it quickly becomes really complex to\nmaintain the layers of separation between <strong><em>unit tests</em></strong>, <strong><em>integration\ntests</em></strong> and <strong><em>end-to-end tests</em></strong>.</p><h2>What did I learn?</h2><p>Given a React/Redux application, here is how I would organise my testing\nstrategy:</p><h3>Unit Tests</h3><ul><li><p>In a React app, <strong>unit tests</strong> will largely apply to testing &quot;helper\nfunctions&quot; and not to testing components, as justified in the next section.\nHelper functions, in this case, would refer to functions that live outside the\ncomponents and are neither Redux action creators nor reducers. These functions\ncan be used inside components, action creators, reducers or other parts of\nyour application.</p></li><li><p>Writing unit tests for &quot;helper functions&quot; would ensure their signatures and\nexpected outputs are protected against regressions. This would also ensure\ntheir use across components or other functions is consistent and as expected.</p></li><li><p>Where possible, each &quot;helper function&quot; must have its own <code>unit test</code>.</p></li><li><p>An example of a unit test would like:</p><pre><code class=\"language-javascript\">const sum = require(&#x27;../../js/sum&#x27;);\n\ntest(&#x27;adds 1 + 2 to equal 3&#x27;, () =&gt; {\n  expect(sum(1, 2)).toBe(3);\n});\n</code></pre></li><li><p>Write a <em>thousand</em> of these.</p></li></ul><h3>Integration Tests</h3><ul><li><p>In the context of a React/Redux app, component tests can be thought of as\n<strong>integration tests</strong>. This is because React components are built around\nfeatures such as <code>&lt;Signup /&gt;</code>, <code>&lt;Search /&gt;</code>, etc. So one React component can\nbe a mix of other components to achieve a UI feature set.</p></li><li><p>To test a component, write an <strong>integration test</strong> that covers the use of a\ngiven component for a given UI feature.</p></li><li><p>If a component being tested dispatches a Redux <code>action</code>, this is the right\nplace to test those actions and their effect on the UI.</p></li><li><p>Pay attention to the concept of <em>feature isolation</em> vs <em>component isolation</em>\nas it will help you write better integration tests and also easily mock\ncomponent contexts.</p></li><li><p>A classic example of <strong>feature isolation</strong> is when you have a <code>&lt;UserList /&gt;</code>\ncomponent which displays a list of users and has a <code>&lt;button /&gt;</code> to add a new\nuser. Writing a test for <code>&lt;UserList /&gt;</code> would be equivalent to testing a\nfeature.</p></li><li><p>In this example, one would be tempted to test the action of clicking on the\n<code>&lt;AddUserButton /&gt;</code> and further test the <code>&lt;NewUser /&gt;</code> form... nope! This is\nwhere we draw the line! Only test that the <code>&lt;UserList /&gt;</code> renders the mock\n<code>users</code> in the list and that the <code>&lt;AddUserButton /&gt;</code> is present/enabled. The\n<code>&lt;UserList /&gt;</code> feature ends there, otherwise you will be sliding into\n<strong>End-to-End</strong> testing :)! The <code>&lt;User /&gt;</code> component, although it is invoked by\n<code>&lt;UserList /&gt;</code> component, it is isolated enough to be tested in its own\nintegration test.</p></li><li><p>Testing components this way would make &quot;context mocking&quot; easier for\ncomponents.</p></li><li><p>Another important benefit for isolating testing context, as in the example\nabove, is that it will be easier to mock the <code>redux actions</code> and/or api calls\nusing tools such as <a href=\"https://jestjs.io/\">Jest</a> and\n<a href=\"https://mswjs.io/\">Mock Service Worker</a> (or &quot;msw&quot;) as explained in the\n<a href=\"#choosing-testing-tools\">Choosing Tools</a> section.</p></li><li><p>The value of writing integration tests for components, in this way, ensures\nthat a given component renders the UI consistently, given all possible\ncombinations of contexts and interactions. This will also allow you to ensure\nredux actions invoked by the component are called as expected and with the\ncorrect arguments.</p></li><li><p>An example component integration test would look like:</p><pre><code class=\"language-javascript\">// ....other imports\nimport { setupServer } from &#x27;msw/node&#x27;;\n// Tell jest to mock the module\njest.mock(&#x27;../js/actions/UserActions&#x27;, () =&gt; ({\n  ...jest.requireActual(&#x27;../js/actions/UserActions&#x27;),\n  saveUser: jest.fn(),\n}));\n\nimport { saveUser as mockSaveUser } from &#x27;../js/actions/UserActions&#x27;;\nconst server = setupServer(...handlers);\n  // Enable API mocking before tests\n  beforeAll(() =&gt; server.listen());\n  // Reset any runtime handlers we may add during the tests\n  afterEach(() =&gt; server.resetHandlers());\n  // Disable API mocking after the tests are done.\n  afterAll(() =&gt; server.close());\n  beforeEach(() =&gt; {\n    jest.clearAllMocks();\n  });\ndescribe(&#x27;&lt;AddUser/&gt;&#x27;, () =&gt; {\n\ntest(&#x27;create new user&#x27;, async () =&gt; {\n    const {getByPlaceholderText,getByText} = render(&lt;User {...defaultProps} /&gt;);\n    userEvent.type(getByPlaceholderText(&#x27;First Name&#x27;), &#x27;John&#x27;);\n    userEvent.type(getByPlaceholderText(&#x27;Last Name&#x27;), &#x27;Doe&#x27;);\n    userEvent.click(getByText(&#x27;Save&#x27;));\n    expect(mockSaveUser).toHaveBeenCalledTimes(1);\n    expect(mockSaveUser).toHaveBeenCalledWith({\n      firstName: &#x27;John&#x27;,\n      lastName: &#x27;Doe&#x27;,\n    });\n}\n\n</code></pre></li><li><p>Write a <em>good couple</em> of these.</p></li></ul><h3>End-to-End (e2e) Tests</h3><ul><li><p>In a React/Redux App, this would mean testing a <em>full flow</em> of a given\nfeature. <strong>end-to-end tests</strong> would require launching the entire application,\nincluding the backend, to run a given test.</p></li><li><p>Note that <strong>end-to-end tests</strong> are different from <strong>integration tests</strong> as\nthey require the entire App to run and render the full flow to your component\nunder test.</p></li><li><p>With this understanding, consider writing <strong>e2e</strong> tests <em>per workflow</em>.</p></li><li><p>An example <strong>e2e workflow</strong> is the &quot;Viewing and adding users&quot; workflow.</p></li><li><p>The e2e test for this workflow would require a test runner to launch the app,\nlog-in, navigate to the users list page, verify existing users are in the\nlist, click on the Add New User button and confirm that the new user has been\nadded to the list.</p></li><li><p>As you can see, e2e tests have more dependencies and require that you setup\nyour testing environment in way that closely simulates your real application\nusage.</p></li><li><p>An example e2e test for a React/Redux App with a Phoenix/Elixir backend, using\n<code>Hound</code> as a test runner looks like this:</p></li></ul><pre><code class=\"language-elixir\">defmodule OpenFn.UsersTest do\n  setup do\n    user = insert(:user, confirmed_at: DateTime.utc_now())\n    {:ok, user: user }\n  end\n\n  @tag :integration\n  test &quot;Sign-up.&quot;, %{user: user} do\n    navigate_to(&quot;/sign-up&quot;)\n    form = find_element(:id, &quot;sign_up_form&quot;)\n\n    form\n    |&gt; find_within_element(:id, &quot;first-name&quot;)\n    |&gt; fill_field(&quot;John&quot;)\n\n    form\n    |&gt; find_within_element(:id, &quot;last-name&quot;)\n    |&gt; fill_field(&quot;Doe&quot;)\n\n    form\n    |&gt; find_within_element(:id, &quot;email&quot;)\n    |&gt; fill_field(&quot;doe@gmail.com&quot;)\n\n    form\n    |&gt; find_within_element(:id, &quot;save-button&quot;)\n    |&gt; click\n\n    assert page_title() === ~s/Welcome to my page/\n    end\nend\n</code></pre><ul><li>Write <em>only a few</em> of these.</li></ul><h2>Choosing Testing Tools</h2><p>There are many testing tools out there, but for a typical <em>React/Redux</em> app the\nfollowing tools should help you accomplish the above tasks:</p><ol><li><a href=\"https://jestjs.io/docs/getting-started\">Jest</a> as test runner for <strong>unit</strong>\nand <strong>integration</strong> tests.</li><li><a href=\"https://testing-library.com/docs/\">React Testing Library</a> used along with\nJest as an &quot;assertion library&quot; for integration tests.</li><li><a href=\"https://mswjs.io/docs/getting-started/install\">MSW</a> used along with Jest as\na REST API mocking library.</li><li><a href=\"https://hexdocs.pm/hound/readme.html\">Hound</a> as a test runner for <strong>e2e</strong>\ntests in Elixir/Phoenix apps.\n<a href=\"https://developers.google.com/web/tools/puppeteer\">Puppeteer</a> can also be\nused along with Jest.<ul><li>If Puppeteer is used, it will work seamlessly with Jest but only in\nheadless browser mode. It also reduces on tech stack since you will only\nneed Jest.</li><li>Hound gives you the ability to run your <strong>e2e</strong> tests both in <code>headless</code>\nand <code>browser</code> mode.</li></ul></li></ol><h2>Final thoughts and next steps</h2><p>Testing a React App can be really hard, but worth it! By building\n<code>Aria-accessible</code> components ahead of time, you save yourself ðŸ’° and good\nhealth! A few more hints would be:</p><ul><li>Build clean, isolated and plugable components for your better testing\nexperience. &quot;God components&quot; can be a <em>pain</em> to test!</li><li>Using test runners such as Jest, that use <em>emulated</em> web browsers (e.g.,\n<code>jsdom</code>) rather than a real browser come with their own challenges in\nrendering and traversing complex DOM trees, especially if you are using UI\nlibraries such as <a href=\"https://mui.com/\">MUI</a>.</li><li>If using Jest for <strong>integration tests</strong>, I would recommend the components\nunder test have as few dependencies as possible to avoid the complexity\ninvolved in mocking http requests and waiting for asynchronous DOM rendering.</li></ul><p>What would I do differently? Here are my few thoughts:</p><ul><li>Organise and document detailed test cases for manual &quot;click testing&quot;.</li><li>Identify and clearly isolate components for <strong>integration tests</strong>.</li><li>Do not <em>delete</em> slow tests, instead re-write your component to be faster.\nRespect the linter&#x27;s advice, always!</li><li>Use a commonly supported frontend testing stack such as Jest, Msw, or\nPuppeteer for easier setup and community support.</li><li>Setup your test runner to use a test database. It helps, especially during\n<strong>e2e</strong> testing.</li><li>Always write <strong><em>all the three types</em></strong> of tests, whenever applicable.</li></ul><p>All this stuff for what?</p><ul><li>Well because regressions can be much more expensive to your organisation!\nWriting high quality and thoroughly tested software will save you ðŸ’° and help\nguarantee a maintainable codebase and a progressive software application.</li></ul><p>:::tip Still looking for the legend&#x27;s advice?</p><p>Gotcha, here you go...</p><ol><li>Swallow your pride and be humble: <em>always</em> do <strong>manual testing!</strong></li><li>Click test your way through the <strong>manual test cases</strong> for every new\ndeployment, catching regressions.</li><li><em>Lock in</em> your fixes and new features as <strong>unit tests</strong>, <strong>integration\ntests</strong>, and <strong>end-to-end tests</strong>.</li></ol><p>:::</p><p>Happy testing,</p><p>Chaiwa</p>",
            "url": "https://docs.openfn.org/articles/2021/10/22/testing-react-app-with-jest-hound",
            "title": "Testing a React app, the blurred line between Unit, integration and E2E",
            "summary": "Have you ever struggled to layout the strategy for testing your React App? Well,",
            "date_modified": "2021-10-22T00:00:00.000Z",
            "author": {
                "name": "Chaiwa Berian",
                "url": "https://github.com/chaiwa-berian"
            }
        },
        {
            "id": "/2021/10/08/improving-multistage-docker-builds-using-buildx",
            "content_html": "<p>So you&#x27;re using docker&#x27;s multi-stage builds and noticed that your build times\naren&#x27;t nearly as quick as you expected?</p><p>As many teams who spend more and more time using docker, it&#x27;s quite common to\nget into multi-stage builds; usually resulting in significantly smaller images.</p><p>However this comes with a pretty significant dilemma with caching. Even when\nusing the <code>--cache-from</code> flag when building, docker only caches the last image.</p><p>One proposed solution<sup><a href=\"#ref1\">1</a></sup>, is to pull, build and push each\nindividual stage. Coming with tight coupling between the shape of your\nDockerfile and your build process/scripts.</p><p>The other solution uses Docker Buildx which the document describes as:</p><blockquote><p>Docker Buildx is a CLI plugin that extends the docker command with the full\nsupport of the features provided by Moby BuildKit builder toolkit. It provides\nthe same user experience as docker build with many new features like creating\nscoped builder instances and building against multiple nodes concurrently.</p></blockquote><p>While that sounds pretty cool, it doesn&#x27;t really touch on caching. This actually\ntook me a while to find out that it would in fact do caching very differently.\nIn fact it&#x27;s a very different experience using it, and has lots of really cool\nfeatures that further detach you from the local docker state allowing you to\nbuild in environments that are stateless - such as Google CloudBuild without\nhaving to wire up some kind of persistence or file caching scheme.</p><h2>Buildx</h2><p>We&#x27;re only going to scratch the surface of Buildx, and with that let&#x27;s get the\nabsolute minimum working; build our image locally.</p><h3>Local Cache</h3><p>First things first we need to create a builder, and select it for use. This is\nimportant as without creating a buildx builder (and setting it as the default),\nbuildx will use the <code>docker</code> driver instead of the <code>docker-container</code> driver\nwhich we want in order to take advantage of cache exporting.</p><pre><code>docker buildx create --name mybuilder --use\n</code></pre><blockquote><p>You only need to run this once, except in the case of CloudBuild where each\ninvocation is a new node.</p></blockquote><pre><code>docker buildx build \\\n  --cache-from=type=local,src=/tmp/buildx-cache \\\n  --cache-to=type=local,dest=/tmp/buildx-cache \\\n  --load \\\n  .\n</code></pre><p>While the <code>--cache-*</code> options aren&#x27;t specifically required when running <code>build</code>,\nas <code>buildx</code> does manage its own local cache (distinct from the regular docker\ncache), it&#x27;s there to emphasise the options that cache can be provided via the\nCLI options.</p><p>This is about as close as you get to a regular docker build, with the\nsignificant difference being that you have to specify where to cache from and\nto.</p><p>The <code>--load</code> flag is to tell buildx to set the output to the local docker\ndaemon. Without that you won&#x27;t actually get a resulting image to run. However,\ndepending on your use case, this could be seen as a convenience - if you&#x27;re\nwanting to run your tests inside your build; a resulting image isn&#x27;t\nparticularly useful.</p><h3>Remote Cache</h3><p>Now comes to the part I&#x27;m most interested in, caching in a stateless/remote\nenvironment. Multipart builds for us at OpenFn are essential, since we use\nElixir and like other compiled languages there is a lot to be gained by only\nshipping the stuff you&#x27;re going to run; and no language is safe from requiring\nseveral times more &#x27;stuff&#x27; in order to build our apps.</p><p>Buildx supports a\n<a href=\"https://github.com/docker/buildx/blob/master/docs/reference/buildx_build.md#-export-build-cache-to-an-external-cache-destination---cache-to\">handful of different types</a>\nof caching sources and destinations. We&#x27;re going to be using the <code>registry</code>\ntype, where you point the cache at a repository reference (repo/image:tag\nstyle).</p><blockquote><p>One thing to note is that Google Container Registry does not support the\nmetadata/manifest format that buildx uses, so if you&#x27;re using Google Cloud you\nwill need to start using Artifact Registry.</p></blockquote><p><strong>Inline</strong></p><p>Push the image and the cache together:</p><pre><code>...\n--cache-from=type=registry,ref=$IMAGE_NAME \\\n--cache-to=type=inline \\\n...\n</code></pre><p>This comes with the constraint that cache mode is always <code>min</code>, which only\nexports/caches the resulting layers; which is still better than the plain docker\nbuild caching but I think having the intermediary layers is generally a win. We\nwant to avoid a single line change invalidating an entire build step.</p><p><strong>Registry</strong></p><p>Resulting image and cache are separated:</p><pre><code>...\n--cache-from=type=registry,ref=$IMAGE_NAME-build-cache \\\n--cache-to=type=registry,ref=$IMAGE_NAME-build-cache,mode=max \\\n...\n</code></pre><p>Again coming back to the cache mode, here being <code>max</code>; all intermediary laters\nare exported to the cache image as well.</p><p>I have opted to create <em>two</em> images, one for caching and another for the\nresulting image used to deploy. This gains us a much more granular cache and the\nability to more easily manage the cache image - like deleting the whole thing\nwhen wanting to invalidate the cache. Not to mention I&#x27;m fairly sure the size of\nour images that get pulled on kubernetes would get significantly larger with\nmany more layers.</p><p>It feels like a safer bet to have lean images for kubernetes to pull, and chunky\ncache images specifically for speeding up build.</p><p>Depending on your setup, pulling large images can get <em>seriously</em> expensive in a\nreasonably active deployment environment - like on AWS ECS without using\nPrivateLink.</p><blockquote><p>It appears the <code>moby/buildkit</code> documentation also demonstrates\n<a href=\"https://github.com/moby/buildkit#registry-push-image-and-cache-separately\">this</a>\napproach.</p></blockquote><pre><code>IMAGE_NAME=us-east4-docker.pkg.dev/&lt;project-name&gt;/platform/app \\\ndocker buildx build \\\n  -t $IMAGE_NAME:latest \\\n  --cache-from=type=registry,ref=$IMAGE_NAME-build-cache \\\n  --cache-to=type=registry,ref=$IMAGE_NAME-build-cache,mode=max \\\n  --push \\\n  --progress=plain \\\n  .\n</code></pre><p>This implies that the cache image is named with the suffix <code>-build-cache</code>:<br/>\n<code>us-east4-docker.pkg.dev/&lt;project-name&gt;/platform/app[-build-cache]</code>.</p><p>The <code>--push</code> argument tells buildx to push the resulting image to the registry.</p><h2>Tips</h2><p><strong>Clearing the local cache</strong></p><p>As mentioned before, buildx has its own cache and in order to clear the cache\nwhile debugging and readying a Dockerfile for remote building you&#x27;ll probably\nneed to reach for <code>docker buildx prune</code>.</p><h2>Closing thoughts</h2><p>Using buildx has been a really pleasant experience, having personally attempted\nusing it a few times over the last 3 years; the most recent one being the first\ntime I felt confident getting it into production. As with any sufficiently\nflexible build tooling, the errors and issues you can run into range from\ncomplete gibberish, genuinely concerning inconsistencies to architectural\nchoices that you haven&#x27;t fully caught up on; requiring an ever growing list of\nchanges you need to make to your own build process.</p><p>Our initial observations have been great, reasonable changes on our build have\ngone from 28 minutes to around 9 minutes.</p><p>While I have encountered a few confusing cache invalidations, especially when\nbuilding locally, exporting the cache to a repository and then having CloudBuild\nuse the image cache. And occasionally locally having what feels like <em>really</em>\naggressive caching on intermediate steps, leading me to pruning the local cache.</p><p>But overall, these issues aren&#x27;t necessarily buildx issues and more likely a\ncombination of building docker images in general except with many more steps\naccounted for by the cache.</p><p>It&#x27;s kinda hard to see now what the exact issues I had with it in the past, but\nhey!</p><p>Buildx has given me what I &#x27;expected&#x27; with docker multi-stage builds, and having\nthe cache in a repository completely side-steps having to attach a shared volume\nor copying from a storage bucket.</p><h2>Resources</h2><ul><li><a href=\"https://pythonspeed.com/articles/faster-multi-stage-builds/\">Multi-stage builds #3: Speeding up your builds</a><a name=\"ref1\"><sup>1</sup></a></li><li><a href=\"https://docs.docker.com/buildx/working-with-buildx/\">Docker Buildx</a></li><li><a href=\"https://github.com/docker/buildx/blob/master/docs/reference/buildx_build.md#buildx-build\">buildx build reference</a></li><li><a href=\"https://github.com/moby/buildkit#registry-push-image-and-cache-separately\">mody/buildkey Registry cache exporter</a></li></ul>",
            "url": "https://docs.openfn.org/articles/2021/10/08/improving-multistage-docker-builds-using-buildx",
            "title": "Improving Multistage Docker Builds using Buildx",
            "summary": "So you're using docker's multi-stage builds and noticed that your build times",
            "date_modified": "2021-10-08T00:00:00.000Z",
            "author": {
                "name": "Stuart Corbishley",
                "url": "https://github.com/stuartc"
            }
        },
        {
            "id": "/2021/07/05/wrapping-my-head-around-jobs",
            "content_html": "<p>Jobs are business processes turned into functional-style scripts. What does that\nmean, how should you approach writing jobs?</p><p>First, this is how <em>I</em> think about jobs and what we do at Open Function Group to\ntry to make our job code as readable, future-proof, and concise as possible.\nThere are a million different ways to approach writing jobs. This is one.</p><h2>It all starts with <code>state</code></h2><p>If a job is a set of instructions for a chef (a recipe?) then the initial\n<code>state</code> is all of the ingredients they need tied up in a perfect little bundle.\nIt usually looks something like this:</p><pre><code class=\"language-json\">{\n  &quot;configuration&quot;: {\n    &quot;hostUrl&quot;: &quot;https://moh.kenya.gov.ke/dhis2&quot;,\n    &quot;username&quot;: &quot;taylor&quot;,\n    &quot;password&quot;: &quot;very-secret&quot;\n  },\n  &quot;data&quot;: {\n    &quot;type&quot;: &quot;registration&quot;,\n    &quot;patient&quot;: {\n      &quot;age&quot;: 24,\n      &quot;gender&quot;: &quot;M&quot;,\n      &quot;nationalId&quot;: &quot;321cs7&quot;\n    }\n  }\n}\n</code></pre><p>This might be the initial <code>state</code> for a real-time, message-triggered job. Some\nsource system generated a new patient payload and sent that payload to OpenFn.\nThe data from our source system will wind up in <code>state.data</code>. Now if my job is\nmeant to take this new patient registration information and use it to create a\nnew record in the national health record system, I&#x27;ll also need to provide my\nrobot-chef here with a credential so they can access that system. The credential\nI&#x27;ve specified will get put into <code>state.configuration</code> and now our &quot;raw\ningredients&quot; are all ready for our robot chef.</p><p>Note that even if this job was initiated by a cron trigger (e.g., &quot;Hey chef,\nprepare this recipe every Tuesday at 7pm&quot;) or by a flow/catch trigger (e.g.,\n&quot;Hey chef, prepare this recipe only when you <em>fail</em> to make banana pancakes&quot;) it\nwill have an initial state.</p><p><strong>Every job, and every operation inside that job (think &quot;step&quot; in a recipe) is\ncalled with <code>state</code> and returns <code>state</code> when it&#x27;s done.</strong></p><p>Initial state for a cron triggered job might look like this:</p><pre><code class=\"language-json\">{\n  &quot;configuration&quot;: {\n    &quot;hostUrl&quot;: &quot;https://moh.kenya.gov.ke&quot;,\n    &quot;apiKey&quot;: &quot;abc123&quot;\n  },\n  &quot;data&quot;: {},\n  &quot;lastProcessedId&quot;: 321\n}\n</code></pre><p>And for a fail triggered job like this:</p><pre><code class=\"language-json\">{\n  &quot;configuration&quot;: {\n    &quot;hostUrl&quot;: &quot;https://moh.kenya.gov.ke&quot;,\n    &quot;apiKey&quot;: &quot;abc123&quot;\n  },\n  &quot;data&quot;: {},\n  &quot;lastProcessedId&quot;: 321,\n  &quot;error&quot;: [&quot;Required field missing&quot;, &quot;Patient Surname&quot;, &quot;Line 43&quot;]\n}\n</code></pre><p>No matter what, jobs start with state. See\n<a href=\"/documentation/jobs/state/\">&quot;Initial and final state for runs&quot;</a> for a detailed\nbreakdown.</p><h2>It ends with <code>state</code> too</h2><p>Now that we&#x27;ve got it in our heads that <code>state</code> is the raw ingredients you hand\nto your chef when you ask them to prepare a recipe, let&#x27;s look at the recipe.\nBoiled down (excuse the pun) a job for loading those patients into the national\nhealth record system might look like this:</p><pre><code class=\"language-js\">get(&#x27;/api/insuranceRegistrations&#x27;);\npost(&#x27;/api/patients&#x27;, { ...someData });\npost(&#x27;/api/visits&#x27;, { ...someData });\n</code></pre><p>We&#x27;re telling our chef to take those raw ingredients (login info for our\nnational health system and a chunk of information about a newly registered\npatient) and do the following:</p><ol><li>Find out whether this person already has a national health insurance number</li><li>Add this person to the patient registry (making use of some insurance data\nfrom step 1)</li><li>Add a visit record with information about this initial visit (making use of\npatient registry data from step 2)</li></ol><p>When all of this is done, we&#x27;ll not only have a new patient and visit logged in\nthe national health registry, but we&#x27;ll also return a final <code>state</code> object with\ninformation about what we&#x27;ve done that can be used in subsequent jobs. Imagine\nthat we want to make a cash transfer to this patient so that they can take a cab\nto the next visitâ€”we might create a job with the Mpesa adaptor that takes the\nfinal state of this first job as its <em>initial state</em>. In this way, jobs are\ncomposable.</p><p>But what about the complexity inside our jobâ€”in order to complete step 2, we\nneed some data from the insurance registry and we only get that data in step 1.\nCrucially, each operation (again, think &quot;step&quot; in a recipe) takes state and\nreturns state. In effect, the OpenFn execution pipeline simply calls all of your\naction methods <em>with state</em>, passing it along from one operation to the next,\nwaiting for each to finish and using the output from the first as the input for\nthe second.</p><p>While you may write your <code>get</code>, <code>post</code>, <code>post</code> job as it&#x27;s show above, the way\nit&#x27;s handled by OpenFn is actually more like:</p><pre><code class=\"language-js\">return get(&#x27;/api/insurance&#x27;, { ...useDataFromState })(state)\n  .then(state2 =&gt; post(&#x27;/api/&#x27;, { ...useDataFromState2 })(state2))\n  .then(state3 =&gt; post(&#x27;/api/visits&#x27;, { ...useDataFromState3 })(state3));\n</code></pre><p>Each of these operations returns a function which <em>takes state</em> and returns\nstate. This means that <em>within</em> a job, you are essentially modifying <code>state</code>,\ncreating/manipulating records in external systems, and returning <code>state</code>.</p><p>It opens up a really interesting world of possibility for data manipulation,\ncleaning, or transformation. Consider what we might do <em>after</em> we get data from\nthe insurance registry but <em>before</em> we create that patient in the national\npatient registry:</p><pre><code class=\"language-js\">get(&#x27;/api/insuranceRegistrations&#x27;);\nfn(state =&gt; {\n  console.log(state.data); // let&#x27;s look at the response from the insurance API.\n  state.data.people.filter(p =&gt; p.HasActiveInsurance); // and modify the payload to only retain those with active insurance\n  return state; // before returning state for our create patients operation.\n});\npost(&#x27;/api/patients&#x27;, { ...someData });\npost(&#x27;/api/visits&#x27;, { ...someData });\n</code></pre><p>We might even need to do some manipulation <em>before</em> we send a <code>get</code> request to\nthe insurance registry. That&#x27;s no problem:</p><pre><code class=\"language-js\">fn(state =&gt; {\n  state.data.registrationType = state.data.age &gt; 18 ? &#x27;Adult&#x27; : &#x27;Minor&#x27;;\n  return state; // before returning state for our create patients operation.\n});\nget(&#x27;/api/insuranceRegistrations&#x27;, {\n  query: { type: dataValue(&#x27;registrationType&#x27;) },\n});\nfn(state =&gt; {\n  state.data.people.filter(p =&gt; p.HasActiveInsurance);\n  return state;\n});\npost(&#x27;/api/patients&#x27;, { ...someData });\npost(&#x27;/api/visits&#x27;, { ...someData });\n</code></pre><p>Here, we&#x27;ve added a step to modify the initial <code>state</code> before we send that first\n<code>get</code> request to the insurance API. We determine if the new patient is a minor,\nand then use that newly calculated data to apply a query to the insurance API\nrequest.</p><p>Using <code>fn(state =&gt; state)</code> or <code>alterState(state =&gt; state})</code> is incredibly\nuseful, because it allows us to separate our data manipulation, calculation, and\nraw Javascript (which will be harder for low-tech users to understand) from our\nexternal actions. Let&#x27;s explore that some more.</p><h2>Keeping external actions clean</h2><p>Inside each operation we could do some data manipulation... all of these\noperations, across the many different language packages, allow for inline data\nmanipulation like this:</p><pre><code class=\"language-js\">get(&#x27;/api/insuranceRegistrations&#x27;, {\n  query: state =&gt; {\n    console.log(&quot;I&#x27;m doing some fancy stuff here.&quot;);\n    return { type: state.data.age &gt; 18 ? &#x27;Adult&#x27; : &#x27;Minor&#x27; };\n  },\n});\npost(&#x27;/api/patients&#x27;, {\n  body: {\n    name: state =&gt; {\n      return `${state.data.firstName}${state.data.lastName}`;\n    },\n  },\n});\n</code></pre><p>But if you&#x27;re interacting with both technical and non-technical users, it makes\nfor harder to read jobs. Consider the following instead:</p><pre><code class=\"language-js\">// Perform calculations...\nfn(state =&gt; {\n  // Create several new calculated attributes...\n  state.data = {\n    ...state.data,\n    type: state.data.age &gt; 18 ? &#x27;Adult&#x27; : &#x27;Minor&#x27;,\n    fullName: `${state.data.firstName}${state.data.lastName}`,\n  };\n\n  return state;\n});\n\n// Get insurance data...\nget(&#x27;/api/insuranceRegistrations&#x27;, { query: { type: dataValue(&#x27;type&#x27;) } });\n\n// Create new patient...\npost(&#x27;/api/patients&#x27;, { body: { name: dataValue(&#x27;fullName&#x27;) } });\n</code></pre><p>Since we often have non-developers creating the external operations like <code>get</code>\nand <code>post</code> above, this pattern makes our handoff easier. The business analyst\ncan say &quot;I need to have a registration <code>type</code> field available for use when\nquerying the insurance registry.&quot; A developer might respond, &quot;Great! How do you\nwant to calculate it... I&#x27;ve got all of Javascript at my fingertips.&quot; That dev\ncan then make as many API calls as they&#x27;d like, perform as many\n<code>map.reduce(...)</code> calls as their heart desires to complete that calculation...\nso long as they make sure the hand off <code>state</code> to the business analyst&#x27;s\noperation with a valid <code>state.data.type</code> attribute.</p><p>A final benefit of this approach is that it becomes much easier to generate job\nscripts from Google Sheets. Our implementation team frequently works with\nnon-technical clients to generate field maps that look like this:</p><table><thead><tr><th>Path to Source Data</th><th>Destination Field</th><th align=\"right\">Auto-generated syntax (using concat)</th></tr></thead><tbody><tr><td>patient.fullName</td><td>name</td><td align=\"right\">field(&#x27;name&#x27;, dataValue(&#x27;patient.fullName&#x27;)),</td></tr><tr><td>patient.age</td><td>age</td><td align=\"right\">field(&#x27;age&#x27;, dataValue(&#x27;patient.age&#x27;)),</td></tr><tr><td>???</td><td>type</td><td align=\"right\">plz help us calculate &#x27;type&#x27; based on x, y, z</td></tr><tr><td>patient.sex</td><td>gender</td><td align=\"right\">field(&#x27;gender&#x27;, dataValue(&#x27;patient.sex&#x27;)),</td></tr></tbody></table><p>We can then copy and paste the syntax generated in that final column directly\ninto OpenFn and update the bits that need some sort of custom code, writing an\n<code>fn(state)</code> block or an <code>alterState(state)</code> block before the external action.</p><h2>Wrapping up</h2><p>Some key takeaways here:</p><ol><li><p>Jobs start and end with <code>state</code> â€” some raw ingredients that will be used in a\nrecipe.</p></li><li><p>Jobs are lists of <code>operations</code> â€” steps in a recipe that <em>each</em> take <code>state</code>,\n<em>do some stuff</em>, and then return <code>state</code>.</p></li><li><p>As you move through the steps in a job, you are modifying <code>state</code>. Each\nsubsequent step begins with the final state from the previous step.</p></li><li><p>It may be useful to keep all your custom Javascript data cleaning,\nmanipulation, etc., in a separate operation (e.g., <code>fn(state)</code> or\n<code>alterState(state)</code>) so that your external actions are clean and easy to\nfollow.</p></li></ol><p>Finally, taking a close look at how developers write those <code>fn(state)</code> steps\ntells us a lot about what the job execution pipeline is really doing:</p><pre><code class=\"language-js\">// here, &quot;fn&quot; is a function that takes state and returns state\nfn(state =&gt; {\n  console.log(&quot;I&#x27;m doing some cool stuff.&quot;);\n  //  I might create some new attribute...\n  state.myNewThing = true;\n\n  // And ALWAYS return state for the next operation to use...\n  return state;\n});\n</code></pre><p>I hope this gives you sense of how I think about structuring jobs and building\ndata pipelines or automation flows on OpenFn. We recognize that this stuff is\ncomplex, and are pushing our new documentation regularly, so please do get in\ntouch if you think there are ways we could improve this type of\nwalk-through/helper article.</p><p>Happy integrating,</p><p>Taylor</p>",
            "url": "https://docs.openfn.org/articles/2021/07/05/wrapping-my-head-around-jobs",
            "title": "Wrapping my head around jobs",
            "summary": "Jobs are business processes turned into functional-style scripts. What does that",
            "date_modified": "2021-07-05T00:00:00.000Z",
            "author": {
                "name": "Taylor Downs",
                "url": "https://github.com/taylordowns2000"
            }
        },
        {
            "id": "/2021/05/24/commcare-events",
            "content_html": "<p>This is a quick one, but I just got off an exciting call with an organization\nthat&#x27;s going to set up some jobs to move data into Salesforce from CommCare and\nrealized that despite this being one of our more common integration\nrequirements, we haven&#x27;t done a &#x27;tips&#x27; article for this type of project. Until\nnow.</p><p>So here goes. While this is by no means an exhaustive project planning template,\nhere are a few things to keep in mind if you&#x27;re planning to implement a CommCare\nto Salesforce integration on your own.</p><h2>Most people use &quot;Data Forwarding&quot; in CommCare</h2><p>First, most people make use of CommCare&#x27;s &quot;Data Forwarding&quot; feature to send form\nsubmissions and changes in cases (creation, update, closure, etc.) to OpenFn in\nreal-time. You can read about that\n<a href=\"/documentation/apps/commcare#forward-cases-andor-forms-from-commcare-to-openfn\">here</a>\nbut the key consideration at this planning stage is <em>when</em> you&#x27;ll be performing\noperationsâ€”<code>create(...)</code>, <code>update(...)</code>, <code>upsert(...)</code>, <code>query(...)</code>,\n<code>(bulk(...)</code>, etc.â€”in Salesforce and what data you&#x27;ll have access to.</p><p>Each time a form submission comes into CommCare, we&#x27;ll get a copy of that\nsubmission at OpenFn and can use that data to create or modify some records in\nSalesforce.</p><p>Likewise, each time a case gets updated (or created or closed) we&#x27;ll get a copy\nof the case with all the case &quot;properties&quot; and we can use that data to <em>do some\nstuff</em> in Salesforce.</p><p>If you are using &quot;Form Forwarding&quot;, the <code>trigger</code> you&#x27;d create in OpenFn might\nlook like this <code>{&quot;form&quot;:{&quot;@name&quot;:&quot;ART Adherence Self-Reporting Tool&quot;}}</code> and it\nwould trigger your <code>job</code> any time an &quot;ART Adherence Self-Reporting Tool&quot;\nsubmission arrived from CommCare, giving that job access to all of the data\ninside that submission.</p><h2>Working with the data that comes from CommCare</h2><p>Assuming you&#x27;re using making use of case management, the data that arrives from\nCommCare will look something like this:</p><pre><code class=\"language-json\">{\n  &quot;__query_params&quot;: {\n    &quot;app_id&quot;: &quot;some-long-id&quot;\n  },\n  &quot;app_id&quot;: &quot;some-long-id&quot;,\n  &quot;archived&quot;: false,\n  &quot;attachments&quot;: {\n    &quot;1621866020043.jpg&quot;: {\n      &quot;content_type&quot;: &quot;image/jpeg&quot;,\n      &quot;length&quot;: 16423,\n      &quot;url&quot;: &quot;https://www.commcarehq.org/a/your-project/api/form/attachment/some-uuid/1621866020043.jpg&quot;\n    },\n    &quot;form.xml&quot;: {\n      &quot;content_type&quot;: &quot;text/xml&quot;,\n      &quot;length&quot;: 2727,\n      &quot;url&quot;: &quot;https://www.commcarehq.org/a/your-project/api/form/attachment/some-uuid/form.xml&quot;\n    }\n  },\n  &quot;build_id&quot;: &quot;0ec83881cd0e420dad5c24ed3a5452fe&quot;,\n  &quot;domain&quot;: &quot;your-project&quot;,\n  &quot;edited_by_user_id&quot;: null,\n  &quot;edited_on&quot;: null,\n  &quot;form&quot;: {\n    &quot;#type&quot;: &quot;data&quot;,\n    &quot;@name&quot;: &quot;ART Adherence Self-Reporting Tool&quot;,\n    &quot;@uiVersion&quot;: &quot;1&quot;,\n    &quot;@version&quot;: &quot;2783&quot;,\n    &quot;@xmlns&quot;: &quot;http://openrosa.org/formdesigner/59E1207B-969F-402D-9EEE-675504036F78&quot;,\n    &quot;administrative&quot;: {\n      &quot;coach_verification&quot;: &quot;check_here&quot;,\n      &quot;visit_notes&quot;: &quot;&quot;,\n      &quot;vist_notes_to_save&quot;: &quot;&quot;\n    },\n    &quot;case&quot;: {\n      &quot;@case_id&quot;: &quot;1ec51ee9-5aef-4bd2-b7eb-7599856251bc&quot;,\n      &quot;@date_modified&quot;: &quot;2021-05-24T14:20:28.693000Z&quot;,\n      &quot;@user_id&quot;: &quot;332e893dcd1b413686621bd80aae0cd3&quot;,\n      &quot;@xmlns&quot;: &quot;http://commcarehq.org/case/transaction/v2&quot;,\n      &quot;update&quot;: {\n        &quot;consent_received&quot;: &quot;yes&quot;,\n        &quot;home_visit_notes&quot;: &quot;&quot;\n      }\n    },\n    &quot;meta&quot;: {\n      &quot;@xmlns&quot;: &quot;http://openrosa.org/jr/xforms&quot;,\n      &quot;appVersion&quot;: &quot;CommCare Android, version \\&quot;2.51.2\\&quot;(463994). App v2798. CommCare Version 2.51.2. Build 463994, built on: 2021-03-17&quot;,\n      &quot;app_build_version&quot;: 2798,\n      &quot;commcare_version&quot;: &quot;2.51.2&quot;,\n      &quot;deviceID&quot;: &quot;commcare_a39f55a5-c744-4e33-8e01-d17e7698894f&quot;,\n      &quot;drift&quot;: &quot;0&quot;,\n      &quot;geo_point&quot;: null,\n      &quot;instanceID&quot;: &quot;130c68c5-7d17-4086-8a85-27d7d7da2216&quot;,\n      &quot;timeEnd&quot;: &quot;2021-05-24T14:20:28.693000Z&quot;,\n      &quot;timeStart&quot;: &quot;2021-05-24T14:18:46.856000Z&quot;,\n      &quot;userID&quot;: &quot;332e893dcd1b413686621bd80aae0cd3&quot;,\n      &quot;username&quot;: &quot;some-chw&quot;\n    },\n    &quot;participant_information&quot;: {\n      &quot;participant_id&quot;: &quot;007&quot;,\n      &quot;name&quot;: &quot;taylor downs&quot;,\n      &quot;gender&quot;: &quot;male&quot;,\n      &quot;guardian_information&quot;: {\n        &quot;guardians_name&quot;: &quot;Fake Data&quot;,\n        &quot;guardians_phone_number&quot;: &quot;8675309&quot;,\n        &quot;guardians_signature&quot;: &quot;1621866020043.jpg&quot;,\n        &quot;relationship_to_participant&quot;: &quot;father&quot;\n      },\n      &quot;current_medications&quot;: [\n        { &quot;name&quot;: &quot;generic-1&quot;, &quot;active&quot;: true },\n        { &quot;name&quot;: &quot;fakelyn-notrealiol&quot;, &quot;active&quot;: false },\n        { &quot;name&quot;: &quot;sasstra-zenica&quot;, &quot;active&quot;: false },\n        { &quot;name&quot;: &quot;ibuprofen&quot;, &quot;active&quot;: true }\n      ]\n    },\n    &quot;tested_for_hiv_status_tested_for_hiv&quot;: &quot;OK&quot;,\n    &quot;visit_information&quot;: {\n      &quot;consent_given&quot;: &quot;yes&quot;,\n      &quot;date_consent_given&quot;: &quot;2021-05-23&quot;,\n      &quot;visit_date&quot;: &quot;2021-05-23&quot;\n    }\n  },\n  &quot;id&quot;: &quot;130c68c5-7d17-4086-8a85-27d7d7da2216&quot;,\n  &quot;indexed_on&quot;: &quot;2021-05-24T14:20:39.045971&quot;,\n  &quot;initial_processing_complete&quot;: true,\n  &quot;is_phone_submission&quot;: true,\n  &quot;metadata&quot;: {\n    &quot;appVersion&quot;: &quot;CommCare Android, version \\&quot;2.51.2\\&quot;(463994). App v2798. CommCare Version 2.51.2. Build 463994, built on: 2021-03-17&quot;,\n    &quot;app_build_version&quot;: 2798,\n    &quot;commcare_version&quot;: &quot;2.51.2&quot;,\n    &quot;deviceID&quot;: &quot;commcare_a39f55a5-c744-4e33-8e01-d17e7698894f&quot;,\n    &quot;drift&quot;: &quot;0&quot;,\n    &quot;geo_point&quot;: null,\n    &quot;instanceID&quot;: &quot;130c68c5-7d17-4086-8a85-27d7d7da2216&quot;,\n    &quot;location&quot;: null,\n    &quot;timeEnd&quot;: &quot;2021-05-24T14:20:28.693000Z&quot;,\n    &quot;timeStart&quot;: &quot;2021-05-24T14:18:46.856000Z&quot;,\n    &quot;userID&quot;: &quot;332e893dcd1b413686621bd80aae0cd3&quot;,\n    &quot;username&quot;: &quot;some-chw&quot;\n  },\n  &quot;problem&quot;: null,\n  &quot;received_on&quot;: &quot;2021-05-24T14:20:37.976363Z&quot;,\n  &quot;resource_uri&quot;: &quot;&quot;,\n  &quot;server_modified_on&quot;: &quot;2021-05-24T14:20:38.111789Z&quot;,\n  &quot;type&quot;: &quot;data&quot;,\n  &quot;uiversion&quot;: &quot;1&quot;,\n  &quot;version&quot;: &quot;2783&quot;\n}\n</code></pre><p>This is a big blob of <code>JSON</code>â€”the body of the message that&#x27;s received at OpenFn\nwhen this particular form (&quot;ART Adherence Self-Reporting Tool&quot;) is submitted in\nCommCareâ€”will be handed off to the job to start processing. The question is,\nwhat should we do?</p><p>When setting up for a self-service implementation on OpenFn, the most important\nthing you can do at this moment is carefully enumerate the data entry process\nthat you&#x27;d like a real human to follow. You can translate it to a job script\nlater.</p><p>You&#x27;ll need to write this up for your own case, but in this fictional example,\nhere&#x27;s the data entry process.</p><h2>The instructions for our worker</h2><p>:::tip</p><p>Right from the start, notice that we&#x27;re being incredibly explicit with these\ninstructions! We&#x27;re using the &quot;API Name&quot; (instead of just the &quot;label&quot;, which\nmight be ambiguous) of every field we want filled out in Salesforce and we&#x27;re\nusing the specific &quot;path&quot; to the data we want this person to enter from\nCommCare.</p><p><strong>Why are we being so specific?</strong> Because eventually, a computer will need to\ninterpret thisâ€”and they&#x27;re <em>terrible</em> with ambiguity!</p><p>:::</p><ol><li>Every time a messaged is received with\n<code>{&quot;form&quot;:{&quot;@name&quot;:&quot;ART Adherence Self-Reporting Tool&quot;}}</code> in the body (this is\nour trigger)</li><li>Log into Salesforce and create a new participant with the <code>participant_id</code>\nyou find in the <code>form.participant_information</code> section as their\n<code>Participant_Code__c</code>. (If one already exists in Salesforce with that code,\nthen update the existing record instead.)</li><li>Fill out the following fields in Salesforce based on the CommCare data in\nthis message:<ul><li><code>Name__c</code> with the data from <code>form.participant_information.name</code></li><li><code>Sex__c</code> with the data from <code>form.participant_information.gender</code></li><li><code>CommCare_Case_ID__c</code> with the data from <code>form.case.@case_id</code></li></ul></li><li>After you&#x27;ve created (or updated) this participant in Salesforce, create a\nrecord of the visit with the <code>instanceID</code> from the <code>metadata</code> section as the\nunique identifier <code>Visit_Code__c</code>. (Again, if there&#x27;s already a visit with\nthat ID please update the existing record.)</li><li>Fill out the following fields for the visit with data from CommCare&quot;<ul><li><code>Date__c</code> with <code>form.visit_information.visit_date</code>.</li><li><code>Consented__c</code> with <code>form.visit_information.consent_given</code>.</li><li>Always set <code>Test_Status__c</code> to <code>true</code>, regardless of what&#x27;s in the message\nfrom CommCare.</li><li>And relate this record with the <code>Community_Health_Worker</code> by their username\nin <code>form.metadata.username</code>.</li></ul></li><li>Finally, add a record for each medication listed in the\n<code>form.participant_information.current_medications</code> arrayâ€”matching on a unique\nID formed by a combination of the medication <code>name</code> and the <code>participant_id</code>\nso that we can update existing medication records if they&#x27;re present.</li><li>Fill out the following fields for the medication:<ul><li><code>Generic_Name__c</code> with <code>name</code></li><li><code>Status__c</code> with <code>active</code></li><li>And relate this record with the participant you created or updated in step\n2 via the <code>participant_id</code> field.</li></ul></li></ol><p>Phew... that&#x27;s the task. It&#x27;s just a fictional example and things could be much\nmore straightforward, or much more complicated than this, but it&#x27;s important to\nremember that if you can get to this level of <strong>precision and granularity</strong> in\nyour data entry process, a tool like OpenFn can automate this for you in a\nflash.</p><h2>Translating this into an OpenFn project</h2><p>If you&#x27;re streaming data in from CommCare and you&#x27;ve got your Salesforce system\nall set up so that this data entry person can complete the above steps (are all\nthe objects and fields created? are the right fields marked as &quot;unique&quot; and set\nto be used as an &quot;external id&quot; in the Salesforce administration section? have\nyou turned on data forwarding in CommCare?) then it&#x27;s time to turn them into an\nOpenFn project!</p><p>:::tip</p><p>A quick plug: <strong>Did you know that there&#x27;s an\n<a href=\"https://community.openfn.org\">OpenFn community forum</a></strong> where you can post\nstuff like the &quot;steps&quot; above and get help from other OpenFn users and staff\nconverting these steps into a real, working, OpenFn job?</p><p>Well, you do know! Check it out at\n<a href=\"https://community.openfn.org\">community.openfn.org</a></p><p>:::</p><h3>Create a Salesforce credential</h3><p>We don&#x27;t need a CommCare credential, since they&#x27;ll send data to us. Create a\nSalesforce credential that will allow the OpenFn worker to log into your\nSalesforce system.</p><p>Read more about credentials <a href=\"/documentation/build/credentials\">here</a>.</p><h3>Create a message-filter trigger</h3><ul><li>Select <code>Message Filter</code> for the <code>type</code></li><li>Enter <code>{&quot;form&quot;:{&quot;@name&quot;:&quot;ART Adherence Self-Reporting Tool&quot;}}</code> for the\n<code>inclusion criteria</code></li></ul><p>Read more about triggers <a href=\"/documentation/build/triggers\">here</a>.</p><h3>Create the job</h3><ul><li>Give it a name</li><li>Select the trigger you just created</li><li>Select the <code>salesforce</code> adaptor</li><li>Select the credential you just created</li></ul><p>And convert the instructions above to &quot;operations&quot; by using the inline help\nprovided by the Salesforce adaptor:</p><pre><code class=\"language-js\">// Use upsert to create or update a participant based on their participant code.\nupsert(\n  &#x27;Participant__c&#x27;,\n  &#x27;Participant_Code__c&#x27;,\n  fields(\n    field(\n      &#x27;Participant_Code__c&#x27;,\n      dataValue(&#x27;form.participant_information.participant_id&#x27;)\n    ),\n    field(&#x27;Name__c&#x27;, dataValue(&#x27;form.participant_information.name&#x27;)),\n    field(&#x27;Sex__c&#x27;, dataValue(&#x27;form.participant_information.gender&#x27;)),\n    field(&#x27;CommCare_Case_ID__c&#x27;, dataValue(&#x27;form.case[@case_id]&#x27;))\n  )\n);\n\n// Then upsert a visit using the visit code.\nupsert(\n  &#x27;Visit__c&#x27;,\n  &#x27;Visit_Code__c&#x27;,\n  fields(\n    field(&#x27;Visit_Code__c&#x27;, dataValue(&#x27;metadata.instanceID&#x27;)),\n    field(&#x27;Date__c&#x27;, dataValue(&#x27;form.visit_information.visit_date&#x27;)),\n    field(&#x27;Consented__c&#x27;, dataValue(&#x27;form.visit_information.consent_given&#x27;)),\n    // Always set status to true\n    field(&#x27;Test_Status__c&#x27;, true),\n    // And related this visit to the participant we just created by their &quot;code&quot;\n    relationship(\n      &#x27;Participant__r&#x27;,\n      &#x27;Participant_Code__c&#x27;,\n      dataValue(&#x27;form.participant_information.participant_id&#x27;)\n    )\n  )\n);\n\n// And finally for EACH mediation listed, create a medication record with a status\neach(\n  merge(\n    dataPath(&#x27;form.participant_information.current_medications[*]&#x27;),\n    fields(\n      field(&#x27;pID&#x27;, dataValue(&#x27;form.participant_information.participant_id&#x27;))\n    )\n  ),\n  upsert(\n    &#x27;Medication_Tx__c&#x27;,\n    &#x27;Medication_Tx_ID__c&#x27;,\n    fields(\n      field(Medication_Tx_ID__c, state =&gt; {\n        // Here, inside the medications array we&#x27;ve &quot;scoped&quot; state so that\n        // state.data, for each item in the array, looks like this:\n        // { pID: 007, name: &quot;sasstra-zenica&quot;, active: false }\n\n        // We will concatenate the participant ID with the medication name.\n        return state.data.pID + state.data.name;\n      }),\n      field(&#x27;Generic_Name__c&#x27;, dataValue(&#x27;name&#x27;)),\n      field(&#x27;Status__c&#x27;, dataValue(&#x27;status&#x27;)),\n      relationship(&#x27;Participant__r&#x27;, &#x27;Participant_Code__c&#x27;, dataValue(&#x27;pID&#x27;))\n    )\n  )\n);\n</code></pre><p>Now, every time this job runs (which is every time a CommCare form is submitted)\nyour OpenFn worker will upsert a <code>Participant</code>, upsert a <code>Visit</code>, and upsert a\nwhole list of <code>Medications</code> in Salesforce.</p><h2>What&#x27;s next</h2><p>Well, in our little example you&#x27;d turn the job &quot;on&quot; (setting it to on the\ninbound messages from CommCare) and let it run. Whenever there was a failure\n(maybe your Salesforce admin added a new required field on the\ncustom<code>Medication</code> object) you&#x27;d get an email and you&#x27;d have to come back to\nOpenFn to update your job, including that new field.</p><p>If you&#x27;re in the process of designing your CommCare and Salesforce systems at\nthe moment, this back-and-forth will be pretty common. Keep in mind that you\nwant as much simplicity as possible in those end-user systems because... well\nbecause <em>humans</em> have the interact with them every day!</p><p>So long as your processes are well defined, OpenFn can handle a bit of\ncomplexity (data cleaning, transformation, complex logical flows, etc.) but you\nshould never make sacrifices to the user experience in CommCare and\nSalesforceâ€”that&#x27;s a quick way to lose adoption.</p><p>So, ideally, you&#x27;ve designed your workflows in CommCare and Salesforce to make\nyour users happy and get them the information they need to do their jobs well\nand <em>then</em> you come back to OpenFn and spell out our data entry instructions\nlike we&#x27;ve done above.</p><h2>A final thought</h2><p>The two most important resources you&#x27;ve got at your disposal if you&#x27;re setting\nthis all up on your own are:</p><ol><li>this site (docs.openfn.org), and</li><li>the <a href=\"https://community.openfn.org\">forum</a> (community.openfn.org)</li></ol><p>Read through the\n<a href=\"/documentation/getting-started/so-you-want-to-integrate\">&quot;What is an integration&quot;</a>,\n<a href=\"/documentation/getting-started/terminology\">&quot;OpenFn Concepts&quot;</a>, and\n<a href=\"/documentation/build/jobs\">&quot;Build&quot;</a> sections if you&#x27;re a thorough,\nbackground-first kind of learner. If you crave snippets and sample job code,\nhead directly to the <a href=\"/library\">Job Library</a> to see how other OpenFn users are\ncreating their jobs.</p><p>Either way, keep the community posted on your progress in the forumâ€”you&#x27;ll find\nlots of helpful folks willing to lend you a hand in your integration journey.</p>",
            "url": "https://docs.openfn.org/articles/2021/05/24/commcare-events",
            "title": "Forms and Cases: CommCare and event-based integration",
            "summary": "This is a quick one, but I just got off an exciting call with an organization",
            "date_modified": "2021-05-24T00:00:00.000Z",
            "author": {
                "name": "Taylor Downs",
                "url": "https://github.com/taylordowns2000"
            }
        },
        {
            "id": "/2021/02/17/syncing-options",
            "content_html": "<p>â€œSyncingâ€ is getting two systems to a state of harmony. This might mean keeping\na list of patients up to date, though modifications can be made in either\nsystem. It might mean copying transactions from one system to another on a\nnightly basis. It might mean a lot of things, but the key concept is that when\nyou sync systems, youâ€™re asking them to work together while simultaneously\nrespecting both software systemsâ€™ independence.</p><p>In this post weâ€™ll discuss two different syncing protocols to consider when\ndesigning your data integration. These include:</p><ol><li><strong>Real-time, or event-based, syncs</strong></li><li><strong>Scheduled syncs</strong></li></ol><p>For a\n<a href=\"https://docs.openfn.org/blog/2021/02/09/interoperability_for_case_referrals\">recent project in Cambodia</a>,\nOpenFn is being used by social workers to automate case referrals between the\nsoftware systems Primero and OSCaR. In the design phase, we evaluated these two\nsyncing options. Below, we&#x27;ll explain what each one is, the differences between\nthem and which option we chose in the end.</p><h3>Real Time/Event Based Syncs</h3><p>The first option considered for this integration was the real-time/event based\nsync. This type of sync is triggered whenever a specified event takes place in a\nsystem. With this approach, whenever a case is referred in Primero (via the user\ninterface, i.e., when a real case-worker clicks the â€œreferâ€ button) OpenFn\nreceives a small payload with case data and transmits it to OSCaR and vice\nversa.</p><p><img src=\"/img/syncs1.png\" alt=\"Real_Time_Sync\"/></p><p>Because of their instantaneous nature, real time/event based syncs are great for\nintegrations that involve mobile payments or sms messages to recipients. Really,\nanything that needs to be done â€œnowâ€! Additionally, depending on your data\nvolumes real time syncs might save you money because youâ€™re only using resources\nwhen specific events take place. For instance, in the above example, a run is\ntriggered by a referral, so if there are only 10 case referrals/month, you&#x27;d\nonly process 10 runs each month.</p><p>This type of sync is great because itâ€™s instantaneous, typically quite\nstraightforward to set up, doesnâ€™t require any â€œstate mangagementâ€ on OpenFn,\nand allows for the reprocessing of individual events. There are, however,\ndrawbacks.</p><p>For instance, what happens if the app thatâ€™s sending notifications to OpenFn\nfails to send? What if AWS or GCP goes down, taking half of the internet with\nit? If Primero â€œthinksâ€ it sent the referral, OpenFn never receives it, that\ncase might not get referred to Oscar!</p><h3>Scheduled Syncs</h3><p><img src=\"/img/syncs2.png\" alt=\"Schedule_Dependent_Sync\"/></p><p>The second option considered, a bi-directional schedule dependent sync, solves\nfor the issue discussed above. On a scheduled basis (every 5 minutes, for\nexample) OpenFn checks with Primero and Oscar to see if case referrals need to\nbe transmitted between the two systems and then refers the case if required. In\nthe unlikely event that any of the software systems involved crash, the\nstability provided by the bi-directional sync means that all data is preserved\nand eventually makes it to its destination safely.</p><p>The major drawback here is complexity. We had to use 4 jobs instead of 2, and\nthe job that is responsible for â€œpullingâ€ data thatâ€™s been updated since the\ntime of the last successful sync has to keep â€œstateâ€â€”or some sort of working\nmemory of what itâ€™s done in the past. When pulling modified cases from Primero,\nOpenFn now only pulls cases modified on or after <code>YYYY-MM-DD HH:MM:SS</code> where\n<code>YYYY-MM-DD HH:MM:SS</code> is the time of the last successful, round-trip\nsynchronization. OpenFn has built-in functionality to handle exactly this\nrequirement, but not all ETL systems do and itâ€™s a design implication that must\nbe considered.</p><p>Ultimately, for the project in Cambodia, we decided that this sync option is the\nright choice because data integrity is more important than the speed of this\ndata flow. Thatâ€™s a crucial point to understandâ€”the organizations operating in\nCambodia decided that for this particular use case, being able to guarantee\neventual syncing was more important than having real-time syncing.</p><h3>Both Sync Options Have Their Pros and Cons</h3><p>Both options definitely have their use-cases and OpenFn&#x27;s platform versatility\nenables your team to decide which type of sync is right for your project.</p><p>As always, we are here to help with any questions as you think through which\nsync option makes the most sense for your project.</p>",
            "url": "https://docs.openfn.org/articles/2021/02/17/syncing-options",
            "title": "Sync Like You Mean It: Thinking Through System â€œSyncingâ€ Protocols",
            "summary": "â€œSyncingâ€ is getting two systems to a state of harmony. This might mean keeping",
            "date_modified": "2021-02-17T00:00:00.000Z",
            "author": {
                "name": "Jed Goldstein",
                "url": "https://github.com/jedbgold"
            }
        },
        {
            "id": "/2021/02/03/hosted-or-local-deployment",
            "content_html": "<p>Zandile is a program manager at an iNGO and she needs to use CommCare, DHIS2,\nand OpenFn for an upcoming public health project. She understands that all three\npieces of software can be deployed locally, or accessed as SaaS (Software as a\nService).</p><p>Essentially, Zandile needs to decide if she would like to run the software on\nsomeone elseâ€™s servers (SaaS), or on her organizationâ€™s own servers (deployed\nlocally). Before making a decision she outlines the basic, non-technical\nconsiderations for both options.</p><h2>What is SaaS?</h2><p>SaaS is software that is installed and <em>runs</em> on computers maintained by\nsoftware professionals, rather than on your own computer. While those computers\nmight be anywhere in the world, typically you&#x27;ll access and <em>use</em> this software via\nthe Internet.</p><h3>Some benefits of SaaS</h3><p>With SaaS, the software vendor is responsible for the expenses of managing and\nmonitoring all of the technical components and issues associated with the\nsoftware. This means that Zandileâ€™s iNGO will not be responsible for updating\nthe software to ensure compliance with new security regulations, maintaining the\nservers, backing up the data, purchasing and managing uninterrupted power\nsupplies, and providing a team of physical security guards to protect the\ncomputers and data therein against physical theft.</p><p>Going the SaaS route is often faster and more secure, because you do not need to\ndevelop expertise in &quot;DevOps&quot; or hire IT and physical security specialists. This\noption also provides the greatest amount of flexibility &amp; scalabilityâ€“ because\nthe SaaS provider is able to deliver more or less computing power, storage, and\nbandwidthâ€”right when itâ€™s needed.</p><p>Having smaller setup costs (you don&#x27;t have to grow a software delivery company\nof your own) often makes this a more economical choice for many, though SaaS\nwill always come with some sort of ongoing feeâ€”a price per month or year that\ngoes to the vendor to compensate for the time and money they&#x27;ll spend to ensure\nyour software works properly.</p><h2>What is Local Deployment?</h2><p>Unlike the SaaS option, local deployment means installing and running software\non your own computersâ€”typically on your organizationâ€™s servers.</p><h3>Some benefits of Local Deployment</h3><p>If a SaaS provider doesn&#x27;t offer hosting in your country and your government\ndoesn&#x27;t allow your data to reside on foreign servers (i.e., you&#x27;re not allowed\nto use things like Gmail, WhatsApp or Facebook for communicating sensitive\ninformation) then local deployment allows you to use tools like CommCare, DHIS2,\nand OpenFn while adhering to government data sovereignty regulations.</p><p>Local deployment also provides your organization with complete ownership of the\nend-to-end system. Your IT team will be personally responsible for ensuring that\nthe software works, is maintained, is secure, etc. If your organization does not\nalready have an IT team in place, then this can become a costly headache, but\nfor a large organization with embedded IT experience, local deployment often\nmakes sense.</p><p>Ultimately, being able to directly hire and fire the people who are responsible\nfor your software&#x27;s proper functioning can be very useful. It means you have\ncomplete responsibility for whether or not the solution succeeds.</p><p>If you&#x27;ve already got the teams in place (security, DevOps, etc.) then this\noption can be more economical in the long run. With a very good DevOps team,\nmaintaining an extra piece of software might only occupy 20% of a\nfull-time-employee&#x27;s salary. For your security guards, if the software is\ninstalled in the same physical location it&#x27;s possible that your costs won&#x27;t\nincrease at all. While there will be very high setup costs, over time you may\nrealize cost savings by running an efficient software delivery unit within your\norganization that spreads its focus around a number of projects.</p><h2>Zandile&#x27;s Decision</h2><p>In this fictional case, data residency is a concernâ€”her data is sensitive or\ncontains PIIâ€”and CommCare, DHIS2 and OpenFn do not provide hosting in the\ncountry she&#x27;s located. Zandile&#x27;s organization has a large, experienced IT team\nthat has managed high-availability software projects for many years... they&#x27;re\npros. While they anticipate that the setup costs will be quite high (around\n$60000 and several months for this set of deployments) they plan on using this\nsoftware for the next 5 years and have determined that they&#x27;ll recoup a\nsignificant portion of that setup cost by not having to pay license fees for\nSaaS. They go with local deployment.</p><h2>Which Deployment Option is Best for your organization?</h2><p>The answer is: &quot;it depends&quot;, but if your organization has never managed local\nsoftware deployments, then we recommend going the SaaS approach. SaaS systems,\nlike the one OpenFn and CommCare offer, are simply going to be more secure, more\nstable, and more scalable for the money.</p><p>Crucially, you can always start with SaaS (most tools even offer a free tier)\nand then decide later to invest in the big startup costs of a local deployment\nif the license fees for the SaaS feel high enough to make local deployment more\neconomical over the long term. After a few months or years on the SaaS, you&#x27;ll\nlikely be in a better position to know if you want to continue using the\nsoftware for 5-10 years.</p><p>Should you need any help with your decision though please do not hesitate to\ncontact OpenFn.</p>",
            "url": "https://docs.openfn.org/articles/2021/02/03/hosted-or-local-deployment",
            "title": "Our Servers or Yours: Thinking through deployment options",
            "summary": "Zandile is a program manager at an iNGO and she needs to use CommCare, DHIS2,",
            "date_modified": "2021-02-03T00:00:00.000Z",
            "author": {
                "name": "Jed Goldstein",
                "url": "https://github.com/jedbgold"
            }
        },
        {
            "id": "/2020/12/09/upsert-in-dhis2",
            "content_html": "<p>tl;dr: Lots of our users want to upsert tracked entity instances in dhis2, but\nupserts arenâ€™t supported by a standard DHIS2 API endpoint. We built one in our\ndhis2 adaptor: itâ€™s composed of existing APIs and a bit of logic ðŸ¤”. Now you can\n<code>upsert</code> tracked entity instances to DHIS2 ðŸ‘ âœ….</p><h2>A bit more...</h2><p>An â€œUPSERTâ€ is a portmanteau of the database functions UPDATE and INSERT. Itâ€™s\ncritical to handle upserts properly when integrating systems. As of version 35\nof the API, DHIS2 does not allow for an administrator to upsert tracked entity\ninstances (â€œTEIsâ€). OpenFnâ€™s own\n<a href=\"https://github.com/chaiwa-berian\">Chaiwa Berian</a> has come up with a solution\nthat highlights the utility of helper functions in our dhis2 adaptor. By\ncombining various DHIS2 APIs through an upsertTEI function in OpenFn, DHIS2\nusers can now perform upserts to TEIs.</p><p>If youâ€™re curious, check out his implementation\n<a href=\"https://github.com/OpenFn/language-dhis2/blob/master/src/Adaptor.js#L347\">here</a>.</p><h2>Even more!</h2><p>A tracked entity instance in DHIS2 is a type of entity that can be tracked\nthrough the system. It can be anything from a person to a commodity like a\nmedicine. If I am a database administrator presiding over two different systems\nthat are connected to one another, letâ€™s call them â€œSystem Aâ€ and â€œSystem B,â€ I\nwould like for any updates made to the TEI of a user named â€œJim Smithâ€ in System\nA to also appear in Jimâ€™s record in System B. Before upserts came about, doing\nso was difficult because of the possibility of duplicate record creation.\nBecause an upsert simultaneously UPDATES and INSERTS, it prevents duplicates.</p><p>Upserts are important and good because they cut down on the risk of duplicate\ndata entry and they also allow for transactions to be retried over and over to\nensure data integrity. That last bit is called â€œidempotencyâ€ and you can read\nabout it <a href=\"https://blog.openfn.org/allow-yourself-to-fail/\">over here</a>.</p><p>Please donâ€™t hesitate to reach out to one of OpenFnâ€™s implementation specialists\nif youâ€™d like to learn more.</p><p>â€” Taylor</p><p><a href=\"https://openfn.org/signup\">Sign up</a>{: .btn} to set up a project today,\nabsolutely free.</p><p><a href=\"mailto:admin@openfn.org\">Reach out</a>{: .btn} for more information.</p>",
            "url": "https://docs.openfn.org/articles/2020/12/09/upsert-in-dhis2",
            "title": "Tracked entity instances in DHIS2",
            "summary": "tl;dr: Lots of our users want to upsert tracked entity instances in dhis2, but",
            "date_modified": "2020-12-09T00:00:00.000Z",
            "author": {
                "name": "Taylor Downs",
                "url": "https://github.com/taylordowns2000"
            }
        },
        {
            "id": "/2020/07/14/cron-is-better-than-a-timer",
            "content_html": "<p>Hi all, this is a quick one from the product team at\n<a href=\"https://openfn.org/\">OpenFn</a> â€” we&#x27;ve made a major upgrade to how timed/period\njobs work.</p><p>In the past, if you weren&#x27;t using OpenFn to drive some real-time (or\n&quot;event-based&quot;) automation, you&#x27;d need to set up an &quot;interval trigger.&quot; Like the\nphoto above, this was essentially a sand timer. Set your trigger to <code>10</code> seconds\nand your job fetches data from DHIS2, some regional public health data set, or\nwhatever, then cleans, transforms, and loads it into some other system.</p><p>For the most part, this has got the job done for the last 5 years, but as our\nNGO and government clients came up with increasingly specific requirements on\nnot only how often but <em>when</em> a crucial job gets executed, we began finding\nourselves creating little customizations for them on a once-off basis. We&#x27;re\nhappy to annouce that as of <code>v1.75</code> (released today), you can now schedule jobs\nto run based on <code>cron</code> expressions, giving you incredible control over when your\ntasks get executed.</p><h3>Scheduling is better than timing.</h3><p>Using <code>cron</code>, you can choose to run a job every minute by typing <code>* * * * *</code>.</p><p>Or maybe you&#x27;ve got a batch sync that you want to take place while your users\nare asleepâ€”why not run it every night at 11pm with <code>23 * * * *</code>.</p><p>What if you&#x27;ve got to submit reuqests for medical inventory only during the\nonset of flu season? Simply type <code>0 0 1 2-4 *</code> and your job will run at midnight\nthe 1st of the month, from February through April.</p><p>You can still run jobs at the click of a button and create timers with\nexpressions like <code>*/10 * * * *</code> for &quot;every 10 minutes&quot;, but scheduling with cron\ngives OpenFn.org users so much more control over how they run their\norganizations. (And that&#x27;s a good thing.)</p><p>If you&#x27;re keen on learning by doing but don&#x27;t have an OpenFn account yet,\n<a href=\"https://www.openfn.org/signup\">sign up for free</a> or mess around with cron\nexpressions at <a href=\"https://crontab.guru\" target=\"_blank\">crontab.guru</a>,\na brilliant site to quickly build complex cron expressions.</p><p>That&#x27;s all from product for today. Speak soon.</p><p>Taylor</p>",
            "url": "https://docs.openfn.org/articles/2020/07/14/cron-is-better-than-a-timer",
            "title": "Product News: Enhanced Scheduled/Periodic Job Control",
            "summary": "Hi all, this is a quick one from the product team at",
            "date_modified": "2020-07-14T00:00:00.000Z",
            "author": {
                "name": "Taylor Downs",
                "url": "https://github.com/taylordowns2000"
            }
        },
        {
            "id": "/2020/07/02/allow-yourself-to-fail",
            "content_html": "<p>Hi all, this is a very short post with a simple message: design for failure.\nEven if you&#x27;ve never heard of\n<a href=\"https://www.microsoft.com/en-us/sql-server\">MSSQL</a> (or\n<a href=\"https://azure.microsoft.com/en-us/\">Azure</a>, or Microsoft?), I want to talk for\none moment about the importance of upserts and a funny developer term called\n&quot;idempotence.&quot;</p><p>We just extended our\n<a href=\"https://github.com/OpenFn/language-mssql\">language-mssql adaptor</a> with a custom\nfunction that allows upserts (an <code>upsert</code> is when you either insert a new record\nor update an existing record based on some identifier). Before, you&#x27;d need to\nwrite something tedious like:</p><pre><code class=\"language-js\">sql({\n  query: `MERGE my_table AS [Target]\n          USING (SELECT &#x27;8675309&#x27; AS some_unique_id, &#x27;writing_blog_posts&#x27; AS skill) AS [Source]\n          ON [Target].some_unique_id = [Source].some_unique_id\n          WHEN MATCHED THEN\n            UPDATE SET [Target].some_unique_id=8675309, [Target].skill=&#x27;writing_blog_posts&#x27;\n          WHEN NOT MATCHED THEN\n            INSERT (some_unique_id, skill) VALUES ([Source].some_unique_id, [Source].skill);`,\n});\n</code></pre><p>whereas now you can simply write:</p><pre><code class=\"language-js\">upsert(&#x27;my_table&#x27;, &#x27;some_unique_id&#x27;, {\n  some_unique_id: 8675309,\n  skill: &#x27;writing blog posts&#x27;,\n});\n</code></pre><p>For an operation to be idempotent means that it can be repeated time and time\nagain without producing an unintended result. This is SUPER important for\ncreating S3 (<strong>S</strong>ecure, <strong>S</strong>table and <strong>S</strong>calableâ€”more on that\n<a href=\"https://openfn.org/trust\">here</a>) integrations because it provides you with two\n&quot;get-out-of-jail-free&quot; cards.</p><ol><li><p>If a destination application fails, if a connection times out, or if (for\nwhatever reason) you&#x27;re not sure if the <code>job</code> was completed (say... making a\npayment to CHW) then an idempotent operation can be RETRIED without fear of\nmaking a double-payment.</p></li><li><p>If you make some change to how your <code>job</code> works, make some modification to\none of your destination systems, or just because you want to be <em>extra extra\nsure</em> that all the data in a 9 month survey made it to the national public\nhealth reporting system, you can <em>REPROCESS</em> every single message that&#x27;s come\nthrough OpenFn at the click of a button, without having to worry about\nduplicates.</p></li></ol><p>So... when clients let me mess around with their jobs, I <em>always</em> recommend we\ndesign for idempotence. It&#x27;s common sense when you&#x27;re passing messages between\ntwo different systems that are bound to evolve, go offline, have a bad day, etc</p><p>â€” Taylor</p><p><a href=\"https://openfn.org/signup\">Sign up</a>{: .btn} to set up a project today,\nabsolutely free.</p><p><a href=\"mailto:admin@openfn.org\">Reach out</a>{: .btn} for more information.</p>",
            "url": "https://docs.openfn.org/articles/2020/07/02/allow-yourself-to-fail",
            "title": "Allow Yourself to Fail",
            "summary": "Hi all, this is a very short post with a simple message: design for failure.",
            "date_modified": "2020-07-02T00:00:00.000Z",
            "author": {
                "name": "Taylor Downs",
                "url": "https://github.com/taylordowns2000"
            }
        },
        {
            "id": "/2020/06/24/three-questions-to-ask",
            "content_html": "<p>Automation can save time, unlock critical resources, and enable scaleâ€“but it\ntypically requires investment to set up. Wondering whether you should automate\nyour processes? Ask yourself these 3 questions.</p><h3>Our partners use <a href=\"https://openfn.org\">OpenFn</a> automation solutions to drive efficiency and scale their processes, delivering integrated digital systems that work better, faster, and together.</h3><p>To date, we have worked with 43 social sector organizations that operate across\nsectorsâ€“from health, education, and agriculture, to livelihoods and emergency\nresponse. Over the last 6 years, OpenFn has been implemented worldwide for a\nwide range of use cases, including building real-time data monitoring systems,\nstreamlining data cleaning pipelines, securely exchanging sensitive information,\nand automating routine processes like uploading indicator results, sending\nSMS/email alerts, making mobile payments,\n<a href=\"https://openfn.org/solutions\">and more</a>.</p><p>By connecting any app, OpenFn can integrate and automate all apps within a\ndigital ecosystem. However, a question that we frequently ask our partners is:</p><h4>Just because you <em>can</em> automateâ€”<em>should</em> you?</h4><p>While integration and automation have the potential to enable scale and save\ntime and money (weâ€™ve learned this from our\n<a href=\"https:openfn.org/clients\">partners</a>), solutions require investment to set up\nand maintain. These costs sometimes outweigh expected efficiency gains and\nservice outcomes. Therefore, when evaluating the cost-benefit of investing in\nautomation and integration solutions, we at Open Function Group typically ask 3\nkey questions.</p><h4>1. Security â€” Will automation limit the exposure of sensitive data?</h4><p>Can the exposure of sensitive data be limited by integrating with secure API\nendpoints (rather than relying on human beings to interact with those data, for\nexample)? Or by automating a data cleaning process?</p><h4>2. Accuracy â€” Will automation increase data accuracy and reduce data entry errors?</h4><p>Can the process take place more reliably by limiting the opportunity for human\nerror (in automating data manipulation or simple algorithmic work, for example)?</p><h4>3. Speed â€” Will automation increase the speed of impact?</h4><p>Can the process be done more quickly via automation and is there value in having\nit done faster? (The answer to the first part is almost always yes, but\nsometimes there&#x27;s not actually lots of value generated by doing something\nfaster.)</p><h4>If you find yourself answering â€œyesâ€ to these questions, it may be time to consider automating critical processes at your organization.</h4><p>Tasks that meet these 3 criteria, take a lot of time to complete or are very\nrepetitive, and/or involve moving data between apps are typically great\ncandidates for automation.</p><p>If you find yourself answering â€œnoâ€, then it may not be worth the investment in\nautomation... at least not yet. This is especially true if these processes are\nstill in flux or require a lot of human involvement to complete. That said, now\nmay be a good time to refine your existing workflows, think about how your\nprocesses might change at scale, and consider what <em>new</em> processes, services, or\noutcomes could be unlocked by automation.</p><h3>Delegate your busywork to OpenFn, and try it today!</h3><p>If you want to try out automation for your organization,\n<a href=\"https://www.openfn.org/signup\">sign up</a> for OpenFn, free of charge. Check out\n<a href=\"https://docs.openfn.org/\">our documentation</a> and\n<a href=\"http://www.openfn.org\">website</a> to learn how to get started.</p><p>Having trouble setting up your first automation &quot;job&quot;? Email us at\n<a href=\"mailto:admin@openfn.org\">admin@openfn.org</a> for support. Our team is always\nhappy to assist and help you evaluate the total cost of ownership of automation\nsolutions.</p>",
            "url": "https://docs.openfn.org/articles/2020/06/24/three-questions-to-ask",
            "title": "To Automate or Not to Automate? Ask Yourself These 3 Questions.",
            "summary": "Automation can save time, unlock critical resources, and enable scaleâ€“but it",
            "date_modified": "2020-06-24T00:00:00.000Z",
            "author": {
                "name": "Aleksa Krolls",
                "url": "https://github.com/aleksa-krolls"
            }
        },
        {
            "id": "/2020/06/16/how-information-is-organized",
            "content_html": "<h4>Does your organization&#x27;s information have an underlying structure? Try this exercise using boxes and crow&#x27;s feet.</h4><p>This article was originally posted by Taylor Downs, Head of Product, on\n<a href=\"https://medium.com/@taylordowns2000\">The OpenFn Founder&#x27;s blog</a> as &quot;The power\nof crow&#x27;s feet.&quot;</p><p>Itâ€™s Saturday Morning in Cape Town and Iâ€™ve just spent an hour talking about how\na non-profit is organized. I thought I was getting into a technical\ndiscussionâ€”Iâ€™ve been doing system architecture discussions for yearsâ€”but what we\nended up talking about was how this NGO thinks.</p><p>This engagement is largely about mapping an already existing â€œpeople &amp; paperâ€\nbased system to technology. Vera Solutions will build a system for this client\nusing Open Data Kit for field data collection and Salesforce.com for the\nmanagement â€œback-endâ€. Because weâ€™re not explicitly being asked to help redesign\nprocesses at this organization, the client is â€œtelling us how things areâ€, then\nexpecting us to create a relational database model that facilitates\nbusiness-as-usual, only in a more efficient, digital way. Seems reasonable.</p><p>This organization runs multiple programs focusing on a handful of strategic\nobjectives. They coordinate various activities in their target communities and\nreport on those activities against numerous (sometimes overlapping) indicators.\nSound familiar? As we get to the 3rd explanation of these programs, and the 11th\niteration of the system schema, it hits meâ€¦</p><h3>Drawing a &quot;relational object model&quot; sounds technical, but it&#x27;s actually an exercise in clear communication... and everyone can benefit from it.</h3><p>When weâ€”human beingsâ€”wrestle with complex problems (like managing lots of\nprograms, other humans, community stakeholders, etc.) we have the capacity to\ntrick ourselves into thinking that we have wrapped our heads around a system\n(for clinic registration, for after-school education, etc.) when, in fact, weâ€™re\nengaging in mental hand-waving and are simply â€˜papering-overâ€™ sections which are\nsecretly not just complicated, but totally incongruous with other parts of the\nsystem. We can make ourselves believe that our logic is sound because we want it\nto be sound, when in reality the organization might be held together by good\npeople, not good, clear, defined processes. By learning a couple of key\nconcepts, itâ€™s possible for non-technical people to articulate their thoughts\nclearly using â€œboxesâ€ and â€œcrowâ€™s feetâ€ and see whether or not there is an\nunderlying structure to their organizationâ€™s information.</p><h3>By forcing yourself to reduce complex systems to sketches containing only two elements, youâ€™ll be able to detect important conflicts and confusions in how you think about your organization that you might otherwise miss.</h3><p>If you canâ€™t diagram the information structure in your organization using boxes\nand crowâ€™s feet, itâ€™s a smell that something isnâ€™t quite right (or at least that\nsomething isnâ€™t easily scalableâ€¦ more on this later!). Let me show you the tools\nin the toolbox and then wrap up by waxing poetic on people, processes, and\ntechnology.</p><h3>Boxes and crow&#x27;s feet</h3><p>![]({{ site.baseurl }}/assets/images/box5.png)</p><p>The box is my favorite. It represents an entity in your data system. Entities\n(like <code>teachers</code>) have attributes (like <code>name</code>, <code>phone number</code>, <code>date of birth</code>,\n<code>gender</code>, etc.) Some people like thinking of entities as simple forms. The\nâ€œTeacher Registration Formâ€ will ask for the teacherâ€™s name, phone number,\ngender, etc. These are the fields on your teacher entity. By submitting one of\nthese forms, youâ€™ll add a new teacher to your database. If youâ€™re an Excel\nperson, the attributes are columns in your <code>teachers</code> table.</p><p>![]({{ site.baseurl }}/assets/images/crowsfeet2.png)</p><p>The crowâ€™s foot is my second favorite. Itâ€™s used to show relationships between\nentities. We know that teachers are related to the sessions that they conduct.\n(And <code>session</code> might be another entity, with fields like <code>date</code>,\n<code>subject taught</code>, and <code>venue</code>, to name just a few.) The crowâ€™s foot allows us to\nspecify exactly how they are related. On that session entity, weâ€™ll need to\nspecify the name (or ID) of the teacher who led it. On the teacher entity,\nhowever, there wonâ€™t be a field to specify the name or ID of the sessionâ€¦\nbecause a single teacher can lead MANY sessions. This is a one-to-many\nrelationship. The crowâ€™s foot (that little three-pronged fella) denotes the\nmany. One teacher can have many sessions. One session, however, can only have\none teacher. See the diagram below.</p><p>![]({{ site.baseurl }}/assets/images/objectmodel3.png)</p><p>If we focus just on <code>teacher</code> and <code>session</code> and think back to MS Excel, we can\nenvision a <code>teachers</code> table and a <code>sessions</code> table. Letâ€™s put them on different\nsheets in the same workbook. On the <code>teachers</code> table, there is no column for\n<code>session</code>, but on the <code>sessions</code> table, there <em>is</em> a column for <code>teacher ID</code>.\nWeâ€™ve just established a one-to-many relationship.</p><p>Next time, weâ€™ll talk about whatâ€™s going with the <code>attendance</code> entity above.\nItâ€™s sometimes called a â€œjunction objectâ€ or a â€œjoin tableâ€, and itâ€™s what\nallows MANY students to be related to MANY sessions. Iâ€™ll write more on this\nnext time, but there is no magic going on, no technicalities here. The way that\nmany students are related to many sessions is through this Real World Concept\nthat we call <code>attendance</code>. Attendance is what happens when a student shows up at\na session. Itâ€™s so important to get the language right in these discussions, and\nmake sure that youâ€™re talking about real-world concepts.</p><h3>Relational object models with lots of confusing terms are not &quot;technical&quot;. They are &quot;bad.&quot;</h3><p>Remember that as you start to put pen to paper. And allow yourselves time (and\nmultiple drafts) to get the boxes and terminology right. Understanding\nrelational object modelling is an incredibly powerful way to organize a company.\nAs I said before, if you canâ€™t model it with boxes and arrows, itâ€™s a smell that\nsomething might not be conceptually sound.</p><h3>A disclaimer and some thoughts on scaling:</h3><p>Some organizations do amazing work without good conceptual systems. They rely on\nhumans, instinct, improvisation, nouse, and other not-so-clearly-defined things.\nThey might do really great work. They might get the job done. But they need to\nbe well aware of their condition and face it head on. If you canâ€™t systematize\nyour program implementation processes, then you need to focus tremendous effort\non finding and retaining the right people.</p><p>A friend once told me that â€œpeople are not scalable.â€ I couldnâ€™t agree more, and\ndefend my earlier stance that if your organizationâ€™s information structure canâ€™t\nbe defined with boxes and crowâ€™s feet, it may be very hard for you to scale\nresponsibly. However, if you can create a ruthlessly efficient, world-class\nâ€œpeople operationsâ€ system (recruitment, training, management, compensation, HR,\netc.) that ensures youâ€™ve always got the right people to figure things out you\nmight be better off than those operating a well defined assembly-line with\ninterchangeable parts. Alas, the middle way is probably the best.</p><p>Thatâ€™s all for now. More soon.</p><p><em>Need help organizing or scaling your organization&#x27;s information or process\nflows? Contact our team of ICT4D specialists at <a href=\"mailto:support@openfn.org\">support@openfn.org</a>.</em></p>",
            "url": "https://docs.openfn.org/articles/2020/06/16/how-information-is-organized",
            "title": "How Information Is Organized... In Organizations",
            "summary": "Does your organization's information have an underlying structure? Try this exercise using boxes and crow's feet.",
            "date_modified": "2020-06-16T00:00:00.000Z",
            "author": {
                "name": "Taylor Downs",
                "url": "https://github.com/taylordowns2000"
            }
        }
    ]
}